## Disagreement

### Introducing the Issues {#introducingtheissues}

So far in this book I have discussed issues about disagreement only insofar as they related to higher-order evidence. In this chapter I change tack, and consider questions about disagreement, and especially peer disagreement, in their own right.

Here is a schematic case of peer disagreement. [Ankita]{acronym-label="Ankita" acronym-form="singular+short"} and [Bojan]{acronym-label="Bojan" acronym-form="singular+short"} are peers in both of the following senses:

1.  They know each other to be equally good at resolving a broad class of questions, of which the question of whether *p* is true is a representative member.

2.  They know that they each have the same evidence that bears on *p*.

They then independently consider the question of whether *p* is true, and when they report back, it turns out they have different views. In one simple, if extreme, case, [Ankita]{acronym-label="Ankita" acronym-form="singular+short"} thinks it is true, while [Bojan]{acronym-label="Bojan" acronym-form="singular+short"} thinks it is false. What changes, if any, should they make to their judgments, once they know what the other thinks?

There are, as elsewhere in philosophy, slightly more actively defended answers to this question than there are philosophers working on the question. So we need to start not with a list of possible answers, but a taxonomy of them. The **conciliationists** say that [Ankita]{acronym-label="Ankita" acronym-form="singular+short"} and [Bojan]{acronym-label="Bojan" acronym-form="singular+short"} should, to a considerable extent, move their credences towards the other's. In the case where one believes *p* to be true and the other believes it to be false, they should move to both withholding judgment. The **anti-conciliationists** deny this; they say that at least in many cases, at least one of the two need not change their credences at all merely in light of the disagreement.

In theory, I'm an anti-conciliationist. In particular, I defend a view that I'll call the **evidence aggregation** theory of disagreement. When someone hears that a peer disagrees with them, that is defeasible evidence the peer has evidence that they lack. Ideally, the hearer would work out exactly what that evidence is, add it to their stock of evidence, and react accordingly. That ideal is rarely, if ever, realised. In more realistic cases, the hearer assigns different probabilities to different hypotheses about what may have produced the disagreement. The typical case is that the peer has reacted differently to having different evidence to the hearer. And it is also typical that that's because the peer has evidence that the hearer lacks. So in (most) typical cases, the hearer will think there is evidence that they lack which supports the peer's view, and typically the rational reaction to learning that is to move one's views in the direction of the peer's view. But this credal movement is defeasible thrice over; sometimes the hearer knows the peer has reacted irrationally, sometimes the hearer knows the peer has strictly less evidence than they do, and (in very rare cases) the rational reaction to evidence of evidence for a rival view is not to move one's view towards the rival view.

In all cases, the guiding principle is that each party should be asking themselves, and each other, why does the other party have the views that they have?[^53] If the most plausible answer is that the other party has information that is relevant to *p*, then one should adjust one's confidence in *p* to suit.

[^53]: Note that I'm assuming here that there is no doubt about what the other party's views are. In realistic cases there is usually doubt about this. But what we are interested in here is how one should rationally respond to learning that another person has views that differ from one's own. It is useful to think about this question separately from the question of whether one does really know, in a given situation, that the other person has different views. Obviously if someone reports having a very improbable view, we should not take that report at face value; they may be lying about what they believe. But as theorists we can still think about the question of how to react to others having different views, even radically different views.

The evidence aggregation view of disagreement is really the conjunction of two separable views. The first claim is that the right theory of disagreement is a reason aggregation theory. That is, hearers should aggregate the reasons for belief they have with the reasons that their interlocutor[^54] has for the conflicting belief. The second claim is that evidence, and evidence alone, provides reasons for belief. The focus of this chapter will be largely on the first claim, though the way I defend it will both presuppose the second claim, and indirectly provide some support for it.[^55]

[^54]: I'm going to talk about hearers and interlocutors for ease of exposition, but don't read much into this. It doesn't matter that the evidence the 'hearer' gets for the disagreement is testimonial. And as noted in the previous footnote, real life cases of testimony involve both questions about how probable it is that the interlocutor is sincere, and how one should react on the assumption that they are sincere. Our interest is solely in the latter question.

[^55]: There is a large epistemological literature on disagreement, but very little of it concerns what we should say in cases where non-evidential reasons for belief are allowed. We'll set those cases aside here, though I think the evidence aggregation theory handles them fairly smoothly.

One consequence of the evidence aggregation view is that a person who has got things right, i.e., responded correctly to the evidence, should not adjust their views if they know the other party has no evidence they lack. So it is anti-conciliationist about the extreme case we started with, where the parties know they have the same evidence. In practice, the evidence aggregation view disagrees with conciliationism less than you might expect. Given the expansive conception of evidence I have been defending, it is vanishingly rare that parties know they have the same evidence. Usually, the rational response to a disagreement is not to give high credence to the proposition that the other party has exactly the same evidence as one does. Instead, it is to give high credence to the proposition that there is evidence that one lacks, and that supports a view closer to that of one's interlocutor. This is what's right about conciliationism, but it is not what is usually defended by philosophical conciliationists.

The evidence aggregation view of disagreement that I'm promoting bears an obvious affinity to the justificationist view of disagreement that Jennifer @Lackey2010 defends. The main differences are really points of emphasis, not deep principle. Lackey describes her view as a way of taking the best features of each of conciliationism and anti-conciliationism; I'm interested in a version of the view that is clearly opposed to conciliationism. Relatedly, Lackey's explanations of some of the cases that motivate conciliationism are different to mine. But the similarities outweigh the differences, and I wanted to note her theory as the closest precursor to the theory I'll defend here.

Another big motivation for the this view of disagreement I'm defending comes from some remarks on testimony by [Frank]{acronym-label="Frank" acronym-form="singular+short"} @Jackson1987. Jackson suggests that the primary role of testimony is evidence aggregation.

> Why should you ever accept what I say, unless you already did so before I spoke -- in which case speech is a luxury? ... The answer cannot be that you are taking me to be sincere. ... Sincerity relates to whether you should infer prior agreement or disagreement in beliefs, not to whether posterior adjustment of belief is in order. The reason posterior adjustment in belief may be in order is that hearers (readers) sometimes have justified opinions about the evidence that lies behind speakers' (writers') assertions. You assert that P. I know enough about you, and your recent situation, to know (i) that you have evidence for P, for you would not otherwise have said it, and (ii) that your evidence is such that had I had it, I would have believed P. I borrow your evidence, so to speak. Typically, I won't know exactly what your evidence is. Perhaps you visited a factory and came back and said 'The factory is well run'. I don't know just what experiences you had there -- just what you saw, heard, smelt and so on -- but I know enough to know that had I had these experiences -- whatever exactly they were -- I too would have come to believe the factory well run. So I do. ...in this way an epistemological division of labour is achieved. Imagine the work (and invasion of privacy) involved if we all had to duplicate each other's evidence. Of course, I may not come to believe exactly what the speaker or writer believes. A friend returning from overseas may say to me of a certain country 'It is very well run'. I may know enough of my friend to know that experiences that would make him say that, are the kind that would make me say 'Dissent is suppressed'. In this case, I will borrow his evidence to arrive, not at what he believes, but at what I would have, had I had his experiences. Â [@Jackson1987 92-3]

I agree with almost all of this, though I'm not going to issue a full defence of such an evidence aggregation account of testimony here. (Why 'almost'? Because it will be rather important later that we not be able to move as freely between sharing experiences and sharing evidence as Jackson does in the last line.) Rather, I'm just going to acknowledge my debt to Jackson's ideas, and move to disagreement.

I'm hardly the first person to start with broadly evidentialist intuitions and end up with anti-conciliationist conclusions about disagreement; you can see a similar trajectory in recent work by Maria [@Lasonen-Aarnio2013; @Lasonen-Aarnio2014], and what I say here also owes a lot to her. But the details are different enough to justify a new variant on similar themes.

### Two Concepts of Peerhood {#twoconceptsofpeerhood}

My setup of the [Ankita]{acronym-label="Ankita" acronym-form="singular+short"}/[Bojan]{acronym-label="Bojan" acronym-form="singular+short"} case is ambiguous at a key point. I said that [Ankita]{acronym-label="Ankita" acronym-form="singular+short"} and [Bojan]{acronym-label="Bojan" acronym-form="singular+short"} are equally good at resolving questions like this. There are two natural ways to interpret this. We could read it as meaning that they are equally likely to come up with a rational verdict, or that their verdicts are equally reliable. David @Christensen2014 is very good on the importance of this distinction.

> The literature typically concentrates on people one has (independent of one's views on the disputed issue) good reason to take as *epistemic peers*--as rough equals along certain dimensions of epistemic evaluation. One such dimension concerns the evidence the other person has relevant to the disputed issue, and the other concerns how well she forms beliefs on the basis of her evidence. ...\[W\]e should notice that there are a couple of different ways of approaching the second dimension of evaluation--ways which are not always clearly separated. One focuses on the other person's equal likelihood of responding *rationally* to her evidence. On this reading, ... the disagreeing friend is what might be called a "rationality-peer" on the given issue: one whose opinion is equally likely to be rational. The second way of evaluating the other person's responses to evidence is in terms of her likelihood of responding to that evidence by forming *accurate* beliefs. On this reading, ... the disagreeing friend ... might be called an "accuracy-peer" on the given issue: one whose opinion on the disputed issue one expects to be as likely to be accurate as one's own. Â [@Christensen2014 3]

Christensen cites @Feldman2007, @Kelly2005, @Christensen2007c and @Cohen2013 as writers who understand peerhood in terms of rationality, and @Elga2007, @White2009, @Enoch2010, @Kelly2010, @Lam2011 and @Levinstein2013 as writers who understand it in terms of accuracy. He's not the first to notice these two possible understandings; the distinction plays a big role in work by Ben @Levinstein2013 and by Miriam @Schoenfield2014b.

The rationality-based understanding is most relevant to the broader themes of this book. If peerhood is understood in terms of rationality, then the motivation to conciliate in light of peer disagreement is indirect. The conciliationist says that [Ankita]{acronym-label="Ankita" acronym-form="singular+short"} should do two things in light of [Bojan]{acronym-label="Bojan" acronym-form="singular+short"}'s disagreement. First, she should use that disagreement as evidence that her initial view is irrational, then second, she should that fact as grounds for revising that first-order credence. Normative externalism disagrees with the second step. The fact that she has some higher-order evidence that she is irrational need not, on its own, be any reason to revise her first-order credence.

But many writers have noted that the first step of this sequence is dubious too. The most that [Ankita]{acronym-label="Ankita" acronym-form="singular+short"} gets from [Bojan]{acronym-label="Bojan" acronym-form="singular+short"}'s disagreement is evidence that some view other than hers is rational. It does not follow that her view is irrational, unless we have make a background assumption that there is only one rational response to any given evidence. So it seems that the argument for conciliationism requires the thesis Roger @White2005 calls Uniqueness: that there is a single rational response to evidence. Whether this seeming is really correct is actively debated: see @Douven2009, @Kelly2010, and [@BallantyneCoffman2011; @BallantyneCoffman2012] for interesting moves in the debate. I'm going to mostly not take a stance on this, since the arguments for conciliationism have other weaknesses.

It might seem that once [Ankita]{acronym-label="Ankita" acronym-form="singular+short"} views [Bojan]{acronym-label="Bojan" acronym-form="singular+short"} as an accuracy-peer, issues about higher-order evidence aren't relevant to determining whether she should conciliate in light of her disagreement. After all, in that case [Ankita]{acronym-label="Ankita" acronym-form="singular+short"} has two pieces of evidence; her own judgment and [Bojan]{acronym-label="Bojan" acronym-form="singular+short"}'s. By hypothesis, each of them are equally accurate. So she should act as if she had two measuring devices, one which said that *p* was true, and the other that said it was false. And in that case one should have no settled view about *p*.

But that misstates the situation. [Ankita]{acronym-label="Ankita" acronym-form="singular+short"} doesn't just have two pieces of evidence; she also has the evidence that led to her initial judgment that *p*. We only get to describe the case in ways that make it seem symmetric if we somehow have a reason to set that initial public evidence aside. This point is well made by @Kelly2010. And the only way I can see to justify that set aside is by adopting some principle like JSE. And JSE, as we saw, is false. Moreover, JSE is equivalent, given plausible assumptions, to an internalist principle about higher-order evidence.

So however we understand peerhood, either in terms of rationality or in terms of accuracy, the arguments for conciliationism will be tied up with arguments about higher-order evidence and hence with normative externalism.

### Evidence, Public and Private {#evidencepublicandprivate}

In many discussions of peer disagreement, cases are presented where it is clear that the disputants have the same public evidence. It does not follow that in those cases the disputants have the same evidence tout court. Consider this simple case.

> **Stars I**
>
> [Ankita]{acronym-label="Ankita" acronym-form="singular+short"} and [Bojan]{acronym-label="Bojan" acronym-form="singular+short"} are wondering how many stars there are. They both have the concept of a prime number, but they aren't familiar with Euclid's proof of the infinity of primes. In fact, they both suspect, given the decreasing frequency of primes, that they run out eventually. In the course of their research into the stars, they run into the Delphic Oracle, who is known to always speak the truth. The Oracle says "There are as many stars as primes". [Bojan]{acronym-label="Bojan" acronym-form="singular+short"} takes this to be evidence that *There are infinitely many stars* is probably false. But while reflecting on it, [Ankita]{acronym-label="Ankita" acronym-form="singular+short"} comes up with a version of Euclid's proof that there are infinitely many primes, and concludes that there are an infinity of stars.

This is a case where [Ankita]{acronym-label="Ankita" acronym-form="singular+short"} should not conciliate in light of her disagreement with [Bojan]{acronym-label="Bojan" acronym-form="singular+short"}. She has a proof that there are infinitely many primes and [Bojan]{acronym-label="Bojan" acronym-form="singular+short"} does not. So she should not change her views. But that's not really a case that the most plausible form of conciliationism gets wrong. For reasons that should be familiar from previous chapters, we should treat [Ankita]{acronym-label="Ankita" acronym-form="singular+short"} as having more evidence than [Bojan]{acronym-label="Bojan" acronym-form="singular+short"}. Her reconstruction of Euclid's proof that there are infinitely many primes is a bit of evidence she has that [Bojan]{acronym-label="Bojan" acronym-form="singular+short"} does not.

This all suggests a very weak, and hence easier to defend, version of conciliationism. It only applies to cases where two parties have differing views about a proposition, and the following four conditions are met.

1.  The two parties have no reason external to this disagreement to think that one is more likely to be rational than the other.

2.  The two parties have no reason external to this disagreement to think that one is more likely to be accurate than the other.

3.  The two parties have the same public evidence.

4.  The two parties have the same private evidence.

The evidence aggregation theory of disagreement is anti-conciliationist in that in this extreme case, it denies that both parties should conciliate. If one party is acting rationally and the other is not, the first party should stick to their view.

But even though I'm not a conciliationist in theory, this kind of case brings out why I'm sympathetic to conciliationism in practice. These four conditions are met in vanishingly rare circumstances. And when they are not met, there are quite mundane reasons for thinking that each party should typically conciliate. A running theme through this chapter will be that the cases thought to motivate conciliationism do not satisfy these four criteria, and hence it is possible for an anti-conciliationist to consistently say that each party should move towards the others view in ordinary cases

Two more points of clarification before we move on.

First, I'm going to start by looking at a very specific form of conciliationism, namely Adam Elga's Equal Weight View (EWV). The EWV says that when two people are peers, and they have the same evidence, and they learn that they have credences $c_1$ and $c_2$ in a disputed proposition *p*, they should each adopt a credence half-way between their initial credences. That is, their new credence in *p* should be $\frac{c_1 + c_2}{2}$. The EWV is not by any means the only version of conciliationism. Indeed, it faces some difficult technical problems, described by @JehleFitelson2009 and by @Levinstein2013. But as long as we are careful, we can see which objections are only problems for the EWV, and which form more general problems for conciliationism.

Second, it is very important here, as almost everywhere in epistemology, to respect the distinction Gilbert @Harman1986 draws between inference and implication. We can see this by looking at another example about stars.

> **Stars II**
>
> In this world [Ankita]{acronym-label="Ankita" acronym-form="singular+short"} and [Bojan]{acronym-label="Bojan" acronym-form="singular+short"} are very knowledgable about primes. Indeed, they are among the co-authors of that world's counterpart paper to @Polymath2014. This time the oracle tells them that there are as many stars as twin primes. [Ankita]{acronym-label="Ankita" acronym-form="singular+short"} infers that there are probably infinitely many stars, but it is too soon to be completely confident. [Bojan]{acronym-label="Bojan" acronym-form="singular+short"}, on the other hand, becomes completely certain that there are infinitely many stars.

In my opinion, and for that matter [Ankita]{acronym-label="Ankita" acronym-form="singular+short"}'s, the evidence [Ankita]{acronym-label="Ankita" acronym-form="singular+short"} and [Bojan]{acronym-label="Bojan" acronym-form="singular+short"} have conclusively settles the question of whether there are infinitely many stars. What they know about primes, plus what they know about the oracle, plus what they are told by the oracle, probably entails that there are infinitely many stars. So there is, probably, a conclusive implication from their evidence to that conclusion. But there is no reasonable inference from their evidence to the conclusion that there are infinitely many stars. That inference requires knowing something that is not in evidence, namely that there are infinitely many twin primes. The fact that this fact is a logical truth (or at least is logically entailed by things they know about primes) is irrelevant. A probably conclusive implication can be a definitely unreasonable inference, and is in this case. Unless [Bojan]{acronym-label="Bojan" acronym-form="singular+short"} has a proof of the twin prime conjecture up his sleeve, one that he hasn't shared with his co-authors, he should move his credences in the direction of [Ankita]{acronym-label="Ankita" acronym-form="singular+short"}'s. That is, he should conciliate. It's possible that [Ankita]{acronym-label="Ankita" acronym-form="singular+short"} should conciliate too; I haven't said nearly enough about the case to settle that one way or the other. I think the mistaken idea that entailments generate maximally strong inferences has led to some confusion about what to say about certain cases, and that will become relevant as we progress.

### Independence and Conciliationism {#independenceandconciliationism}

In early writings on concliationism, such as those by @Elga2007 and @Christensen2009, there was a line of argument from principles like Independence (as we've discussed in previous chapters) to conciliationism. This line is flawed, for reasons well set out by Errol @Lord2014. The point of this section is simply to rehearse Lord's arguments before moving onto other possible motivations for conciliationism.

There are weaker and stronger versions of the kind of Independence principle that Elga, Christense and others use. The strongest such principle says that in any dispute, a party to the dispute can only reasonably conclude that the other party is wrong based on reasons independent of their reasons for having a disputed view. But that leads to very odd predictions in cases like this.

> **Bus Stop**
>
> While waiting at the bus stop, [Ankita]{acronym-label="Ankita" acronym-form="singular+short"} is approached by [Bojan]{acronym-label="Bojan" acronym-form="singular+short"} , who tells her that he is certain she lives in a shoe. [Ankita]{acronym-label="Ankita" acronym-form="singular+short"} is fairly confident, based on long familiarity with her apartment, that she lives in an apartment, not a shoe.

[Ankita]{acronym-label="Ankita" acronym-form="singular+short"} doesn't have to find independent evidence that [Bojan]{acronym-label="Bojan" acronym-form="singular+short"} is mistaken to hold onto her belief that she lives in an apartment. Perhaps in some realistic versions of Bus Stop, [Bojan]{acronym-label="Bojan" acronym-form="singular+short"} would appear drunk or be slurring his words, and that would be the relevant independent evidence. But those external clues are not necessary. [Bojan]{acronym-label="Bojan" acronym-form="singular+short"} could appear perfectly sane and sensible in every respect except his firm belief that [Ankita]{acronym-label="Ankita" acronym-form="singular+short"} lives in a shoe, and she could still dismiss his view. So this strongest independence principle is false.

More plausible independence principles restrict the circumstances in which one must rely on independent reasons to dismiss a conflicting view. There are two interesting restrictions we could look at:

-   Independence might be restricted to cases where the disagreeing parties are known to be just as good at reading the evidence. (We could break this down into two sub-cases depending on whether 'good' is understood in terms of accuracy or rationality, but this won't matter.)

-   Independence might be restricted to cases where the disagreeing parties are known to have the same evidence.

But, and this is the crucial point that Lord makes, neither of these restrictions on their own gives us a plausible principle. If we only impose the first restriction, we end up with the implausible conclusion that [Ankita]{acronym-label="Ankita" acronym-form="singular+short"} is expected to conciliate in this case.

> **Party**
>
> [Ankita]{acronym-label="Ankita" acronym-form="singular+short"} and [Bojan]{acronym-label="Bojan" acronym-form="singular+short"} are just as good, in both senses, at working out where a party is given some evidence. But [Bojan]{acronym-label="Bojan" acronym-form="singular+short"} hasn't looked at the invitation to tonight's party in weeks, so is uncertain whether the party is on State St or Main St. [Ankita]{acronym-label="Ankita" acronym-form="singular+short"} looked at the invitation two minutes ago, and is certain the party is on State St.

It would be absurd to think that because [Ankita]{acronym-label="Ankita" acronym-form="singular+short"}'s credence that the party is on State St is 1, and [Bojan]{acronym-label="Bojan" acronym-form="singular+short"}'s is 0.5, and they are just as good at working out where parties are given some evidence, that [Ankita]{acronym-label="Ankita" acronym-form="singular+short"}'s credence that the party is on State St should move to 0.75. Rather, she should conclude that [Bojan]{acronym-label="Bojan" acronym-form="singular+short"} hasn't looked at the invitation recently. And she should conclude that simply because [Bojan]{acronym-label="Bojan" acronym-form="singular+short"} has a different credence to her about where the party is. That's what an independence principle that only imposes the first constraint would rule out, so such an independence principle is false.

Nor will the second restriction on its own do. If we restrict the restriction to public evidence, then Stars I is already a counterexample to it. But we can come up with cases where arguably [Ankita]{acronym-label="Ankita" acronym-form="singular+short"} and [Bojan]{acronym-label="Bojan" acronym-form="singular+short"} even have the same private evidence, and the restriction is still not sufficient.

> **Diagnosis**
>
> [Ankita]{acronym-label="Ankita" acronym-form="singular+short"} is a professor at a medical school, and [Bojan]{acronym-label="Bojan" acronym-form="singular+short"} a student. The students at her school are very good; often they are as good at diagnosis as the professors. And [Bojan]{acronym-label="Bojan" acronym-form="singular+short"} has done, [Ankita]{acronym-label="Ankita" acronym-form="singular+short"} knows, very well on his theory exams. But some students who know a lot of theory are very poor at making a diagnosis based on material in a patient's file. So [Ankita]{acronym-label="Ankita" acronym-form="singular+short"} pulls out a file at random for her and [Bojan]{acronym-label="Bojan" acronym-form="singular+short"} to look at. Given the symptoms displayed, [Ankita]{acronym-label="Ankita" acronym-form="singular+short"} is very confident in a particular diagnosis. But [Bojan]{acronym-label="Bojan" acronym-form="singular+short"} has no idea what to say about the case; his best guess is that we should have low but positive credence in several distinct diagnoses.

In this case, [Ankita]{acronym-label="Ankita" acronym-form="singular+short"} shouldn't infer that she had been over-confident. She should conclude that, despite his solid background, [Bojan]{acronym-label="Bojan" acronym-form="singular+short"} isn't very good at making a diagnosis. I've obviously simplified a lot, but this seems like a very natural way for professors to test whether their students have or lack a practical skill. Now perhaps the best explanation of this case is that [Bojan]{acronym-label="Bojan" acronym-form="singular+short"} really lacks some evidence, despite his doing well on tests. That's actually what I suspect is going on. But I suspect most people, and certainly most conciliationists, don't think that. It is much easier to motivate conciliationism if we think that there is a skill of processing evidence that goes well beyond the possession of evidence, and that in cases like this one what's happened is that [Bojan]{acronym-label="Bojan" acronym-form="singular+short"} lacks that skill. (Why say conciliationism is easier to motivate if one posits large skill differences that go beyond evidence possession? Because now we can say why one person should defer to another without thinking the other person has evidence they lack; the other person may have more skills.)

Now if independence just requires that the parties had the same evidence, and this is a case where the parties have the same evidence, it would be an independence violation for [Ankita]{acronym-label="Ankita" acronym-form="singular+short"} to infer from [Bojan]{acronym-label="Bojan" acronym-form="singular+short"}'s lack of certainty in any diagnosis to his lack of skill in making diagnoses. Rather, she should conciliate with him, and lose confidence in her diagnosis. That's wrong, so this independence principle is too strong.

So just putting each of these restrictions on independence singularly does not yield a viable principle. What happens if we put both restrictions on at once, and say independence holds only if the parties are known to have the same evidence and known to be just as good (in some sense) at processing it? Lord points out that then we don't have a premise in an interesting argument for conciliationism. Rather, the independence principle that is supposed to motivate conciliationism has just become a statement of conciliationism. So it can't provide any independent support for it.

### Circularity and Conciliationism {#circularityandconciliationism}

Conciliationism has been supported, or at least anti-conciliationist positions opposed, with arguments that anti-conciliationism lapses into an implausible kind of circularity. Here are a couple of quotes setting out this kind of worry. First, from Adam Elga.

> To see the correctness of the equal weight view, start with a case of perceptual disagreement. You and a friend are to judge the same contest, a race between Horse A and Horse B. Initially, you think that your friend is as good as you at judging such races. In other words, you think that in case of disagreement about the race, the two of you are equally likely to be mistaken. The race is run, and the two of you form independent judgments. As it happens, you become confident that Horse A won, and your friend becomes equally confident that Horse B won.
>
> When you learn of your friend's opposing judgment, you should think that the two of you are equally likely to be correct. For suppose not--suppose it were reasonable for you to be, say, 70% confident that you are correct. Then you would have gotten some evidence that you are a better judge than your friend, since you would have gotten some evidence that you judged this race correctly, while she misjudged it. But that is absurd. It is absurd that in this situation you get any evidence that you are a better judge ...
>
> Furthermore, the above judgment of absurdity is independent of who *in fact* has done a better job. Even if in fact you have judged the series of races much more accurately than your friend, simply comparing judgments with your friend gives you no evidence that you have done so. Â [@Elga2007 486-7, emphasis in original]

And second, from Diego E. Machuca. (This quote comes just after a presentation of Thomas Kelly defending something close enough, for current purposes, to the evidence aggregation view I'm defending.)

> Kelly maintains that one can be justified in thinking that one has appropriately responded to the first-order evidence even in the absence of independent evidence that one has done so. For the reason why one takes up a given belief is precisely that one *recognizes* that it is supported by the evidence one possesses, and one would not be able to recognize this if one were unjustified in thinking that the evidence does support the belief in question. I confess that I cannot see how this move is not question-begging all the way through. Just as one can affirm that one's opinion is justified because one recognizes that the available evidence supports it, so too one's opponent can affirm that his opinion is justified because he recognizes that the available evidence supports it. And if one were to argue that one's opponent is clearly mistaken because one would not recognize that one's belief is supported by the evidence if one were not justified in thinking that it is, one's opponent would retort that it is he who cannot be mistaken simply because he would not recognize that the evidence supports his belief were he not justified in so thinking. Â [@Machuca2013 77-78]

There are two things to say about this kind of argument. The first is that the strong form of the objection Elga makes is not really a response to the evidence aggregation view, but to the view that any agent is entitled to privilege their own view over others', simply because it is their own. But the kind of reasoning Elga worries about is only available to the one who has got things right, not to both parties. So the worry is not that everyone could have their self-confidence rise, but that those who get things right could become more confident in their ability to get things right in virtue of their recent track record of having got things right. And that doesn't look like much of a worry. (I'm here not far away from the replies that Andrew @Rotondo2013 makes to circularity arguments for conciliationism.)

But at this point we run into Machuca's complaint. If the successful can be more confident in their own ability in virtue of their successes, won't those who merely think they are successful become more confident in their own ability in virtue of their own perceived success? And, in this game, doesn't everyone perceive of themselves as being successful?

There are a number of ways we could try to turn these rhetorical questions into arguments. For the reasons I went over in chapter 9, none of the resulting arguments will work. The underlying argument could be that appropriate epistemic methods must be bidirectionally luminous; everyone must be able to know if they are applying them correctly. But that kind of argument falls to the Williamsonian anti-luminosity arguments. Or it could be that appropriate epistemic methods must be sensitive, in Nozick's sense. But that kind of argument falls to the anti-sensitivity arguments. And so on for all the other ways of precifisying the argument that evidentialism licences noxiously question-begging practices.

Now I will note one sense in which those replies in chapter 9 might miss the mark. Machuca is defending a form of Pyrrhonian scepticism. And many of my defences of externalism involved showing that the principles deployed against externalism had implausible consequences. In particular, they implied Pyrrhonian scepticism. Now that won't look implausible to a Pyrrhonian like Machuca. Here I must simply note that I'm taking it as a fixed point that we do know a lot, and that Pyrrhonian scepticism is false. This obviously loses some potential converts, but I doubt it is possible to find philosophical arguments that work for one's position against all possible rivals Â [@Lewis1982c].

### Six Examples {#sixexamples}

The last two sections reply to arguments based on general theoretical principles in favor of conciliationism. The prospects for this way of defending the EWV, or indeed any conciliatory position, look dim. But these general theoretical principles have not been what have most moved philosophers towards conciliationism. Rather, they are moved by the idea that the EWV, or at least some form of conciliationism, is the best explanation of the clear facts about some simple cases. The literature here, as with the literature on higher-order evidence, suffers from that "main cause of philosophical disease--an unbalanced diet: one nourishes one's thinking with only one kind of example." Â [@Wittgenstein1953 Â§593]. I can't claim to offer a balanced diet, but I can offer the start of a more varied one. Here are six new morsels that will form the basis of the discussion to follow. I'm going to argue that the evidence aggregation view can explain the last two, while conciliationist can not. And I'll argue there is no case that the conciliationist can explain while the evidence aggregation theorist can not.

#### Arithmetic

[Ankita]{acronym-label="Ankita" acronym-form="singular+short"} and [Bojan]{acronym-label="Bojan" acronym-form="singular+short"} are working on some arithmetic problems. They both know that they have a similar track record at these problems; both are reliable, with very similar rates of mistakes. They are trying to work out *What is 22 times 18?*. [Ankita]{acronym-label="Ankita" acronym-form="singular+short"} correctly works out that it is 396; [Bojan]{acronym-label="Bojan" acronym-form="singular+short"} says that it is 386. What should their credences in each answer be?

#### Jellybeans

[Ankita]{acronym-label="Ankita" acronym-form="singular+short"} and [Bojan]{acronym-label="Bojan" acronym-form="singular+short"} are trying to guess how many jellybeans are in a sealed, transparent container. They both have equal access to the container, and they both know that they have similarly good track records at this kind of game. [Ankita]{acronym-label="Ankita" acronym-form="singular+short"} correctly guesses that there are 396; [Bojan]{acronym-label="Bojan" acronym-form="singular+short"} guesses that there are 386. What should their credences in each answer be? (A similar case is considered by Jack L. @Treynor1987.)

#### Detectives

[Ankita]{acronym-label="Ankita" acronym-form="singular+short"} and [Bojan]{acronym-label="Bojan" acronym-form="singular+short"} are the two best murder detectives in the world. They both know that they are the only peers they each have, and that they have very similar track records of success, with equal (and rare) failures. They are brought in to solve a mystery that no one has made any progress on. Each quickly sees that it could only be the butler or the gardener. [Bojan]{acronym-label="Bojan" acronym-form="singular+short"} has equal credence in each suspect, but [Ankita]{acronym-label="Ankita" acronym-form="singular+short"} figures out a subtle reason that it could not have been the gardener, so is sure the butler did it. And in fact the butler did do it, and [Ankita]{acronym-label="Ankita" acronym-form="singular+short"} is right about why the gardener could not have done it. After they compare credences, [Bojan]{acronym-label="Bojan" acronym-form="singular+short"} giving equal credence to each suspect, and [Ankita]{acronym-label="Ankita" acronym-form="singular+short"} being sure it is the butler, what should their credences in each answer be? (I owe this case to Ben @Levinstein2013.)

#### Football

[Ankita]{acronym-label="Ankita" acronym-form="singular+short"} and [Bojan]{acronym-label="Bojan" acronym-form="singular+short"} are both very good at predicting football games of different codes. They both typically make highly rational predictions, and they both have excellent (and similar) records for accuracy. They both know all this, and they have the same public evidence about this weekend's matches. They are comparing their credences in the home team winning ahead of two big matches: an Australian Rules match in Melbourne, and an English Premier League match in London. For each match, [Ankita]{acronym-label="Ankita" acronym-form="singular+short"} has a credence of 0.9 that the home team will win, and [Bojan]{acronym-label="Bojan" acronym-form="singular+short"} has a credence of 0.1 that the home team will win. They both regard the matches as completely independent, so [Ankita]{acronym-label="Ankita" acronym-form="singular+short"}'s credence that both home teams will win is 0.81, while [Bojan]{acronym-label="Bojan" acronym-form="singular+short"}'s is 0.01, and each of them have credence 0.09 in each of the hypotheses that one particular home team will win and the other will not. Once they share their credences with each other, what should their credence be that (a) the home team will win the Australian Rules match, (b) the home team will win the English Premier League match, and (c) both home teams will win?

#### Simple Arithmetic {#simplearithmetic}

[Ankita]{acronym-label="Ankita" acronym-form="singular+short"} and [Bojan]{acronym-label="Bojan" acronym-form="singular+short"} are working on some arithmetic problems. They both know that they have a similar track record at these problems; both are reliable, with very similar rates of mistakes. They are answering the question *What is 2 plus 2?*. [Ankita]{acronym-label="Ankita" acronym-form="singular+short"} says it is 4; [Bojan]{acronym-label="Bojan" acronym-form="singular+short"} says that it is 5. What should their credences in each answer be?

#### Doctors

[Ankita]{acronym-label="Ankita" acronym-form="singular+short"} and [Bojan]{acronym-label="Bojan" acronym-form="singular+short"} are the two best cardiologists in the world. They know each other to be peers, the only peers each has. They are brought in to diagnose a case that has stumped all the other experts in the field. [Ankita]{acronym-label="Ankita" acronym-form="singular+short"} judges that it is likely disease A, but she is just short of fully believing it is disease A, since she thinks disease B is an unlikely, but real, possibility. This is the rational response to the evidence. Although the patient has disease A, the evidence available to an expert cardiologist is just short of being sufficient to ground knowledge that the patient has disease A, since B is also a realistic possibility. She reports all this when she and [Bojan]{acronym-label="Bojan" acronym-form="singular+short"} compare notes, but [Bojan]{acronym-label="Bojan" acronym-form="singular+short"} reports that he is confident that the patient has disease A. What should their credence in each diagnosis be?

#### My Verdicts {#myverdicts}

These cases are, in general, not so clear that we can simply know what is true about them after a moment's thought, and use that knowledge to evaluate theories. But for the record, here are my verdicts on the cases.

In **Arithmetic**, I think a lot depends on the finer details of the case, particularly on how [Ankita]{acronym-label="Ankita" acronym-form="singular+short"} got to her answer. But I think no matter how those details are filled in, there isn't a lot of pressure on her to conciliate. Now this isn't a popular view. Much of the motivation for conciliationism comes from thinking that in versions of **Arithmetic** where the sum in question is not specified, there is rather strong pressure to conciliate. We'll come back to that idea several times below.

In **Jellybeans**, I think they clearly should conciliate. And unlike in **Arithmetic**, this conciliation should take the form of not just lowering their credences in their preferred answers, but in increasing their credence in answers between the two they offered. In **Jellybeans**, the announced answers should increase their confidence that the answer is 391, which is not what should happen in **Arithmetic**.

I have no idea what the answer to the third question in **Football**, about the appropriate credence in the compound proposition, is. We'll say a bit below about why this is such a hard question.

In each of the last three cases, **Detectives**, **Simple Arithmetic** and **Doctors** [Ankita]{acronym-label="Ankita" acronym-form="singular+short"} should not conciliate, and [Bojan]{acronym-label="Bojan" acronym-form="singular+short"} should move his credence dramatically in the direction of [Ankita]{acronym-label="Ankita" acronym-form="singular+short"}'s. Or at least so I say.

### Equal Weight and the Cases {#equalweightandthecases}

On the face of it, the EWV gets at most one of the six cases right. After all, the only case where it seems even prima facie right to move to a credence half-way between the two expressed views is **Arithmetic**. But a more nuanced understanding of the cases lets EWV handle **Jellybeans**, and a more subtle version of conciliationism does well (or at least well enough) with **Detectives** and **Football**. If there is a case-based objection to conciliationism, it comes from the last two cases. But first I want to go over why the second, third and fourth cases are really not problems for conciliationism. Why, as an anti-conciliationist, should I do that? It's for two reasons. First, I want to demonstrate how hard it is to use any case around here to show that a particular view on disagreement is wrong. Second, we get an interesting insight into the range of possible and indeed plausible versions of conciliationism by working through the cases carefully.

The apparent problem with **Jellybeans** is that it seems the rational reaction, for both [Ankita]{acronym-label="Ankita" acronym-form="singular+short"} and [Bojan]{acronym-label="Bojan" acronym-form="singular+short"}, is to increase their credence in a particular hypothesis that neither of them endorses, namely that there are 391 beans in the jar. But it isn't hard to see that this is a merely apparent problem. What credences should we attribute to [Ankita]{acronym-label="Ankita" acronym-form="singular+short"} when she announces her guess of 396? Presumably not that she has credence 1 that there are 396, and credence 0 in everything else. Given what we know about jars of jellybeans, and human visual capacities, it is best to interpret her as saying that the mode of her credal distribution over the competing hypotheses about the content of the jar is 396. But that distribution will presumably be fairly spread out, and indeed fairly flat around the peak. Similarly, [Bojan]{acronym-label="Bojan" acronym-form="singular+short"} will have a credal distribution that is spread out, and fairly flat around its peak of 386. If we average out those distributions, it could easily be that the peak of the new distribution is at 391. That happens, for instance, if each of [Ankita]{acronym-label="Ankita" acronym-form="singular+short"} and [Bojan]{acronym-label="Bojan" acronym-form="singular+short"}'s distributions are normal distribution, with a mean at the number they announce, and a standard deviation of 10.

Now there are hard questions about how we do, or even could, know that the number they utter means that they have just this credal distribution. But that's not particularly our problem here. The question is what the parties to the dispute should do given that we add to their evidence each other's credence distribution. Questions about how we could know what another person's credence distribution are, while fascinating, are not at issue here. This is a point worth keeping in mind as we work through the examples.

The EWV does rather badly on **Detectives**, but other versions of conciliationism do better. Assuming that the detectives are actually very good at their jobs, then neither would have formed the conclusion that the butler did it without a very good reason. If one of them believes this, and the other does not, the one who does not should believe that they've missed a reason. So they should largely defer to the other.

Note that the reasoning in the last paragraph is entirely symmetric, and doesn't directly make use of the fact that [Ankita]{acronym-label="Ankita" acronym-form="singular+short"} was right to infer that it was the butler. So it is reasoning that should be available to the conciliationist, even if it isn't available to the equal weight theorist. And there is a natural method for how to get the right result in **Detectives** in a conciliationist-friendly way. The method in question is one I'm taking from some work by Sarah @Moss2011.

Imagine that [Chika]{acronym-label="Chika" acronym-form="singular+short"} is not a detective, and has no particular expertise in solving murders. Moreover, she has very little information that bears directly on the case. What she does know is what [Ankita]{acronym-label="Ankita" acronym-form="singular+short"} and [Bojan]{acronym-label="Bojan" acronym-form="singular+short"} think; she knows that [Ankita]{acronym-label="Ankita" acronym-form="singular+short"} is confident the butler did it, while [Bojan]{acronym-label="Bojan" acronym-form="singular+short"} is uncertain. The reasoning from two paragraphs ago is available to [Chika]{acronym-label="Chika" acronym-form="singular+short"} too. She can think that [Ankita]{acronym-label="Ankita" acronym-form="singular+short"} wouldn't be so confident unless she had a very good reason, so she can infer that it is very likely that the butler did it.

One natural form of conciliationism says that the parties to a dispute face the same normative pressures as an outsider, like [Chika]{acronym-label="Chika" acronym-form="singular+short"}. Whatever is rational for [Chika]{acronym-label="Chika" acronym-form="singular+short"} to do given the knowledge just of the parties' credences, and their track records and backgrounds, is rational for the parties to the dispute to do. In general, that will mean conciliating, since in general [Chika]{acronym-label="Chika" acronym-form="singular+short"} should form a credence somewhere between the parties' credences. But that isn't always true. If [Ankita]{acronym-label="Ankita" acronym-form="singular+short"} and [Bojan]{acronym-label="Bojan" acronym-form="singular+short"} were both 90% confident that it was the butler, and that's all [Chika]{acronym-label="Chika" acronym-form="singular+short"} knows, then [Chika]{acronym-label="Chika" acronym-form="singular+short"} should give some credence to the possibility that [Ankita]{acronym-label="Ankita" acronym-form="singular+short"} and [Bojan]{acronym-label="Bojan" acronym-form="singular+short"} have noticed independent reasons for thinking it is the butler, and should have a credence in the butler's guilt slightly higher than 0.9. Nevertheless, the view that insiders to the dispute, like [Ankita]{acronym-label="Ankita" acronym-form="singular+short"} and [Bojan]{acronym-label="Bojan" acronym-form="singular+short"}, should end up in the same place as an outsider, like [Chika]{acronym-label="Chika" acronym-form="singular+short"}, who knows just the credences, seems to capture the idea at the heart of conciliationism.

I haven't said very much in general about how [Chika]{acronym-label="Chika" acronym-form="singular+short"} should reason about these cases. Ben @Levinstein2013, to whom I owe this example, thinks that [Chika]{acronym-label="Chika" acronym-form="singular+short"} should have a credence function that minimises the sum of [Ankita]{acronym-label="Ankita" acronym-form="singular+short"} and Bogan's expected inaccuracy. He persuasively argues that this method delivers the right result in a number of tricky cases.

We can also think about **Football** as an 'insider-outsider' problem. This case is really rather hard. I used to think it was a counterexample to any form of conciliationism, since conciliationists would have to say that each party would improperly regard the games as probabilistically dependent after learning about the disagreement. But I now think that both premises of this little argument (that conciliationism implies probabilistic dependence, and this is bad) are dubious. The case is just a hard case for everyone, and we can see that by thinking about it from [Chika]{acronym-label="Chika" acronym-form="singular+short"}'s perspective. (The next few paragraphs draw on work by Julia @Staffel2015.)

Assume that [Chika]{acronym-label="Chika" acronym-form="singular+short"} knows nothing about football (of any code), but does know about [Ankita]{acronym-label="Ankita" acronym-form="singular+short"} and [Bojan]{acronym-label="Bojan" acronym-form="singular+short"}'s predictive records and their credences concerning these games. And assume that she's an ideal aggregator. Finally assume, more or less for reductio, that [Chika]{acronym-label="Chika" acronym-form="singular+short"} aggregates probabilistic judgments by taking the linear average of them. (If that's right, the EWV and the 'insider-outsider' version of conciliationism coincide; if it isn't right, they don't.) The following table gives [Ankita]{acronym-label="Ankita" acronym-form="singular+short"}, [Bojan]{acronym-label="Bojan" acronym-form="singular+short"} and [Chika]{acronym-label="Chika" acronym-form="singular+short"}'s credences and conditional credences, assuming that [Chika]{acronym-label="Chika" acronym-form="singular+short"} does this. I'll use *p* for the home team wins the Australian match and *q* for the home team wins the English match.

::: tabulary
\@llllll\@ & $p$ & $q$ & $p \wedge q$ & $q \vert p$\

[Ankita]{acronym-label="Ankita" acronym-form="singular+short"} & 0.9 & 0.9 & 0.81 & 0.9\
[Bojan]{acronym-label="Bojan" acronym-form="singular+short"} & 0.1 & 0.1 & 0.01 & 0.1\
[Chika]{acronym-label="Chika" acronym-form="singular+short"} & 0.5 & 0.5 & 0.41 & 0.82\
:::

The key number is in the bottom right. Assuming that [Chika]{acronym-label="Chika" acronym-form="singular+short"} plans to update by conditionalisation, that means that although her credence in $q$ is now 0.5, if she learns $p$, it will rise to 0.82.

It has been argued, e.g. by @Loewer1985 and @JehleFitelson2009 that this is a mistake for the following reason. [Ankita]{acronym-label="Ankita" acronym-form="singular+short"} and [Bojan]{acronym-label="Bojan" acronym-form="singular+short"} both take the games to be probabilistically independent. So [Chika]{acronym-label="Chika" acronym-form="singular+short"}, who only has their credences to go on, should take them to be independent too. This argument doesn't work, for a reason Sarah @Moss2011 gives. The probabilities in this table are evidential probabilities. Even if the games are physically independent, it could be that the result of one gives [Chika]{acronym-label="Chika" acronym-form="singular+short"} evidence about the other. And that is what happens; if she learns $p$ she gets one more data point in favor of [Ankita]{acronym-label="Ankita" acronym-form="singular+short"}'s general accuracy in football-predicting, and against [Bojan]{acronym-label="Bojan" acronym-form="singular+short"}'s. So it is plausible that, for her, learning $p$ will raise her credence in $q$.

What isn't plausible, as Staffel notes, is that it could raise her credence that much. We can imagine, consistent with everything I've said so far, that [Chika]{acronym-label="Chika" acronym-form="singular+short"} has a lot of evidence about [Ankita]{acronym-label="Ankita" acronym-form="singular+short"} and [Bojan]{acronym-label="Bojan" acronym-form="singular+short"}'s track records. If *p* is true, then [Ankita]{acronym-label="Ankita" acronym-form="singular+short"} did better at forecasting *p* than [Bojan]{acronym-label="Bojan" acronym-form="singular+short"} did. So that's a reason to no longer given exactly equal weights to their forecasts. But for all I've said so far, this might mean that we have a data set consisting of 1001 times that [Ankita]{acronym-label="Ankita" acronym-form="singular+short"}'s forecast was better, and 1000 times that [Bojan]{acronym-label="Bojan" acronym-form="singular+short"}'s forecast was better. That does not look like a good reason to have a probability for *q* that is several times closer to [Ankita]{acronym-label="Ankita" acronym-form="singular+short"}'s forecast than it is to [Bojan]{acronym-label="Bojan" acronym-form="singular+short"}'s. More generally, just what number goes into the bottom right of the table should be sensitive to how much information we have about [Ankita]{acronym-label="Ankita" acronym-form="singular+short"} and [Bojan]{acronym-label="Bojan" acronym-form="singular+short"}, and not just to the balance between them. Arguably, having a conditional credence for *q* given *p* of 0.82 could be reasonable if [Chika]{acronym-label="Chika" acronym-form="singular+short"} knew almost nothing about [Ankita]{acronym-label="Ankita" acronym-form="singular+short"} and [Bojan]{acronym-label="Bojan" acronym-form="singular+short"} before the games were played. But it is not reasonable if she has a very substantial set of results where they have both done very well, and within that a substantial and balanced set of results in games where they have disagreed. But the Equal Weight View is insensitive to the quantity of information that [Chika]{acronym-label="Chika" acronym-form="singular+short"} has.

So the Equal Weight View is wrong about this case. It gives an implausible prediction, and it is insensitive to a factor that we know to be relevant. But the failure of Equal Weight does not mean that conciliationism fails. Saying just what values should go in the two right-most boxes in the bottom row is a very very hard question. But presumably it has at least one good answer. It doesn't seem like this is an epistemic dilemma for [Chika]{acronym-label="Chika" acronym-form="singular+short"}. So the conciliationist can still say something substantive about how [Ankita]{acronym-label="Ankita" acronym-form="singular+short"} and [Bojan]{acronym-label="Bojan" acronym-form="singular+short"} should react to learning about each other's forecast. The conciliationist, I suggest, should say that [Ankita]{acronym-label="Ankita" acronym-form="singular+short"} and [Bojan]{acronym-label="Bojan" acronym-form="singular+short"} should adopt whatever credences [Chika]{acronym-label="Chika" acronym-form="singular+short"} should adopt. This is a substantive and interesting claim. I think it is false, but I don't think it is obviously false. Ideally the conciliationist who says this would have something a little more substantive to say about what [Chika]{acronym-label="Chika" acronym-form="singular+short"}'s credence should be. But ideally any epistemologist who discusses the problem would have something a little more substantive to say about what [Chika]{acronym-label="Chika" acronym-form="singular+short"}'s credence should be, so this isn't a particular problem for conciliationism. Nor is there any reason to think that adopting conciliationism makes it harder to say what [Chika]{acronym-label="Chika" acronym-form="singular+short"} should do. So while this looks like a hard case, I don't think it can be used in an argument against conciliationism. Or, at least, it can't be so used just yet. Perhaps we could solve the problem of how [Chika]{acronym-label="Chika" acronym-form="singular+short"} should react, and then show it is implausible for [Ankita]{acronym-label="Ankita" acronym-form="singular+short"} and/or [Bojan]{acronym-label="Bojan" acronym-form="singular+short"} to react that way. But I'm not in any position to run that argument, because I don't know what [Chika]{acronym-label="Chika" acronym-form="singular+short"} should do.

What I'm saying here is very similar to what I said in the chapter 6 about the problem of inter-theoretic value comparisons. In both cases, normative internalism makes vivid a particularly hard epistemic problem. But the problem in question, in each case a problem about aggregation, was hard to start with, and isn't any harder in virtue of internalism. The fact that internalism makes the problem vivid is not in itself a reason to reject internalism.

On the other hand, **Doctors** is a problem for conciliationism, and looking at the problem through [Chika]{acronym-label="Chika" acronym-form="singular+short"}'s eyes doesn't help the conciliationist. If [Chika]{acronym-label="Chika" acronym-form="singular+short"} knows that [Bojan]{acronym-label="Bojan" acronym-form="singular+short"} is certain of a diagnosis, and that [Ankita]{acronym-label="Ankita" acronym-form="singular+short"} gives that credence a very high credence just short of belief, it seems prima facie plausible that [Chika]{acronym-label="Chika" acronym-form="singular+short"} should conclude from that that the diagnosis is correct. Unless we have some way to motivate a theory of judgment aggregation where the aggregate opinion is never more confident in a proposition than the weakest member, there must be some such cases where [Chika]{acronym-label="Chika" acronym-form="singular+short"} should believe the diagnosis is correct. But [Ankita]{acronym-label="Ankita" acronym-form="singular+short"} should not share this confidence. She should not find her doubts assuaged by [Bojan]{acronym-label="Bojan" acronym-form="singular+short"}'s not sharing them. So **Doctors** is a counterexample to the 'insider-outsider' version of conciliationism. And that's the only version that seems to get **Football** right. So no version of conciliationism can get both these cases right.

It is easy for the evidentialist to say what's going on in **Simple Arithmetic**. [Ankita]{acronym-label="Ankita" acronym-form="singular+short"} has maximally strong evidence that 2 plus 2 is in fact 4. That's not just because the conclusion is a logical truth. There are plenty of logical truths that we have insufficient evidence to believe, either because we don't know which logics validate them, or because we don't know what the correct logic is. Rather, it is because the inference from $x = 2 + 2$ to $x = 4$ is one that is immediately justified, without the need for further steps. [Bojan]{acronym-label="Bojan" acronym-form="singular+short"}'s disagreement can't dislodge that.

But how can the conciliationist handle the case? It doesn't seem very plausible to say that when an otherwise reasonable person says that two plus two is five, we're obliged to doubt that it is four. The usual response on behalf of conciliationists is to appeal to the notion of 'personal information'. The idea was first developed by Jennifer @Lackey2010, but I want to first mention the version of this defence put forward by David @Christensen2011. (Christensen is describing a scenario where the narrator plays the role of Ankita, and Bojan is their friend.)

> If such a bizarre situation were actually to occur, I think one would reasonably take it as extremely unlikely that one's friend (a) was feeling as clear-headed as oneself; (b) had no memories of recent drug-ingestions or psychotic episodes; and most importantly, (c) was being completely sincere. Thus, to use Lackey's term, one's personal information (that one was feeling clear, lacked memories suggesting mental malfunction, and was being sincere in one's assertion) would introduce a relevant asymmetry, and one could reasonably maintain one's belief.

The first thing to be said here is that (c), which is what Christensen adds to Lackey's original characterisation, is beside the point. The question is what [Ankita]{acronym-label="Ankita" acronym-form="singular+short"} should do given that [Bojan]{acronym-label="Bojan" acronym-form="singular+short"} believes that 2 plus 2 is 5. It's not the separate question of whether she should believe he believes that, given his utterance. So questions of sincerity are beside the point. Then the question is whether (a) and (b), which are the aspects of personal information that Lackey originally highlighted, are enough to help.

And it is hard to see how they could be. If the reason for discounting [Bojan]{acronym-label="Bojan" acronym-form="singular+short"}'s opinion rested on one's personal information, then the more information we get about [Bojan]{acronym-label="Bojan" acronym-form="singular+short"}, the more worried we should be. But I rather doubt that running a drug test on [Bojan]{acronym-label="Bojan" acronym-form="singular+short"}, to see whether (b) is a relevant difference between him and [Ankita]{acronym-label="Ankita" acronym-form="singular+short"}, should make any difference at all to [Ankita]{acronym-label="Ankita" acronym-form="singular+short"}'s confidence.

More generally, this explanation rests on an odd view about epistemic capacities. [Ankita]{acronym-label="Ankita" acronym-form="singular+short"}'s ability to do simple arithmetic is not, according to Christensen, a sufficient ground to believe that two plus two is four. But her ability to detect differences in capacities and aptitudes between two people, one of whom is herself, is enough of a ground. Speaking personally, I'm sure I'm much better at simple arithmetic than I am at doing such comparisons. Indeed, my abilities to make such comparisons intuitively are so weak that I could only possibly do them by careful statistical analysis, and that would require, among other things, being able to add two plus two. In other words, if I can't know what two and two is, I can't process the evidence that might tell for or against the abilities of one party or another. So the conciliationist doesn't have a good explanation of how we can hold on to knowledge in these simple cases.

Simple arithmetic cases are important not just because they raise problems for conciliationism, but because they tell us something about what's at issue in debates about disagreement. Consider this argument by David Enoch for thinking that in debates about disagreement as such, we should treat the parties to the disagreement symmetrically.

> Second, our question, as you will recall, was the focused one about the epistemic significance of the disagreement itself. The question was not that of the overall epistemic evaluation of the beliefs of the disagreeing peers. Kelly is right, of course, that in terms of overall epistemic evaluation (and barring epistemic permissiveness) no symmetry holds. But from this it does not follow that the significance of the disagreement itself is likewise asymmetrical. Indeed, it is here that the symmetry is so compelling. The disagreement itself, after all, plays a role similar to that of an omniscient referee who tells two thinkers 'one of you is mistaken with regard to p'. It is very hard to believe that the epistemically responsible way to respond to such a referee differs between the two parties. And so it is very hard to believe that the epistemic significance of the disagreement itself is asymmetrical in anything like the way Kelly suggests. Â [@Enoch2010 657]

Well, consider the case when *p* is the proposition that two plus two is four, and [Ankita]{acronym-label="Ankita" acronym-form="singular+short"} is the party who believes *p*, while [Bojan]{acronym-label="Bojan" acronym-form="singular+short"} rejects it. Having an omniscient referee tell the parties that one of them is mistaken should produce asymmetric responses in the two parties. Now maybe there are only a small class of cases where this is the case, and what Enoch says is right in the majority of cases. But we can't argue for that on perfectly general grounds about the nature of disagreement, because it fails in extreme cases like **Simple Arithmetic**. The argument that it holds in normal cases needs a distinct defence.

### The Evidence Aggregation Approach {#theevidenceaggregationapproach}

Having gone over how conciliationism handles, or doesn't handle, the cases, let's compare it to how an evidence aggregation view handles them. We'll look at them in reverse order, because the earlier cases are harder for the view.

Evidence Aggregation gets **Simple Arithmetic** right. [Ankita]{acronym-label="Ankita" acronym-form="singular+short"} has clear and compelling evidence that two plus two is four. The fact that two plus two is four is part of her evidence, and when the conclusion is part of one's evidence, that is maximally strong support. Learning that something has gone badly wrong with [Bojan]{acronym-label="Bojan" acronym-form="singular+short"}'s arithmetic competence or performance does not make her lose this evidence.

It also gets **Doctors** right, by treating the case as parallel to the case of [Roshni]{acronym-label="Roshni" acronym-form="singular+short"} from chapter 8. When [Ankita]{acronym-label="Ankita" acronym-form="singular+short"} learns that [Bojan]{acronym-label="Bojan" acronym-form="singular+short"} is very confident that the patient has disease A, that isn't yet evidence that [Bojan]{acronym-label="Bojan" acronym-form="singular+short"} has stronger evidence that the patient has disease A. It might mean simply that [Bojan]{acronym-label="Bojan" acronym-form="singular+short"} hasn't considered the possibility of B, or that he has overly hastily dismissed it. And indeed, that's just what has happened. Until [Ankita]{acronym-label="Ankita" acronym-form="singular+short"} learns why [Bojan]{acronym-label="Bojan" acronym-form="singular+short"} has the credences he does, she can reasonably, if provisionally, keep her current credences. After all, there may not be any new evidence in favour of diagnosing A. And when she does learn why [Bojan]{acronym-label="Bojan" acronym-form="singular+short"} has these credences, she should stick to her initial view. That's not because it was her view, but rather because it was the view best supported by the current evidence.

From this perspective, **Detectives** is just like **Doctors**. When [Ankita]{acronym-label="Ankita" acronym-form="singular+short"} hears [Bojan]{acronym-label="Bojan" acronym-form="singular+short"}'s credence, it is reasonable for her to infer that she has some evidence that [Bojan]{acronym-label="Bojan" acronym-form="singular+short"} lacks. This evidence need not be public evidence; it might be more like the kind of evidence a mathematician gets when working through a proof. But it is reasonable for her to infer, given just the facts about their conflicting credences, that [Bojan]{acronym-label="Bojan" acronym-form="singular+short"} has simply missed the reason that it must have been the butler. So she doesn't have new evidence that it wasn't the butler, so her credence shouldn't move.

The last two cases are not like most everyday cases of disagreement. The usual situation, when another person disagrees with us, is that they have evidence we lack. Or, at least, it is usually the case that one should give the possibility that the other person has extra evidence substantial credence. That's why it is usually the case that one should conciliate. The default view is that the other probably has good evidence we lack, and that is reason to move one's attitude towards the other's. It is very hard to say in general when one should abandon this default stance. Indeed, it is very hard to even say whether the 'should' in question is moral or epistemic. It feels like an epistemic question at first, but perhaps moral considerations to do with humility, respect and friendship are also relevant factors. But we shouldn't let the fact that it is hard to give a general theory here prevent us from saying something about some cases. And we should say that **Doctors** and **Detectives** are among the (presumably rare) cases where one party, in this case [Ankita]{acronym-label="Ankita" acronym-form="singular+short"}, is warranted in holding firm to their beliefs.

It's a little harder to know what the evidence aggregation view should say about **Football**. The case as presented didn't include much detail about how [Ankita]{acronym-label="Ankita" acronym-form="singular+short"} or [Bojan]{acronym-label="Bojan" acronym-form="singular+short"} came to their conclusions. If I was in one or other of their positions, I would likely infer that the other had picked up on some reason I missed, but also that they had probably missed some reason I'd seen. So I would be tempted to conciliate, because this is a case where the conflicting credences really are useful evidence that there is (private) evidence that would motivate a change of view.

While the evidence aggregation view doesn't have a firm theoretical recommendation, it does have a firm practical recommendation. Each party should ask the other why they have the view that they do. Assuming it is possible to ask the other this question, and the disagreement is about something significant enough to make it worth the bother, this is pretty much always the practical recommendation. As far as I can tell, intuition and folk wisdom agree with the evidence aggregation view on this point. And it is hard to see how rival views of disagreement could motivate such a strong recommendation to ask the other person "Why do you think that?". After all, those rival views already say what the disagreeing parties should do, and the answer is not sensitive to why the other person has the views they do. If it turns out that all the reasons [Bojan]{acronym-label="Bojan" acronym-form="singular+short"} can offer are ones that [Ankita]{acronym-label="Ankita" acronym-form="singular+short"} had already properly weighed, she should revert to her initial credence. But probably he has thought of something she missed, and probably she has thought of something he missed, and adding those reasons together will bring their views closer together.

The conciliationist thinks that [Ankita]{acronym-label="Ankita" acronym-form="singular+short"} and [Bojan]{acronym-label="Bojan" acronym-form="singular+short"} should aggregate the outputs of their deliberation. The evidence aggregation view says that they should aggregate the inputs to their deliberation. If the only evidence they have as to those inputs is the outputs, then they should use the outputs to make reasonable guesses as to the nature of the inputs, and aggregate them. But this is very much a second-best solution; the best thing to do is to find out exactly what the inputs were. That is exactly what good interlocutors do. The primary reaction to hearing that someone has a very different view to one's own shouldn't be to jump to a new credence, it should be to find out why they have the conflicting view.

In **Football** it was plausible that the two parties would have different evidence; in **Jellybeans** it is just about certain. [Ankita]{acronym-label="Ankita" acronym-form="singular+short"} and [Bojan]{acronym-label="Bojan" acronym-form="singular+short"} will have had different appearances when they looked at the jar, they will have seen it from different angles, they will be bringing different histories with these kinds of estimation tasks to bear on the subject, and so on. In **Football** it was likely that the parties will have different views about the question because they have different evidence; in **Jellybeans** it is practically certain. So the evidence aggregation view says, along with intuition, that this is a case where they should conciliate. It has a simpler explanation as to why their credence in hypotheses like 391 should increase than the conciliationist offers, but both parties get to the right result for plausible reasons.

The case that's left is **Arithmetic**. This case seems to be the one that moves people to reject evidentialist views. Cases like **Arithmetic** are used as a primary motivation for conciliationist views of disagreement in, for example [@Bogardus2009; @Matheson2009; @Carey2011; @Kraft2012; @Lee2013; @Vavova2014; @Worsnip2014; @Mogensen2015] and @Ebeling2017. In many of these papers, intuitions about cases like **Arithmetic** are the sole motivation offered for conciliationism, or are offered as a sufficient reason to believe conciliationism. Worship says that cases like **Arithmetic** show that views like evidence aggregation are "not even slightly plausible" Â [@Worsnip2014 6]. Although cases like **Arithmetic** are commonly used by conciliationist philosophers, none of them ever say just what arithmetic problem is under dispute in their version of the case. The usual methodology s to describe the kind of arithmetic problem at issue, then present the conflicting answers that the peers give. I'm using a more concrete example because my analysis turns on being able to talk about the particular arithmetic problem under discussion.

The first thing to note about **Arithmetic** as I've presented it is that it leaves out some details about how [Ankita]{acronym-label="Ankita" acronym-form="singular+short"} came to her conclusion. (Remember that the versions offered in the literature are even lighter on details.) So I'll go over two variants of the case. The variations will be important enough that I'll introduce new characters to participate in them. Each character has the same prior relationship to [Bojan]{acronym-label="Bojan" acronym-form="singular+short"} as [Ankita]{acronym-label="Ankita" acronym-form="singular+short"} does.

[Deanna]{acronym-label="Deanna" acronym-form="singular+short"} thinks to herself that 22 times 18 is 20 times 18 plus 2 times 18, so it is 360 plus 36, so it is 396. That strikes her as conclusive, so she announces that it is 396. [Bojan]{acronym-label="Bojan" acronym-form="singular+short"} then says he thinks 22 times 18 is 386. So [Deanna]{acronym-label="Deanna" acronym-form="singular+short"} decides to double check. She thinks that 22 times 18 is 20 plus 2 times 20 minus 2, so it is 20 squared minus 2 squared, so it is 400 minus 4, so it is 396. She now feels confident sticking to her original verdict.

[Efrosyni]{acronym-label="Efrosyni" acronym-form="singular+short"} thinks to herself that 22 times 18 is 20 times 18 plus 2 times 18, so it is 360 plus 36, so it is 396. But she feels she should double check. So she thinks that 22 times 18 is 20 plus 2 times 20 minus 2, so it is 20 squared minus 2 squared, so it is 400 minus 4, so it is 396. She now feels confident sticking to her original verdict. She then hears [Bojan]{acronym-label="Bojan" acronym-form="singular+short"} say that he thinks 22 times 18 is 386.

Whatever one's view about how confident [Deanna]{acronym-label="Deanna" acronym-form="singular+short"} and [Efrosyni]{acronym-label="Efrosyni" acronym-form="singular+short"} should end up being in their verdict that 22 times 18 is 396, they should be equally confident. After all, they have exactly the same evidence for and against it: two calculations that point to 396, and [Bojan]{acronym-label="Bojan" acronym-form="singular+short"}'s announcement of 386. But no form of conciliationism can deliver that result. After all, conciliationism requires that a form of independence hold.[^56] The reasoning that led to one's disagreeing views cannot be used to 're-check' that those views are correct. So once [Efrosyni]{acronym-label="Efrosyni" acronym-form="singular+short"} hears [Bojan]{acronym-label="Bojan" acronym-form="singular+short"}'s disagreement, she can't rely on either of the two routes to the conclusion that she used. But [Deanna]{acronym-label="Deanna" acronym-form="singular+short"} is free to use the second calculation she did as independent evidence that [Bojan]{acronym-label="Bojan" acronym-form="singular+short"} is wrong. So the standard conciliationist has to say, falsely, that [Deanna]{acronym-label="Deanna" acronym-form="singular+short"} and [Efrosyni]{acronym-label="Efrosyni" acronym-form="singular+short"} should have different credences in the proposition that 22 times 18 is 396, or, equally falsely, that [Deanna]{acronym-label="Deanna" acronym-form="singular+short"} doesn't get any extra reason to believe that 22 times 18 is 396 when she does the double-check.

[^56]: The discussion of Lord's work above wasn't meant to undermine that claim. The result of that discussion was that conciliationism is equivalent to the strongest plausible independence principle, so that principle can't be used to independently defend conciliationism. That's all consistent with saying that conciliationism requires an independence principle.

The evidence aggregation theory suggests a better analysis of the case. Consider the state of mind that [Efrosyni]{acronym-label="Efrosyni" acronym-form="singular+short"} was in when she thought, "I'd better double check this." She actually had conclusive, entailing, evidence that 22 times 18 was 396. Of course, everyone has just the same evidence at all times, so perhaps that isn't so important. What is more important is that after doing the first calculation she had evidence that a reasonable person could, other things being equal, base a belief on. [Deanna]{acronym-label="Deanna" acronym-form="singular+short"} was not unreasonable when she made her announcement, but yet [Efrosyni]{acronym-label="Efrosyni" acronym-form="singular+short"} in a similar position thought she should get more information. How should we explain that? We could treat this as a case where a kind of permissivism is right; [Deanna]{acronym-label="Deanna" acronym-form="singular+short"} was being reasonable in ending inquiry, and [Efrosyni]{acronym-label="Efrosyni" acronym-form="singular+short"} was reasonable in not ending it, despite their being in identical positions. But it is better to treat these cases as not quite identical. [Efrosyni]{acronym-label="Efrosyni" acronym-form="singular+short"} had a nagging doubt, which [Deanna]{acronym-label="Deanna" acronym-form="singular+short"} did not have. Perhaps that is the difference; the calculations they had both done are sufficient to end inquiry in the absence of positive reasons to extend inquiry. A nagging doubt like [Efrosyni]{acronym-label="Efrosyni" acronym-form="singular+short"} had is reasonable, and if one has such a doubt, one has a reason to address it. But it is also reasonable to not have such a doubt.

If that story is right, then the evidence aggregation theorist can easily say what's going on in **Arithmetic**. If [Ankita]{acronym-label="Ankita" acronym-form="singular+short"} is like [Deanna]{acronym-label="Deanna" acronym-form="singular+short"}, then the exchange with [Bojan]{acronym-label="Bojan" acronym-form="singular+short"} provides a good reason to recheck her calculations. The idea here is that the evidence [Ankita]{acronym-label="Ankita" acronym-form="singular+short"} acquired by doing the calculation is good enough to close inquiry, but only in the absence of positive reason to keep the inquiry going. That reason could be internal, a nagging doubt, or it could be external, such as peer disagreement. So it is fine for an evidential aggregation theorist to say that [Deanna]{acronym-label="Deanna" acronym-form="singular+short"} (or Ankita if she is like her) should not necessarily conciliate, but should re-open inquiry. If [Ankita]{acronym-label="Ankita" acronym-form="singular+short"} is like [Efrosyni]{acronym-label="Efrosyni" acronym-form="singular+short"}, then the evidence aggregation theorist can't make that move. But she shouldn't want to. After all, [Efrosyni]{acronym-label="Efrosyni" acronym-form="singular+short"} has just as good reason to believe 22 times 18 is 396 as [Deanna]{acronym-label="Deanna" acronym-form="singular+short"} did after rechecking. So she has excellent reason to believe that 22 times 18 is 396. So she should keep believing it. It is much more plausible that [Bojan]{acronym-label="Bojan" acronym-form="singular+short"} made a rare mistake than that she made distinct mistakes on distinct calculations that ended up at the same point.

As stated, **Arithmetic** is not detailed enough for us to know what [Ankita]{acronym-label="Ankita" acronym-form="singular+short"} should do or believe. The advantage of the evidence aggregation theory is that it can explain why the missing details matter. Probably the most intuitive way to fill in the details in the original case is to make [Ankita]{acronym-label="Ankita" acronym-form="singular+short"} like [Deanna]{acronym-label="Deanna" acronym-form="singular+short"}; she does the calculation once, and easily could have a reason to double-check, but does not do this. In this case we can say [Bojan]{acronym-label="Bojan" acronym-form="singular+short"}'s disagreement should prompt [Ankita]{acronym-label="Ankita" acronym-form="singular+short"} to double-check. So we can explain the case that was meant to be the best case for conciliationism. And, if one thinks the differences between [Deanna]{acronym-label="Deanna" acronym-form="singular+short"}'s case and Efrosnyi's case needs to be explained, the evidence aggregation theory can explain them even more smoothly than the conciliationist can. So there is no argument from intuitions about cases for conciliationism, and if any side is favoured by considerations about cases, it is the evidence aggregation theory.
