<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.525">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Normative Externalism - 3&nbsp; Against Symmetry</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./dilemma.html" rel="next">
<link href="./internalism.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="site_libs/bootstrap/bootstrap-dark.min.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<link rel="stylesheet" href="https://use.typekit.net/uzz2drx.css">


</head>

<body class="nav-sidebar floating nav-fixed slimcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="./index.html">
    <span class="navbar-title">Brian Weatherson</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-papers" role="button" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Papers</span>
    </a>
    <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="nav-menu-papers">    
        <li>
    <a class="dropdown-item" href="https://brian.weatherson.org/quarto/papers.html">
 <span class="dropdown-text">All Papers</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://brian.weatherson.org/quarto/epist.html">
 <span class="dropdown-text">Epistemology</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://brian.weatherson.org/quarto/gdt.html">
 <span class="dropdown-text">Games and Decisions</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://brian.weatherson.org/quarto/books.html">
 <span class="dropdown-text">On Books</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item dropdown ">
    <a class="nav-link dropdown-toggle" href="#" id="nav-menu-books" role="button" data-bs-toggle="dropdown" aria-expanded="false">
 <span class="menu-text">Books</span>
    </a>
    <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="nav-menu-books">    
        <li>
    <a class="dropdown-item" href="https://brian.weatherson.org/ne/">
 <span class="dropdown-text">Normative Externalism</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://lda.weatherson.org/">
 <span class="dropdown-text">A History of Philosophy Journals</span></a>
  </li>  
        <li>
    <a class="dropdown-item" href="https://brian.weatherson.org/kahis/">
 <span class="dropdown-text">Knowledge: A Human Interest Story</span></a>
  </li>  
    </ul>
  </li>
  <li class="nav-item">
    <a class="nav-link" href="https://brian.weatherson.org/quarto/cv.html"> 
<span class="menu-text">CV</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://brian.weatherson.org/quarto/teaching.html"> 
<span class="menu-text">Teaching Notes</span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
          <div class="quarto-navbar-tools">
    <div class="dropdown">
      <a href="" title="Download" id="quarto-navigation-tool-dropdown-0" class="quarto-navigation-tool dropdown-toggle px-1" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download"><i class="bi bi-download"></i></a>
      <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="quarto-navigation-tool-dropdown-0">
          <li>
            <a class="dropdown-item quarto-navbar-tools-item" href="./Normative-Externalism.pdf">
              <i class="bi bi-bi-file-pdf pe-1"></i>
            Download PDF
            </a>
          </li>
          <li>
            <a class="dropdown-item quarto-navbar-tools-item" href="./Normative-Externalism.epub">
              <i class="bi bi-bi-journal pe-1"></i>
            Download ePub
            </a>
          </li>
          <li>
            <a class="dropdown-item quarto-navbar-tools-item" href="./Normative-Externalism.docx">
              <i class="bi bi-bi-file-word pe-1"></i>
            Download Docx
            </a>
          </li>
      </ul>
    </div>
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./internalism.html">Ethics</a></li><li class="breadcrumb-item"><a href="./symmetry.html"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Against Symmetry</span></a></li></ol></nav>
        <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./introduction.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction</span></span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">
 <span class="menu-text">Ethics</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./internalism.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">All About Internalism</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./symmetry.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Against Symmetry</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./dilemma.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">A Dilemma for Internalism</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./blame.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Blame and Moral Ignorance</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./double.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Double Standards</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true">
 <span class="menu-text">Epistemology</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./level.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Level-Crossing Principles</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./higher.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Higher-Order Evidence</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./circles.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Circles, Epistemic and Benign</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./akrasia.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Akrasia</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./screening.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Screening and Regresses</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./disagreement.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Disagreement</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./epilogue.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Epilogue</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar"><div class="quarto-margin-header"><div class="margin-header-item">
<p>&nbsp;</p>
</div></div>
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">In this chapter:</h2>
   
  <ul>
  <li><a href="#guiltandshame" id="toc-guiltandshame" class="nav-link active" data-scroll-target="#guiltandshame"><span class="header-section-number">3.1</span> Guilt and Shame</a></li>
  <li><a href="#jacksoncases" id="toc-jacksoncases" class="nav-link" data-scroll-target="#jacksoncases"><span class="header-section-number">3.2</span> Jackson Cases</a>
  <ul class="collapse">
  <li><a href="#caseone-abortion" id="toc-caseone-abortion" class="nav-link" data-scroll-target="#caseone-abortion"><span class="header-section-number">3.2.1</span> Case One - Abortion</a></li>
  <li><a href="#casetwo-theft" id="toc-casetwo-theft" class="nav-link" data-scroll-target="#casetwo-theft"><span class="header-section-number">3.2.2</span> Case Two - Theft</a></li>
  <li><a href="#anasymmetry" id="toc-anasymmetry" class="nav-link" data-scroll-target="#anasymmetry"><span class="header-section-number">3.2.3</span> An Asymmetry</a></li>
  </ul></li>
  <li><a href="#motivation" id="toc-motivation" class="nav-link" data-scroll-target="#motivation"><span class="header-section-number">3.3</span> Motivation</a></li>
  <li><a href="#welfareandmotivation" id="toc-welfareandmotivation" class="nav-link" data-scroll-target="#welfareandmotivation"><span class="header-section-number">3.4</span> Welfare and Motivation</a></li>
  <li><a href="#motivationvirtuesandvices" id="toc-motivationvirtuesandvices" class="nav-link" data-scroll-target="#motivationvirtuesandvices"><span class="header-section-number">3.5</span> Motivation, Virtues and Vices</a></li>
  <li><a href="#theweakmotivationprinciplewmp" id="toc-theweakmotivationprinciplewmp" class="nav-link" data-scroll-target="#theweakmotivationprinciplewmp"><span class="header-section-number">3.6</span> The Weak Motivation Principle (WMP)</a>
  <ul class="collapse">
  <li><a href="#equilibrium" id="toc-equilibrium" class="nav-link" data-scroll-target="#equilibrium"><span class="header-section-number">3.6.1</span> Equilibrium</a></li>
  <li><a href="#whyengageinmoralreflection" id="toc-whyengageinmoralreflection" class="nav-link" data-scroll-target="#whyengageinmoralreflection"><span class="header-section-number">3.6.2</span> Why Engage in Moral Reflection?</a></li>
  <li><a href="#thewmpandtwokindsofmotivationgaps" id="toc-thewmpandtwokindsofmotivationgaps" class="nav-link" data-scroll-target="#thewmpandtwokindsofmotivationgaps"><span class="header-section-number">3.6.3</span> The WMP and Two Kinds of Motivation Gaps</a></li>
  <li><a href="#against-symmetry" id="toc-against-symmetry" class="nav-link" data-scroll-target="#against-symmetry"><span class="header-section-number">3.6.4</span> Against Symmetry</a></li>
  </ul></li>
  <li><a href="#thestrongmotivationprinciplesmp" id="toc-thestrongmotivationprinciplesmp" class="nav-link" data-scroll-target="#thestrongmotivationprinciplesmp"><span class="header-section-number">3.7</span> The Strong Motivation Principle (SMP)</a>
  <ul class="collapse">
  <li><a href="#howtoexplainreflection" id="toc-howtoexplainreflection" class="nav-link" data-scroll-target="#howtoexplainreflection"><span class="header-section-number">3.7.1</span> How to Explain Reflection</a></li>
  <li><a href="#againstmotivationbymorality" id="toc-againstmotivationbymorality" class="nav-link" data-scroll-target="#againstmotivationbymorality"><span class="header-section-number">3.7.2</span> Against Motivation by Morality</a></li>
  <li><a href="#backtosymmetryandmoraluncertainty" id="toc-backtosymmetryandmoraluncertainty" class="nav-link" data-scroll-target="#backtosymmetryandmoraluncertainty"><span class="header-section-number">3.7.3</span> Back to Symmetry, and Moral Uncertainty</a></li>
  </ul></li>
  <li><a href="#motivationthroughthickandthin" id="toc-motivationthroughthickandthin" class="nav-link" data-scroll-target="#motivationthroughthickandthin"><span class="header-section-number">3.8</span> Motivation Through Thick and Thin</a></li>
  <li><a href="#mollersexample" id="toc-mollersexample" class="nav-link" data-scroll-target="#mollersexample"><span class="header-section-number">3.9</span> Moller’s Example</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content page-columns page-full" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./internalism.html">Ethics</a></li><li class="breadcrumb-item"><a href="./symmetry.html"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Against Symmetry</span></a></li></ol></nav>
<div class="quarto-title">
<h1 class="title"><span id="againstsymmetry" class="quarto-section-identifier"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Against Symmetry</span></span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<p>In the previous chapter, I suggested that one of the key motivations for normative internalism that it allows for a symmetry between the way we treat factual uncertainty and ignorance, and the way we might think about treating normative uncertainty and ignorance. Some writers have found it so obvious that these cases should be treated symmetrically that they have simply incorporated this symmetric treatment into their theory without arguing for it. Those who have argued for it have usually found the symmetry very intuitive.</p>
<p>In this chapter, I’ll try to undermine that intuitive symmetry. The first three sections will introduce three considerations that undermine the idea that the factual and normative uncertainty should be treated symmetrically, and the last three sections deal with some complications that the first three sections introduce. In the next chapter, I’ll argue that even if we found the symmetry intuitive, we should ultimately reject it, because there is no way to incorporate it into a theory that is even remotely plausible. That is, I’ll argue that any internalist theory that can handle even very simple cases has to reject the symmetry thesis, and so cannot be motivated by symmetry considerations.</p>
<section id="guiltandshame" class="level2" data-number="3.1">
<h2 data-number="3.1" class="anchored" data-anchor-id="guiltandshame"><span class="header-section-number">3.1</span> Guilt and Shame</h2>
<p>If normative and factual uncertainty have the same normative implications, then we should feel similarly about our own past actions that were done due to factual ignorance, and those that were done due to moral ignorance. But this doesn’t seem to be how we do, or should, feel. We can see this by comparing a pair of cases. The second of the cases is a minor modification of a case Elizabeth <span class="citation" data-cites="Harman2014">Harman (<a href="references.html#ref-Harman2014" role="doc-biblioref">2015</a>)</span> uses in making a similar argument to the one I’m presenting in this section.</p>
<p><span data-acronym-label="Prasad" data-acronym-form="singular+short">Prasad</span> is a father of two children, an older daughter and a younger son. In the division of parental labour in his house, teaching the children to read is primarily his responsibility. He takes this very seriously, and reads the latest studies on which techniques are most effective at teaching reading. He doesn’t have a strong enough background in statistics to be able to evaluate many of the papers he reads, but he can tell what techniques are being approved by the leading figures in the field, and those are the techniques he uses in teaching his children to read.</p>
<p>Unfortunately, the relevant science around here moves slowly and fitfully. The technique that <span data-acronym-label="Prasad" data-acronym-form="singular+short">Prasad</span> followed when his daughter was learning to read was soon shown to be mostly ineffective. It was better than not spending time on reading, but wasn’t any better than unstructured reading time. By the time his son was learning to read, educational science had advanced substantially, and <span data-acronym-label="Prasad" data-acronym-form="singular+short">Prasad</span> was able to use a technique that led to his son learning to read relatively quickly. This gave his son an advantage that persisted throughout his schooling, and led to him being admitted to an exclusive college, and subsequently earning much more than he would have without the benefit of early reading. <span data-acronym-label="Prasad" data-acronym-form="singular+short">Prasad</span>’s daughter did well at school, as you’d expect with this level of parental attention, but would have been even better off had been trained to read the way her brother was trained.</p>
<p><span data-acronym-label="Archie" data-acronym-form="singular+short">Archie</span> is a 1950s father who, like many other 1950s fathers, thinks it is more important to look after his son’s interests than his daughter’s. So while he puts aside a substantial college fund for his son, he puts aside less for his daughter. As a consequence, his daughter cannot afford to go to as good a college as his son goes to, and subsequently is materially less well off throughout her life than <span data-acronym-label="Archie" data-acronym-form="singular+short">Archie</span>’s son.</p>
<p><span data-acronym-label="Prasad" data-acronym-form="singular+short">Prasad</span> was mistaken about a matter of fact; about which techniques are most effective at teaching a child to read. <span data-acronym-label="Archie" data-acronym-form="singular+short">Archie</span> was mistaken about a moral matter; whether one should treat one’s sons and daughters equally. Now consider what happens when both see the error of their ways. <span data-acronym-label="Prasad" data-acronym-form="singular+short">Prasad</span> may feel bad for his son, but there is no need for any kind of self-reproach. It’s hard to imagine he would feel ashamed for what he did. And there’s no obligation for him to feel guilty, though it’s easier to imagine him feeling guilty than feeling ashamed. <span data-acronym-label="Archie" data-acronym-form="singular+short">Archie</span>, on the other hand, should feel both ashamed and guilty. And it’s natural that a father who realised too late that he had been guilty of this kind of sexism would in fact feel the shame and guilt he should feel. The fact that his earlier sexist attitudes were widely shared, and firmly and sincerely held, simply seems irrelevant here.</p>
<p>If the symmetry thesis were correct, there should not be any difference in <span data-acronym-label="Prasad" data-acronym-form="singular+short">Prasad</span> and <span data-acronym-label="Archie" data-acronym-form="singular+short">Archie</span>’s attitudes. Both of them behaved in just the way we should expect, given their factual and normative beliefs. And both of them had beliefs that were sincere, and widely shared in their community. But there is still a difference between the two of them, as revealed by the emotional reactions they both do and should have.</p>
</section>
<section id="jacksoncases" class="level2" data-number="3.2">
<h2 data-number="3.2" class="anchored" data-anchor-id="jacksoncases"><span class="header-section-number">3.2</span> Jackson Cases</h2>
<p>As <span class="citation" data-cites="Zimmerman2008">Zimmerman (<a href="references.html#ref-Zimmerman2008" role="doc-biblioref">2008</a>)</span> argues, the kinds of cases discussed by <span class="citation" data-cites="Jackson1991">Jackson (<a href="references.html#ref-Jackson1991" role="doc-biblioref">1991</a>)</span> are important for seeing how factual uncertainty is normatively significant. It isn’t just that when an agent doesn’t know what is true, and so doesn’t know which action produces the best outcome, she thereby doesn’t know what is right to do. In some cases of decision making under uncertainty, the thing that is clearly right to do is the one thing she knows will not produce the best outcome. Gambling the charitable donation on the roulette wheel is wrong, although the best outcome would be to gamble on the number that will actually come up. In the previous chapter we dubbed cases like this, where the right thing to do is something one knows will not produce the best outcome, Jackson cases. Jackson cases are ubiquitous when making decisions under factual uncertainty.</p>
<p>If we should treat factual uncertainty and moral uncertainty symmetrically, then Jackson cases for moral uncertainty would be easy to find. But it is far from clear that there are any such cases. That is, it is far from clear that there are cases where we want to say anything positive about an agent who hedges their moral bets.</p>
<p>A simple way to generate Jackson cases is to set up a decision problem with the following features:</p>
<ul>
<li>There are three option: A, B and C;</li>
<li>There are two epistemic possibilities, <em>w</em><sub>1</sub> and <em>w</em><sub>2</sub>, the agent knows that precisely one of them is realised, and the she reasonably thinks each is fairly likely.</li>
<li>In <em>w</em><sub>1</sub>, A is optimal, C is a little worse, and B is a catastrophe.</li>
<li>In <em>w</em><sub>2</sub>, B is optimal, C is a little worse, and A is a catastrophe.</li>
</ul>
<p>If the agent’s uncertainty about <em>w</em><sub>1</sub> or <em>w</em><sub>2</sub> is grounded in a straightforwardly factual uncertainty, it seems the agent should do C. Just what that ‘should’ amounts to is up for debate, but there is something awful about doing A or B - even if it produces the optimal outcome.</p>
<p>What happens, though, if <em>w</em><sub>1</sub> and <em>w</em><sub>2</sub> are factually alike, but differ in the correct moral theory? (As has come up a few times, it is unlikely that both <em>w</em><sub>1</sub> and <em>w</em><sub>2</sub> will be <em>possible</em> worlds in this case, but I don’t think this matters for current purposes.) Well, let’s look at some cases and see.</p>
<section id="caseone-abortion" class="level3" data-number="3.2.1">
<h3 data-number="3.2.1" class="anchored" data-anchor-id="caseone-abortion"><span class="header-section-number">3.2.1</span> Case One - Abortion</h3>
<p><span data-acronym-label="Marilou" data-acronym-form="singular+short">Marilou</span> is 12 weeks pregnant, and lives in a state where abortion is criminalised and, on occasion, heavily punished. <span data-acronym-label="Marilou" data-acronym-form="singular+short">Marilou</span> deeply desires to have an abortion. <span data-acronym-label="Marilou" data-acronym-form="singular+short">Marilou</span> is reasonably well off, and as is the norm in states that criminalise abortion, reasonably well off people are able to obtain abortions with a little assistance. <span data-acronym-label="Marilou" data-acronym-form="singular+short">Marilou</span> asks her friend <span data-acronym-label="Shila" data-acronym-form="singular+short">Shila</span> for such assistance. <span data-acronym-label="Shila" data-acronym-form="singular+short">Shila</span> now has to make a choice. <span data-acronym-label="Shila" data-acronym-form="singular+short">Shila</span> is torn between two moral views about abortions 12 weeks into pregnancy. According to one, the potential that the fetus has to develop into a fully functioning human being means that aborting it is the moral equivalent of murder. According to another, the fetus has little or no moral standing on its own, the importance of <span data-acronym-label="Marilou" data-acronym-form="singular+short">Marilou</span>’s autonomy means that <span data-acronym-label="Marilou" data-acronym-form="singular+short">Marilou</span> should be able to get an abortion, and her friends should assist her in avoiding the oppressive laws against abortion. <span data-acronym-label="Shila" data-acronym-form="singular+short">Shila</span> now has three choices.</p>
<ol type="1">
<li>Assist <span data-acronym-label="Marilou" data-acronym-form="singular+short">Marilou</span> in getting the abortion, which is either a way of respecting <span data-acronym-label="Marilou" data-acronym-form="singular+short">Marilou</span>’s autonomy and honouring their friendship, or is a way of being an accomplice to murder.</li>
<li>Report <span data-acronym-label="Marilou" data-acronym-form="singular+short">Marilou</span>’s plans to the authorities, which is either horribly disrespectful to <span data-acronym-label="Marilou" data-acronym-form="singular+short">Marilou</span> and a gross violation of their friendship, or bravely preventing a murder. (Assume that Shila knows that although the authorities aren’t maximally vigilant about preventing abortions, they are obliged to act on incriminating information, so this tip-off will lead to Marilou’s imprisonment.)</li>
<li>Do nothing, suspecting that without her help, <span data-acronym-label="Marilou" data-acronym-form="singular+short">Marilou</span> will carry the child to term and quietly adopt it out.</li>
</ol>
<p>In either <em>w</em><sub>1</sub>, the world where abortion is permissible, or <em>w</em><sub>2</sub>, the world where it is not, C is bad. In <em>w</em><sub>1</sub>, <span data-acronym-label="Shila" data-acronym-form="singular+short">Shila</span> is a bad friend, and is tacitly collaborating in state oppression. In <em>w</em><sub>2</sub>, <span data-acronym-label="Shila" data-acronym-form="singular+short">Shila</span> is not taking simple steps that would remove the mortal danger facing an innocent human. But option C isn’t catastrophic in either world. In <em>w</em><sub>1</sub>, <span data-acronym-label="Shila" data-acronym-form="singular+short">Shila</span> is not personally stopping <span data-acronym-label="Marilou" data-acronym-form="singular+short">Marilou</span> get an abortion, she just isn’t helping <span data-acronym-label="Marilou" data-acronym-form="singular+short">Marilou</span> break the law. (You can be a good enough friend and still draw the line between helping one move houses and helping one move bodies.) And in <em>w</em><sub>2</sub>, she’s not killing anyone, or even letting someone be killed, just not being maximally vigilent in preventing a killing. So the case has the structure of a Jackson case.</p>
<p>And yet there is little to be said for C. The situation calls for moral bravery, one way or the other. (I think in the direction of A, but it doesn’t matter for these purposes whether you agree with that.) And C is moral cowardice. Unlike in the cases involving factual uncertainty, it doesn’t seem at all like the safe, prudent, commendable option.</p>
</section>
<section id="casetwo-theft" class="level3" data-number="3.2.2">
<h3 data-number="3.2.2" class="anchored" data-anchor-id="casetwo-theft"><span class="header-section-number">3.2.2</span> Case Two - Theft</h3>
<p><span data-acronym-label="Eurydice" data-acronym-form="singular+short">Eurydice</span> and <span data-acronym-label="Pandora" data-acronym-form="singular+short">Pandora</span> are acquaintances, and they are planning to go to a party. <span data-acronym-label="Eurydice" data-acronym-form="singular+short">Eurydice</span> is worried because <span data-acronym-label="Pandora" data-acronym-form="singular+short">Pandora</span> plans to wear some very expensive jewellery, and the party features a number of thieves, several of whom are <span data-acronym-label="Eurydice" data-acronym-form="singular+short">Eurydice</span>’s friends. <span data-acronym-label="Eurydice" data-acronym-form="singular+short">Eurydice</span> tells <span data-acronym-label="Pandora" data-acronym-form="singular+short">Pandora</span> this, but <span data-acronym-label="Pandora" data-acronym-form="singular+short">Pandora</span> is unmoved, and insists she won’t be deterred from living her life the way she wants by the existence of petty criminals. <span data-acronym-label="Eurydice" data-acronym-form="singular+short">Eurydice</span> is much more observant than <span data-acronym-label="Pandora" data-acronym-form="singular+short">Pandora</span>, and knows that if someone tries to steal the jewellery, she’ll be able to prevent them, but only by using a non-trivial amount of physical force. For example, she could punch the would-be thief hard in the jaw while he was making his escape, revealing his thievery. (Realistically, she can’t know exactly how she would prevent a theft, but assume that’s the level of force that would be needed.)</p>
<p><span data-acronym-label="Eurydice" data-acronym-form="singular+short">Eurydice</span> is torn between two moral theories. One of them is a fairly mainstream view on which a moderate amount of physical force is warranted if it is the only way to prevent the theft of expensive goods. On the other moral theory, the demands of friendship and bodily autonomy completely outweigh considerations arising from property, so punching a friendly thief to prevent a theft would be a completely unjustified assault. Given all this, <span data-acronym-label="Eurydice" data-acronym-form="singular+short">Eurydice</span> has three options.</p>
<ol type="1">
<li>Go to the party and plan to prevent (using violence if necessary) any theft of <span data-acronym-label="Pandora" data-acronym-form="singular+short">Pandora</span>’s jewellery.</li>
<li>Go to the party and plan to refrain from any violence, even if this means standing by while a theft occurs.</li>
<li>Prevent <span data-acronym-label="Pandora" data-acronym-form="singular+short">Pandora</span> going to the party. The most morally acceptable way to do that, <span data-acronym-label="Eurydice" data-acronym-form="singular+short">Eurydice</span> thinks, would be to tell <span data-acronym-label="Pandora" data-acronym-form="singular+short">Pandora</span> a small lie that leads to <span data-acronym-label="Pandora" data-acronym-form="singular+short">Pandora</span> going on a wild goose chase for half the night, leaving it impossible to go to the party.</li>
</ol>
<p>Again, this feels like a Jackson case. C is a moral misdemeanour - you shouldn’t lie to people for the purpose of distracting them away from a party they have every right to be at. But it’s worse to stand by and watch a theft take place that you could easily (and properly) prevent, or to unjustifiedly punch a friend in the jaw.</p>
<p>Yet again it seems like C would be a terrible option to take. Either the amount of violence needed to apprehend the thief would be justified or it wouldn’t be. In neither case does it seem like sending <span data-acronym-label="Pandora" data-acronym-form="singular+short">Pandora</span> on a wild goose chase to prevent the theft would be a good way to prevent the problem arising. This seems true even though it would guarantee that things don’t go badly morally wrong, while either alternative runs a substantial moral risk.</p>
</section>
<section id="anasymmetry" class="level3" data-number="3.2.3">
<h3 data-number="3.2.3" class="anchored" data-anchor-id="anasymmetry"><span class="header-section-number">3.2.3</span> An Asymmetry</h3>
<p>When welfare is on the line, it is not just acceptable, but laudable, to sacrifice the chance of the best outcome for a certainty of a very good outcome. But it isn’t at all clear that this is true when virtue is on the line. Committing a moral misdemeanour because you don’t know which of the other options is a moral felony and which is the right thing to do is, still, committing a moral misdemeanour.</p>
</section>
</section>
<section id="motivation" class="level2 page-columns page-full" data-number="3.3">
<h2 data-number="3.3" class="anchored" data-anchor-id="motivation"><span class="header-section-number">3.3</span> Motivation</h2>
<p>Moral uncertainty, at least of the kind I’m focussing on, is a kind of constitutive uncertainty. An agent who is morally uncertain is uncertain about what kind of things constitute goodness, rightness, praiseworthiness, and so on. It’s very plausible that these are indeed constituted by something else. It’s hard to imagine that rightness is a free-floating feature of reality.</p>
<p>Cases of constitutive uncertainty are useful test cases for thinking about what’s really valuable. If we know that A constitutes B, and hence have equally strong desires for A and for B, it isn’t always easy to tell which of these desires is more fundamental, and which is derived. Of course, neither of the desires will be an <em>instrumental</em> desire, since getting A isn’t a means to getting B. But one of them could be derivative on the other.</p>
<p>And the simplest way to tell which is which, is to look to people who do not know that A constitutes B, and see what makes sense from their perspective. Think again about <span data-acronym-label="Monserrat" data-acronym-form="singular+short">Monserrat</span>, who has forgotten the victory conditions for her game. We know that being first to 10 points constitutes winning. But she doesn’t. What action makes sense for her to do? I think it is doing the thing that maximises her probability of winning, given her credal distribution. It turns out that isn’t the thing that maximises her probability of being first to 10 points, which is what actually amounts to winning. But she has no motivation to be first to 10 points, unless that amounts to winning. Or, at least, she has no such motivation on the most natural telling of the story. Perhaps she has an odd psychological tick that means she always values being first to <em>n</em> figures in points in any game she plays. But the more natural story is that she wants to win, and she should do the thing that maximises the probability of winning.</p>
<p>Things are rather different when it comes to moral uncertainty. There it seems that agents should be moved to produce the outcome that actually constitutes goodness or rightness, not the thing that maximises expected goodness or rightness. This is a point well made by Michael Smith. He compared the person who desires to do what is actually right, as he put it, desires the right de re, with the person who desires to do what is right whatever that turns out to be, as he put it, desires the right de dicto.</p>
<blockquote class="blockquote">
<p>Good people care non-derivatively about honesty, the weal and woe of their children and friends, the well-being of their fellows, people getting what they deserve, justice, equality, and the like, not just one thing: doing what they believe to be right, where this is read <em>de dicto</em> and not <em>de re</em>. Indeed, commonsense tells us that being so motivated is a fetish or moral vice, not the one and only moral virtue. &nbsp;<span class="citation" data-cites="Smith1994">(<a href="references.html#ref-Smith1994" role="doc-biblioref">Smith 1994, 75</a>)</span></p>
</blockquote>
<p>I think that’s all true. A good person will dive into a river to rescue a drowning child. (Assuming that is that it is safe enough to do so; it’s wrong to create more rescue work for onlookers.) And she won’t do so because it’s the right thing to do. She’ll do it because there’s a child who needs to be rescued, and that child is valuable.</p>
<p>Not everyone agrees with Smith that commonsense has this verdict about moral motivation. It helps to see the point made less abstractly, about a particular case. Here is the initial description of <span data-acronym-label="Saint-Just" data-acronym-form="singular+short">Saint-Just</span> from Palmer’s classic study of the Committee of Public Safety, <em>Twelve Who Ruled</em>.</p>
<blockquote class="blockquote">
<p>Saint-Just was an idea energised by a passion. All that was abstract, absolute and ideological in the Revolution was embodied in his slender figure and written upon his youthful face, and was made terrible by the unceasing drive of his almost demonic energy. He was a Rousseauist, but what he shared with Rousseau was the Spartan rigor of the <em>Social Contract</em>, not the soft day-dreaming of the <em>Nouvelle Héloïse</em>, still less the self-pity of the <em>Confessions</em>. He was no lover of blood, as Collot d’Herbois seems to have become. <em>Blood to him simply did not matter</em>. The individual was irrelevant to his picture of the world. The hot temperament that had disturbed his adolescence now blazed beneath the calm exterior of the political fanatic. &nbsp;<span class="citation" data-cites="Palmer1941">(<a href="references.html#ref-Palmer1941" role="doc-biblioref">Palmer 1941, 74</a>, emphasis added)</span></p>
</blockquote>
<p>That’s what someone who is only motivated by the good, as such, looks like. And it’s terrifying. Commonsense morality prefers a view where blood matters, and the individual is relevant, and where all of Rousseau’s works have something to teach us about how to live. <a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a></p>
<div class="no-row-height column-margin column-container"><li id="fn1"><p><sup>1</sup>&nbsp;I’ve mentioned <span data-acronym-label="Robespierre" data-acronym-form="singular+short">Robespierre</span> a few times in this context, so it’s interesting to note that Palmer thinks <span data-acronym-label="Robespierre" data-acronym-form="singular+short">Robespierre</span> is not as extreme as <span data-acronym-label="Saint-Just" data-acronym-form="singular+short">Saint-Just</span>. He compares the two in the paragraph preceding this one, mostly saying that <span data-acronym-label="Saint-Just" data-acronym-form="singular+short">Saint-Just</span> is a more extreme version of <span data-acronym-label="Robespierre" data-acronym-form="singular+short">Robespierre</span>. <span data-acronym-label="Saint-Just" data-acronym-form="singular+short">Saint-Just</span> is similar to his hero, but “without the saving elements of kindness and sincerity”. I think ‘saving’ is a little strong, but otherwise that judgment seems right. Collot positively desired actually bad things, <span data-acronym-label="Robespierre" data-acronym-form="singular+short">Robespierre</span> cared insufficiently about actually good things, and <span data-acronym-label="Saint-Just" data-acronym-form="singular+short">Saint-Just</span> simply did not care about anything beyond ideology.</p></li></div><p>We need to distinguish here two theses one might have about moral motivation. One is that the good, as such, should not be one’s only motivation. That’s what Smith says commonsense says, and it’s what the example of <span data-acronym-label="Saint-Just" data-acronym-form="singular+short">Saint-Just</span> supports. Another is that the good, as such, should not be among one’s motivations. I think this latter claim is mostly true as well. But I’ll come back to that; for now I want to spell out the consequences of the weaker claim, that the good should not be one’s only motivation.</p>
<p>This claim already makes trouble for normative internalists, including Smith himself. It makes trouble because it offers us a nice explanation of why there should be the kind of asymmetry between factual and normative uncertainty that we see in cases like <span data-acronym-label="Shila" data-acronym-form="singular+short">Shila</span>’s. Think again about the situation she is facing. She has to choose between respecting <span data-acronym-label="Marilou" data-acronym-form="singular+short">Marilou</span>’s autonomy, and respecting the foetus’s life. And she doesn’t know what to do, in no small part because she doesn’t know which form of respect constitutes moral rightness. But one thing she does know is that the moderate option maximises expected goodness. If we thought that this was an important motivation, we presumably should think it could be decisive in some cases, and <span data-acronym-label="Shila" data-acronym-form="singular+short">Shila</span> might take that moderate option. But intuitively she should never do that, and not have any motivation to do that. A pro-choice theorist may think <span data-acronym-label="Shila" data-acronym-form="singular+short">Shila</span> should believe that respecting autonomy is the right thing to do, and so <span data-acronym-label="Shila" data-acronym-form="singular+short">Shila</span> should be motivated to do what’s right because she’s motivated to respect autonomy. A pro-life theorist may think <span data-acronym-label="Shila" data-acronym-form="singular+short">Shila</span> should believe that respecting life is the right thing to do, and so <span data-acronym-label="Shila" data-acronym-form="singular+short">Shila</span> should be motivated to do what’s right because she’s motivated to respect life. But neither will hold that <span data-acronym-label="Shila" data-acronym-form="singular+short">Shila</span> should have a motivation to do what’s right that floats free of her motivation to respect autonomy, and to respect life.</p>
<p>This way of thinking about <span data-acronym-label="Shila" data-acronym-form="singular+short">Shila</span>‘s case suggests a prediction, one that is borne out by the cases. It isn’t always the case that moral ’hedging’, of the kind I’ve been criticising since the start of section 3.2, is bad. Imagine an agent faces a choice between competing values, both of which are values that she holds dear. For instance, consider an administrator who faces a student in a somewhat unusual situation. (The point of it being unusual is to ensure there is no clear precedent for what to do in such cases.) The administrator has to choose between being compassionate to the person in front of her, and doing the thing she thinks would best treat the case in front of her like previous cases. She may well care both about compassion and equality, and in such a case, it would make sense to look for a way to minimise the distance between how she treats this case and how she has treated past cases, while also being highly compassionate to the person in front of her. And that is true even if the outcome she comes up with is neither the most compassionate thing she can do, nor the most respecting of her desire to treat like cases alike. The reason this makes sense is that the administrator doesn’t think rightness is either exclusively constituted by compassion, or by treating like cases as alike as possible. Rather, she has plural values, like most of us do. And plural values, as opposed to uncertainty about what is the one true value, can produce moral Jackson cases.</p>
<p>What is the difference between <span data-acronym-label="Monserrat" data-acronym-form="singular+short">Monserrat</span>’s case and <span data-acronym-label="Shila" data-acronym-form="singular+short">Shila</span>’s? Why should <span data-acronym-label="Monserrat" data-acronym-form="singular+short">Monserrat</span> aim for what maximises the constituted quantity, while <span data-acronym-label="Shila" data-acronym-form="singular+short">Shila</span> aims for what maximises (or perhaps best respects) the constituting quantity? The answer comes from what it means for something to be right. It just is for it to be valuable. One of the striking things about games is that they turn something otherwise pointless, like being first to 10 points, into something that rational people can value. But morality isn’t like that. It can’t make value out of something that wasn’t valuable, because if it wasn’t valuable, it wouldn’t be fit to constitute rightness. So whatever rightness is, be it respecting autonomy or maximising welfare or whatever, must be something already valuable. And it is hard to see how having the property of being most valuable can be more valuable than the valuable thing itself.</p>
<p>So we get an explanation of Smith’s observation. (And here I’m not saying anything that hasn’t been said before, by for example Nomy <span class="citation" data-cites="Arpaly2003">Arpaly (<a href="references.html#ref-Arpaly2003" role="doc-biblioref">2003</a>)</span> and Julia <span class="citation" data-cites="Markovits2010">Markovits (<a href="references.html#ref-Markovits2010" role="doc-biblioref">2010</a>)</span>.) It is good to aim at what is actually right and good, not at rightness and goodness themselves, because the constitutors are where the value lies. But that means moral uncertainty should not affect our motivations. And that’s a striking asymmetry with factual uncertainty, which quite clearly should affect our motivations.</p>
</section>
<section id="welfareandmotivation" class="level2 page-columns page-full" data-number="3.4">
<h2 data-number="3.4" class="anchored" data-anchor-id="welfareandmotivation"><span class="header-section-number">3.4</span> Welfare and Motivation</h2>
<p>Smith’s insight, that there is something wrong about being motivated to do what’s good as such, generalises. There are plenty of other things where we do and should care about their constituents, but we should not (and typically do not) care about them as such. Welfare, for instance, is like this.</p>
<p>It’s plausible that deliberately undermining your own welfare, for no gain of any kind to anyone, is irrational. Indeed, it may be the paradigmatic form of irrationality. There is a radically Humean view that says that welfare just consists of preference satisfaction, and rationality is just a matter of means-end reasoning. If that’s right then what I just said is plausible is not only true, but almost definitional of rationality. You don’t have to be that radical a Humean, or really any kind of Humean at all, to think there is a connection between welfare and rationality. But if rationality is connected to welfare, it is because it is connected to the constituents of welfare, not to welfare as such. To see this, consider two examples, <span data-acronym-label="Bruce" data-acronym-form="singular+short">Bruce</span> and <span data-acronym-label="Oberon" data-acronym-form="singular+short">Oberon</span>.</p>
<p><span data-acronym-label="Bruce" data-acronym-form="singular+short">Bruce</span> has thought a bit about philosophical views on welfare. In particular, he has spent a lot of time arguing with a colleague who has the G. E. Moore-inspired view that all that matters to welfare is the appreciation of beauty, and personal love.<a href="#fn2" class="footnote-ref" id="fnref2" role="doc-noteref"><sup>2</sup></a> <span data-acronym-label="Bruce" data-acronym-form="singular+short">Bruce</span> is pretty sure this isn’t right, but he isn’t certain, since he has a lot of respect for both his colleague and for Moore.</p>
<div class="no-row-height column-margin column-container"><li id="fn2"><p><sup>2</sup>&nbsp;It would be a bit of a stretch to say this is Moore’s own view, but you can see how a philosopher might get from <span class="citation" data-cites="Moore1903">Moore (<a href="references.html#ref-Moore1903" role="doc-biblioref">1903</a>)</span> to here. Appreciation of beauty is one of the constituents of welfare in the objective list theory of welfare put forward by John <span class="citation" data-cites="Finnis2011">Finnis (<a href="references.html#ref-Finnis2011" role="doc-biblioref">2011, 87–88</a>)</span>.</p></li></div><p><span data-acronym-label="Bruce" data-acronym-form="singular+short">Bruce</span> also doesn’t care much for visual arts. He thinks that art is something he should learn something about, both because of the value other people get from art, and because of what you can learn about the human condition from it. And while he’s grateful for what he learned while trying to inculcate an appreciation of art, and he has become a much more reliable judge of what’s beautiful and what isn’t, the art itself just leaves him cold. I suspect most of us are like <span data-acronym-label="Bruce" data-acronym-form="singular+short">Bruce</span> about some fields of art; there are genres that we feel have at best a kind of sterile beauty. That’s how <span data-acronym-label="Bruce" data-acronym-form="singular+short">Bruce</span> feels about visual art in general. This is unfortunate; we should feel sorry for <span data-acronym-label="Bruce" data-acronym-form="singular+short">Bruce</span> that he doesn’t get as much pleasure from great art as we do. But it doesn’t make <span data-acronym-label="Bruce" data-acronym-form="singular+short">Bruce</span> irrational, just unlucky.</p>
<p>Finally, we will suppose, <span data-acronym-label="Bruce" data-acronym-form="singular+short">Bruce</span> is right to reject his colleague’s Moorean view on welfare. Appreciation of beauty isn’t a constituent of welfare. We’ll for the sake of the example that welfare is a matter of health, happiness and friendship. That is, a fairly restricted version of an objective list theory of welfare is correct in <span data-acronym-label="Bruce" data-acronym-form="singular+short">Bruce</span>’s world. And for people who like art, appreciating art can produce a lot of goods. Some of these are direct - art can make you happy. And some are indirect - art can teach you things and that learning can contribute to your welfare down the line. But if the art doesn’t make you happy, as it doesn’t make <span data-acronym-label="Bruce" data-acronym-form="singular+short">Bruce</span> happy, and one has learned all one can from a genre, as <span data-acronym-label="Bruce" data-acronym-form="singular+short">Bruce</span> has, there is no welfare gain from going to see art. It doesn’t in itself make you better off, in the way that <span data-acronym-label="Bruce" data-acronym-form="singular+short">Bruce</span>’s Moorean colleague thinks it does.</p>
<p>Now <span data-acronym-label="Bruce" data-acronym-form="singular+short">Bruce</span> has to decide whether to spend some time at an art gallery on his way home. He knows the art there will be beautiful, and he knows it will leave him cold. There isn’t any cost to going, but there isn’t anything else he’ll gain by going either. Still, <span data-acronym-label="Bruce" data-acronym-form="singular+short">Bruce</span> decides it isn’t worth the trouble, and stays out. He doesn’t have anything else to do, so he simply takes a slightly more direct walk home, which (as he knows) makes at best a trifling gain to his welfare.</p>
<p><span data-acronym-label="Bruce" data-acronym-form="singular+short">Bruce</span> is perfectly rational to do this. He doesn’t stand to gain anything at all from going to the gallery. In fact, it would be a little perverse, in a sense we’ll return to, if he did go.</p>
<p><span data-acronym-label="Oberon" data-acronym-form="singular+short">Oberon</span> is also almost, but not completely certain, that health, happiness and friendship are the sole constituents of welfare.<a href="#fn3" class="footnote-ref" id="fnref3" role="doc-noteref"><sup>3</sup></a> But he worries that this is undervaluing art. He isn’t so worried by the Moorean considerations of <span data-acronym-label="Bruce" data-acronym-form="singular+short">Bruce</span>’s colleagues. But he fears there is something to the Millian distinction between higher and lower pleasures, and thinks that perhaps higher pleasures contribute more to welfare than lower pleasures. Now most of <span data-acronym-label="Oberon" data-acronym-form="singular+short">Oberon</span>’s credence goes to alternative views. He is mostly confident that people think higher pleasures are more valuable than lower pleasures because they are confusing causation and constitution. It’s true that experiencing higher pleasures will, typically, be part of experiences with more downstream benefits than experiences of lower pleasures. But that’s the only difference between the two that’s prudentially relevant. (Oberon also suspects the Millian view goes along with a pernicious conservatism that values the pop culture of the past over the pop culture of the present solely because it is past. But that’s not central to his theory of welfare.) And like <span data-acronym-label="Bruce" data-acronym-form="singular+short">Bruce</span>, we’ll assume <span data-acronym-label="Oberon" data-acronym-form="singular+short">Oberon</span> is right about the theory of welfare in the world of the example.</p>
<div class="no-row-height column-margin column-container"><li id="fn3"><p><sup>3</sup>&nbsp;Thanks to Julia Markovits for suggesting the central idea behind the Oberon example, and to Jill North for some comments that showed the need for it.</p></li></div><p>Now <span data-acronym-label="Oberon" data-acronym-form="singular+short">Oberon</span> can also go to the art gallery. And, unlike <span data-acronym-label="Bruce" data-acronym-form="singular+short">Bruce</span>, he will like doing so. But going to it will mean he has to miss a night playing video games that he often goes to. <span data-acronym-label="Oberon" data-acronym-form="singular+short">Oberon</span> knows he will enjoy the video games more. And since playing video games with friends helps strengthen friendships, he has a further reason to skip the gallery and play games. Like <span data-acronym-label="Bruce" data-acronym-form="singular+short">Bruce</span>, <span data-acronym-label="Oberon" data-acronym-form="singular+short">Oberon</span> knows that there can be very good consequences of seeing great art. But also like <span data-acronym-label="Bruce" data-acronym-form="singular+short">Bruce</span>, <span data-acronym-label="Oberon" data-acronym-form="singular+short">Oberon</span> knows that none of that relevant here. Given <span data-acronym-label="Oberon" data-acronym-form="singular+short">Oberon</span>’s background knowledge, he will have fun at the exhibition, but won’t learn anything significant.</p>
<p>Still, <span data-acronym-label="Oberon" data-acronym-form="singular+short">Oberon</span> worries that he should take a slightly smaller amount of higher pleasure rather than a slightly larger amount of lower pleasure. And he’s worried about this even though he doesn’t give a lot of credence to the whole theory of higher and lower pleasures. But he doesn’t go to the gallery. He simply decides to act on the basis of his preferred theory of welfare, and since that theory of welfare is correct, he maximises his welfare by doing this.</p>
<p>Now distinguish the following two claims about welfare and rationality. The first of these claims is plausibly true; the second is false.</p>
<ul>
<li>A person’s welfare is such that it is irrational for them to do something that might undermine it for no compensating gain.</li>
<li>It is irrational for a person to do something that might undermine their welfare, whatever that turns out to be, for no compensating gain.</li>
</ul>
<p>If welfare turns out to be health, happiness and learning, then the first claim says that it is irrational to risk undermining one’s health, happiness and learning for no compensating gain. And that is correct. But the second claim says that for any thing, if that thing might be welfare, and an action might undermine it, it is irrational to perform the action without a compensating gain. That’s a much stronger, and a much less plausible, claim. The examples of <span data-acronym-label="Bruce" data-acronym-form="singular+short">Bruce</span> and of <span data-acronym-label="Oberon" data-acronym-form="singular+short">Oberon</span> show that it is false; they act rationally even though they do things that might undermine what welfare turns out to be.</p>
<p>One caveat to all this. On some theories of welfare, it will not be obvious that even the first claim is right. Consider a view (standard among economists) that welfare is preference satisfaction. Now you might think that even the first claim is ambiguous, between a claim that one’s preferences are such that it is irrational to undermine them (plausibly true), and a claim that it is irrational to undermine one’s preference satisfaction. The latter claim is not true. If someone offers a person a pill that will make her have preferences for things that are sure to come out true (she wants the USA to stay being more populous than Monaco, she wants to have fewer than ten limbs; etc.), it is rational to refuse it. And that’s true even though taking the pill will ensure that she has a lot of satisfied preferences. What matters is that taking the pill does not satisfy her actual preferences. If she prefers X to Y, she should aim to bring about X. But she shouldn’t aim to bring about a state of having satisfied preferences; that could lead to rather perverse behaviour, like taking this pill.</p>
</section>
<section id="motivationvirtuesandvices" class="level2" data-number="3.5">
<h2 data-number="3.5" class="anchored" data-anchor-id="motivationvirtuesandvices"><span class="header-section-number">3.5</span> Motivation, Virtues and Vices</h2>
<p>So far in this chapter I have relied heavily on Michael Smith’s principle that a certain kind of motivation would be unreasonably fetishistic. In this section I’m going to defend Smith’s principle in more detail. Since Smith’s principle has been extensively discussed, I’m going to spend some time on the existing literature. But one key point of this section will be that I need a much weaker principle for my broader conclusion than Smith needs for his. So even if the existing objections to Smith are correct, and I will concede at least one has some force against the strong principle Smith defends, they may not affect my argument for externalism.</p>
<p>That Smith and I need different versions of the principle should not be too surprising. As we saw in chapter 2, Smith defends some of the internalist principles I’m arguing against. Since we have different conclusions, one might hope we had different premises. The passage from Smith I quoted about moral fetishism is in defence of his motivational internalism. As I noted in chapter 1, the different theses called internalism are dissociable, but they do have some affinities. Motivational internalism is consistent with normative externalism, but is in some tension with it. So again, it isn’t surprising that I’ll be using Smith’s idea in a slightly different way.</p>
<p>Let’s start by setting out three theses that one might try to draw from considerations starting from Smith’s reflections.</p>
<dl>
<dt>Weak Motivation Principle (WMP)</dt>
<dd>
In equilibrium, it is permissible to not be intrinsically motivated by maximally thin moral properties de dicto.
</dd>
<dt>Strong Motivation Principle (SMP)</dt>
<dd>
In most circumstances, it is impermissible to be at all intrinsically motivated by moderately thin (or thinner) moral properties de dicto.
</dd>
<dt>Ideal Motivation Principle (IMP)</dt>
<dd>
In all circumstances, it is impermissible to be at all intrinsically motivated by maximally thin moral properties de dicto.
</dd>
</dl>
<p>The SMP and IMP are both stronger than the WMP, though neither is stronger than the other. As I read him, Smith needs the IMP to get his argument for motivational internalism to work. Since I’m not interested in that, I’ll set it aside from now on.</p>
<p>In the next section I’ll discuss the WMP, with a focus on clarifying the term ‘equilibrium’. The aim is to argue that it is is true, and that if it is true, there is an asymmetry between factual and moral uncertainty.</p>
<p>After that, I’ll discuss the SMP. I also think the SMP is true, and if it is true, then there is a huge asymmetry between factual and moral uncertainty. But I need to stress at this point that defending the SMP isn’t strictly necessary for the major argument of the chapter; the WMP is enough to raise problems.</p>
<p>After that, I’ll discuss a few examples that help clarify the boundaries of the two principles, and which I think provide some argument for the principles. But I’m discussing them at the end, because I don’t really want the case for or against the principles to rest on intuitions about disputed examples like the ones I’ll bring up.</p>
<p>The principles appeal to the notion of ‘intrinsic motivation’, and it’s worth spending a few words on that. Just about everything I say here is drawn from <span class="citation" data-cites="ArpalySchroeder2014">Arpaly and Schroeder (<a href="references.html#ref-ArpalySchroeder2014" role="doc-biblioref">2014, 6–14</a>)</span>, and they go into more detail than I do about some of the important distinctions.</p>
<p>There is a distinction in everyday English between ends and means. And to a first approximation, to desire something as an end is to desire it intrinsically, and to desire it as a means it to desire it instrumentally. But here we need to make a slightly finer distinction than that.</p>
<p>Parents typically desire that their children be well educated. For some people this will be an instrumental desire; they want their children to be, say, very rich, and think that education is a means to wealth. But for others it will be intrinsic; a good education is part of what is good for their children.</p>
<p>Now consider the desire (again widely held among parents) that one’s children be well educated in arithmetic. How does this relate to the general desire that they be well educated? It isn’t exactly a means to that end. It is part of what it is to be well educated. To desire that a child be well educated, and to know what it is to be well educated, just means that you desire that the child be well educated in arithmetic. Call desires like this, ones which have a constitutive rather than causal connection to intrinsic desires, <em>realizer</em> desires.</p>
<p>The most obvious cases of realizer desires are when the intrinsic desire is more general, and the realizer desire is more specific. But we can go the other way around too. Consider again the perfectly normal parent who wants their child to be well educated, to be healthy, to be happy, to have lots of friendships, and generally wants all the things that make up a good life for their child. That parent will want their child to have a good life. This might be an intrinsic desire; maybe all those other desires are realizers of it. It might even be an instrumental desire, though this would be a little perverse. Or it might be a realizer desire, and I think this is the most natural case. If one wants the child to be happy, healthy, befriended, educated, etc, and one has a sensible balance between those desires, then in virtue of all that, one has the desire that the child have a good life. To desire all these things just is to desire the child have a good life. It’s a very different way of desiring that the child have a good life than having that desire instrumentally, as one might if one wanted the child to have a good life solely so one would be rewarded in the afterlife. And it is a somewhat different way of desiring that the child have a good life than having that desire intrinsically. The difference shows up in two ways. One concerns the order of explanation: does one want the child to have a good life in virtue of wanting the child to be happy, healthy etc, or is it the other way around? The other concerns how one’s desires for the child change when one’s conception of the good life changes.</p>
<p>So the SMP and WMP concern themselves neither with instrumental desires nor with realizer desires. A good person will typically desire that they do the right thing, but they will desire that because the things they desire are actually the right thing to do, and they will (typically) know this. The principles say that the desires to do things that are actually right could be, or in the case of the latter two principles should be, explanatorily prior to the desire to do the right thing as such.</p>
</section>
<section id="theweakmotivationprinciplewmp" class="level2 page-columns page-full" data-number="3.6">
<h2 data-number="3.6" class="anchored" data-anchor-id="theweakmotivationprinciplewmp"><span class="header-section-number">3.6</span> The Weak Motivation Principle (WMP)</h2>
<section id="equilibrium" class="level3" data-number="3.6.1">
<h3 data-number="3.6.1" class="anchored" data-anchor-id="equilibrium"><span class="header-section-number">3.6.1</span> Equilibrium</h3>
<p>The WMP is restricted to equilibrium states. This restriction is there to deal with an important class of cases that Sigrún <span class="citation" data-cites="Svavarsdottir1999">Svavarsdóttir (<a href="references.html#ref-Svavarsdottir1999" role="doc-biblioref">1999</a>)</span> discusses.</p>
<blockquote class="blockquote">
<p>[Smith argues that] the externalist account “re-describe[s] familiar psychological processes in ways that depart radically from the descriptions that we would ordinarily give of them” &nbsp;<span class="citation" data-cites="Smith1996">(<a href="references.html#ref-Smith1996" role="doc-biblioref">Smith 1996, 180</a>)</span> … Smith tells a story of a friend (let’s call him<span data-acronym-label="Mike" data-acronym-form="singular+short">Mike</span>) who has radically changed his moral view over the years from act-utilitarianism to a view that sanctions, in some instances, favoring family and friends, even when this cannot be given utilitarian justification. Since <span data-acronym-label="Mike" data-acronym-form="singular+short">Mike</span> is a moralist, his motivational dispositions have changed correspondingly … I would like to offer an illustration of what sort of description externalists might give of <span data-acronym-label="Mike" data-acronym-form="singular+short">Mike</span>’s mental states before, during, and after his two moral conversions. I venture the following speculation: <span data-acronym-label="Mike" data-acronym-form="singular+short">Mike</span> has always had some inclination to favor family and friends, but at one point he developed strong inhibitions against acting on these inclinations. These inhibitions were largely the result of being convinced that act-utilitarianism specifies the correct criterion for moral rightness. Having a strong desire to do the right thing and a rigid temperament, <span data-acronym-label="Mike" data-acronym-form="singular+short">Mike</span> quickly developed an avid interest in maximizing total happiness in the world, taking the interest of each person equally into account. In due time, his desire to maximize happiness actually started to dominate all other desires to the point that his friends thought of him as a utilitarian monster. But slowly doubts started to emerge as a result of exposure to arguments against utilitarianism. By and by <span data-acronym-label="Mike" data-acronym-form="singular+short">Mike</span>’s conviction eroded and in the end he accepted a moral view according to which it is often right to be partial to family and friends, even when doing so cannot be given a utilitarian justification. At the same time, he came to see himself as a utilitarian monster, ever ready to sacrifice the interests of friends and family for the utilitarian project. Motivational dispositions he formerly took pride in having developed now became distasteful to him. However, since his desire to do the right thing has continued to be operative in his psyche, these dispositions are slowly eroding and the inhibitions on his inclinations to favor family and friends are undergoing radical change. They are gradually falling in line with his view of when it is right to give extra benefits to family and friends. &nbsp;<span class="citation" data-cites="Svavarsdottir1999">(<a href="references.html#ref-Svavarsdottir1999" role="doc-biblioref">Svavarsdóttir 1999, 208–10</a>)</span></p>
</blockquote>
<p>Smith had argued that it is always a bad thing to be moved by the desire to do the right thing, as such. Svavarsdóttir’s reply here is that this isn’t bad at the very moment of major change in one’s moral outlook. (Since this was the very example that Smith used against the motivational externalist, such examples were rather relevant to her debate with Smith.) Adopting a moral theory wholeheartedly requires adjusting one’s motivations to align with it. But this need not be an instantaneous process; it can take time and effort. And the motivation to engage in this process of adjustment may come from a desire to do the right thing.</p>
<p>The defender of the WMP can concede all this. What the defender says is that <span data-acronym-label="Mike" data-acronym-form="singular+short">Mike</span>, in Svavarsdóttir’s example, is not in equilibrium. What do we mean here by being in equilibrium?</p>
<p>For current purposes, it means having fairly settled moral views, and having had enough time and space since one’s views became settled to make suitable adjustments in the rest of one’s mind. Equilibrium requires the absence of felt pressure to change one’s desires in light of changes to one’s moral outlook.</p>
<p>Here are two cases that I take to not be in equilibrium, in the sense relevant to the WMP.</p>
<ul>
<li>Our hero faces a choice between competing values, and is torn about how to resolve them. She does not know which value is stronger, and she either lacks a clear disposition to resolve the tension in one particular way, or has such a disposition but does not trust it.</li>
<li>Our hero systematically does not do what they believe to be best, and is trying to change their attitudes and behaviour to conform to their beliefs about the good.</li>
</ul>
<p>On the other hand, the following two cases are cases of equilibrium in the relevant sense, albeit highly imperfect equilibrium.</p>
<ul>
<li>Our hero does not do what they believe to be best, but they have learned to live with this, perhaps feeling guilty about the gap between their thoughts and their deeds.</li>
<li>Our hero is disposed to act one way, but would change their disposition if the reasons for acting a different way, reasons they already possess, were made salient to them.</li>
</ul>
<p>In all four cases, the person already possesses something like reasons to change. But what makes for being in disequilibrium is the feeling that things must and will change.</p>
<p>Our ultimate interest here is in cases where moral beliefs do or don’t line up with action, but we can come up with mundane, non-moral, illustrations of each of them. Here’s a (schematic) illustration of the fourth kind of case.</p>
<p>I have a particular route I usually use going from B to C. I have a different route I use going from A to C. That route goes via B, but it does not take the usual route I use from B to C. This can’t be optimal; if there is a best way to get from B to C, I should use it in parts of journeys as well as wholes. I could, nevertheless, be in equilibrium, even if a small suggestion (hey, why don’t you do something different for the second part of the A-C route?) would push me to change my behaviour. The point is that equilibrium in the relevant sense just requires that the agent isn’t trying to change, and isn’t feeling pressure to change, even if they possess perfectly good reasons to change, and could easily be changed.</p>
<p>But in Svavarsdóttir’s example, we do not have someone in equilibrium even in this weak sense. <span data-acronym-label="Mike" data-acronym-form="singular+short">Mike</span> wants to change his dispositions to line up with his moral theory, and he is making progress at this, but he still isn’t there. The WMP does not deny that in cases like this, it is permissible to have goodness itself as a motivation.</p>
</section>
<section id="whyengageinmoralreflection" class="level3" data-number="3.6.2">
<h3 data-number="3.6.2" class="anchored" data-anchor-id="whyengageinmoralreflection"><span class="header-section-number">3.6.2</span> Why Engage in Moral Reflection?</h3>
<p>The following kind of consideration is sometimes advanced as a reason to be motivated by goodness as such. Sometimes people engage in practically directed moral reflection. That is, they think hard about what is the right thing to do, and the intended result of that thinking is that they do the thing they think is right. The most obvious analysis of what’s going on in these cases is that the people involved want to do the right thing, and the point of engaging in reflection and acting on it is to bring it about that they do the right thing. And at least in cases where this leads to the thinker acting well, it seems this kind of moral reflection is a very good thing to engage in.</p>
<p>In the next section I’m going to say a lot more about this kind of case, because the SMP has to give a very different analysis of what is going on in moral reflection. But the defender of the WMP does not need to say much about these cases because they can simply endorse the ‘obvious analysis’. The defender of the WMP can say that it is good, even optimal, to engage in moral reflection, motivated by the desire to do the right thing, when not in equilibrium.</p>
<p>The WMP is only making the following claim. When the storm is over and the seas are flat, a good person may be motivated by the things that make their actions right, not by the rightness itself. People who don’t know what to do, and are torn between competing values, could not be a counterexample to such a principle.</p>
</section>
<section id="thewmpandtwokindsofmotivationgaps" class="level3" data-number="3.6.3">
<h3 data-number="3.6.3" class="anchored" data-anchor-id="thewmpandtwokindsofmotivationgaps"><span class="header-section-number">3.6.3</span> The WMP and Two Kinds of Motivation Gaps</h3>
<p>But why should we believe the WMP? I think the best reason is the simple intuition that Smith put forward: good people are motivated by things around them in the world, not by abstract notions of virtue and rightness. Another reason comes from reflection on fanatics like <span data-acronym-label="Robespierre" data-acronym-form="singular+short">Robespierre</span> and <span data-acronym-label="Saint-Just" data-acronym-form="singular+short">Saint-Just</span>. But not everyone accepts those reasons. So let’s look at a pair of cases that need explaining, and which the WMP can explain.</p>
<p>The first case is a petty crook who won’t cross certain lines. In particular, while he’ll steal anything from anyone, he won’t engage in violence. This isn’t just because he is scared of getting punished for violent acts. He has a kind of moral objection to violence. Perhaps speaking loosely, let’s say that he has no respect for property rights, but a fitting and proper respect for rights involving bodily autonomy.</p>
<p>The thief’s colleagues are planning a violent robbery. Feeling uncomfortable with this turn of events, the thief informs the police, who prevent the violence. This was a right and praiseworthy action by the thief. But what could make it right and praiseworthy? Not that he was trying to do the right thing - he’s a thief who would have happily gone along with a non-violent plan to steal the goods. What makes his actions right and praiseworthy is that his motivation, prevention of violence against (relative) innocents, was good. There is nothing mysterious, and nothing wrong, with having this motivation without having a general motivation to be moral.</p>
<p>The second case is a person who has a desire to do what’s right, but no underlying motivations. There are a couple of interesting variants of this case. Nomy <span class="citation" data-cites="Arpaly2003">Arpaly (<a href="references.html#ref-Arpaly2003" role="doc-biblioref">2003</a>)</span> spends some time on examples of ‘misguided conscience’; people who want to do the right thing and are wrong about what it is. But we can also imagine someone who does want to do the right thing, and is broadly correct about what is right, but lacks any direct desire to do the thing that’s actually right. Let’s think about such a case for a bit.</p>
<p>Our protagonist, call him <span data-acronym-label="Rowly" data-acronym-form="singular+short">Rowly</span>, was brought up well enough that he knows it is wrong to use violence to get things you want. And a desire to avoid wrongdoing was inculcated at a young age. So when <span data-acronym-label="Rowly" data-acronym-form="singular+short">Rowly</span> wants a beer, but could only get one by punching someone, he declines to take the opportunity. But he is upset by this; he has no desire to avoid violence, or to avoid causing suffering, and wishes it was not wrong to punch someone to get a beer.</p>
<p>There is something deeply wrong with <span data-acronym-label="Rowly" data-acronym-form="singular+short">Rowly</span>. We can see this by thinking about our interpretative practices. When someone says they did something because “it was the right thing to do”, we do not normally interpret them as having no other-directed desires other than the desire to avoid wrong-doing. We do not normally think of such a person as being like <span data-acronym-label="Rowly" data-acronym-form="singular+short">Rowly</span>. Someone who has to be taught what’s right and wrong, and who has this belief as the only barrier stopping serious wrongdoing, is a deeply flawed human being. Even when people are too inarticulate to say what desires they have beyond a desire to do the right thing, we normally interpret this as inarticulateness, not a lack of respect for others, nor a lack of desire that others not suffer. This inarticulateness is not surprising; it’s really hard to describe what makes actions right or wrong. But not wishing well for others is surprising; it’s a serious character flaw.</p>
<p>So a desire to do the right thing is, in equilibrium, either unnecessary or insufficient. If one wants to prevent suffering to others, and acts on this, that’s great, and it makes the desire to do the right thing unnecessary. If one lacks a desire to prevent (causing) suffering, then it is perhaps fortunate to have a desire to do the right thing, but that is insufficient for virtue.</p>
<p>Since a desire to do the right thing seems so useless, at least in equilibrium and in the presence of other good desires, it seems permissible to not have such a desire. And that’s all WMP says.</p>
</section>
<section id="against-symmetry" class="level3 page-columns page-full" data-number="3.6.4">
<h3 data-number="3.6.4" class="anchored" data-anchor-id="against-symmetry"><span class="header-section-number">3.6.4</span> Against Symmetry</h3>
<p>I’ve argued so far that the WMP is true. I’m now going to argue that, assuming the WMP is true, there is an asymmetry between factual and moral uncertainty. The role the WMP plays is to block one of three possible routes out of a problem facing the defender of symmetry.</p>
<p>We know that having the probability of some factual proposition move from 0% to 5% can (rationally) change behaviour. If I think the probability of rain is 0%, I don’t have to check whether there is an umbrella in the car. If I think it is 5%, I will check the trunk to see the umbrella is still there before heading out. If symmetry holds, then changing the probability of a moral proposition from 0% to 5% should also change behaviour. And it is hard to see how that could happen.</p>
<p>I’m going to mostly assume here a broadly Humean picture of motivation: people do things that promote their desires assuming their beliefs are true. The relevant contrast here is with the view that beliefs, or at least belief-like states, can promote action without an underlying desire. So the Humean thinks I pack the umbrella because I believe it prevents me getting wet, and I have a desire to avoid getting wet, while the anti-Human thinks I pack it because I believe it prevents me getting wet, and I believe that it is good to avoid getting wet (or something similar).</p>
<p>I’m assuming the Humean view partially because it is implicit in our best formal models, partially because it seems intuitive, and partially because there are technical problems with the anti-Human view. David <span class="citation" data-cites="Lewis1988b Lewis1996a">(<a href="references.html#ref-Lewis1988b" role="doc-biblioref">Lewis 1988</a>, <a href="references.html#ref-Lewis1996a" role="doc-biblioref">1996</a>)</span> showed that the view that beliefs about the good played the role of values in expected value theory led to problems with updating mental states. Recently Jeffrey Sanford Russell and John Hawthorne <span class="citation" data-cites="RussellHawthorne2016">(<a href="references.html#ref-RussellHawthorne2016" role="doc-biblioref">2016</a>)</span> have shown that these results rely on much weaker premises, and apply much more broadly, than a casual reading of Lewis’s papers would suggest. Anyone who thinks that belief-like states alone can drive action has to adopt a rather implausible seeming picture of how beliefs are updated.</p>
<p>So I think rejecting belief-desire psychology is a high price to pay. But let’s note it is one way out of the argument I’m about to give. I’ll call it Option One for the symmetry defender.</p>
<p>If we don’t take option one, then the symmetry defender must say which desires interact with a change in credence to produce a change in action. An obvious choice is to say that it is a desire to do the right thing. But that’s blocked by the WMP. If symmetry is true, then there are times when a change in credence from 0% to 5% makes it compulsory to change actions. And it is not compulsory to have a desire to do the right thing. So that won’t work. For the record, Option Two for the symmetry defender is to reject the WMP, but that’s also a bad move.</p>
<p>What the symmetry defender needs is to identify desires, other than desires to do the right thing, that can generate the action. These will be tricky to find. If someone thinks that it is 0% likely that doing X is wrong, then presumably it is completely rational to have no desire to avoid X, or avoid what X involves. So it looks like this route won’t work either.</p>
<p>But that’s too quick. All the symmetry defender needs is that after the change in credence, there is a desire that drives the change in action. Perhaps a change in credence could be correlated with a change in desires that produced, via orthodox belief-desire reasoning, the outcome the internalist wants.</p>
<p>But thinking there will always be such a change in desires is too much to hope for. Indeed, in some cases having such a change would be bad, as we can see using an example from Lara <span class="citation" data-cites="Buchak2013">Buchak (<a href="references.html#ref-Buchak2013" role="doc-biblioref">2014</a>)</span>.</p>
<p><span data-acronym-label="Malai" data-acronym-form="singular+short">Malai</span> has a good friend, who she has known since childhood, and she values the friendship highly<a href="#fn4" class="footnote-ref" id="fnref4" role="doc-noteref"><sup>4</sup></a>. Then <span data-acronym-label="Malai" data-acronym-form="singular+short">Malai</span> learns that someone committed a horrible crime, and there is some very weak evidence that it was her friend. It’s reasonable for <span data-acronym-label="Malai" data-acronym-form="singular+short">Malai</span> to have a slightly greater than zero credence that it was her friend who committed the crime, while not changing at all how much she values the friendship. Indeed, if the evidence is strong enough to move her credence, but not much more, it would be bad to have any other attitude. It’s wrong to devalue friendships because you get some almost certainly misleading evidence about your friend. It’s true the expected value of the friendship goes down when the evidence comes in, and if the friendship had only instrumental value, then that’s a reason to devalue it. If <span data-acronym-label="Malai" data-acronym-form="singular+short">Malai</span>’s only interest was in, say, getting to heaven, and she only valued the friendship insofar as she thought it likely it was a friendship with a good person, and that’s the kind of thing that helps get you to heaven, then she should reduce how much she values the friendship. But most of us do not have quite that transactional an attitudes towards our friends or our friendships. <span data-acronym-label="Malai" data-acronym-form="singular+short">Malai</span> should have just as strong a desire to respect her friend and promote her friend’s interests, and to respect and promote the friendship, as she had before getting the evidence. The evidence should not make her value the friendship less, and that’s because friendships are intrinsically valuable, and how much something is intrinsically valued is not proportionate to one’s credence that it is intrinsically valuable.</p>
<div class="no-row-height column-margin column-container"><li id="fn4"><p><sup>4</sup>&nbsp;I’m assuming throughout this paragraph that to value the friendship is a matter of having the right desires concerning the friend and the friendship, not having beliefs about the value of the friend or friendship.</p></li></div><p>The same goes at the other end of the valuing scale. If one thinks that, for example, there is a 5% chance that purity is intrinsically valuable, it doesn’t follow that one needs to (intrinsically) value purity at all. Nor does it follow that one needs to be motivated, at all, by considerations of purity.</p>
<p>I’ll call Option Three the rejection of all that’s been said in the last three paragraphs, and the insistence that changes in moral credences must occasion changes in desires. The examples involving <span data-acronym-label="Malai" data-acronym-form="singular+short">Malai</span> and involving purity make this option very unattractive.</p>
<p>Ultimately, I think this is the deepest problem for the symmetry view. Factual uncertainty changes our actions, and it does so rationally because it changes which factual uncertainty changes the expected value of different actions. For moral uncertainty to have the same effect, either we have to have a false view of the role of desire in action (Option One), or have to reject the WMP (Option Two), or have to adopt an implausible and unattractive view of how desires change when credences change (Option Three). None of these are correct, so symmetry fails.</p>
</section>
</section>
<section id="thestrongmotivationprinciplesmp" class="level2 page-columns page-full" data-number="3.7">
<h2 data-number="3.7" class="anchored" data-anchor-id="thestrongmotivationprinciplesmp"><span class="header-section-number">3.7</span> The Strong Motivation Principle (SMP)</h2>
<p>It is easy to imagine very good characters who are not motivated by the good as such; instead they are directly motivated by things that are actually good. Indeed, if one’s motivations are fully in line with the good, it isn’t clear what extra there is to be gained by also being motivated to be good. At worst, this motivation seems like either a distraction, or impermissibly self-centered. As Michael Smith puts it, people with this motivation “seem precious, overly concerned with the moral standing of their acts when they should instead be concerned with the features in virtue of which their acts have the moral standing that they have.” &nbsp;<span class="citation" data-cites="Smith1996">(<a href="references.html#ref-Smith1996" role="doc-biblioref">Smith 1996, 183</a>)</span></p>
<p>There is something disturbing about a person who does not find the fact that a certain act is, say, a torture of a child to be sufficient motivation to not do it, and needs the extra motivation that it would be wrong. And the same goes for any other wrong act. Nothing is wrong as a matter of brute fact; there is always some explanation for why it is wrong. And that explanation always provides a motivation that would prevent a good person from doing the action. Anyone who needs some further motivation is in some way deficient.</p>
<p>That is the intuitive argument for the SMP. And it seems to me compelling. But we can say more to motivate, and justify, the SMP. I’ll start with a discussion of a central objection to the SMP; that it doesn’t allow a special role for moral reflection. Then I’ll discuss another reason to support the SMP; it avoids a certain kind of danger, one that we see manifest in history. And I’ll close with a sketch of what a proponent of the SMP thinks the good person is like.</p>
<section id="howtoexplainreflection" class="level3 page-columns page-full" data-number="3.7.1">
<h3 data-number="3.7.1" class="anchored" data-anchor-id="howtoexplainreflection"><span class="header-section-number">3.7.1</span> How to Explain Reflection</h3>
<p>We typically think the following kind of activity is good. A person is faced with a difficult moral question, or with a question that she thought was easy, but which it turns out people she respects take a different view on. She reflects on what morality requires in such a situation. Upon coming to believe that morality requires of her something different than her current practices, she changes her behaviour to match with her new moral beliefs.</p>
<p>Such a character seems to pose a problem for the SMP. At first glance, it seems like a motivation to do good, or at least avoid doing bad, plays a central role. It is, apparently, the agent’s change in her moral beliefs that triggers a change in action. And a change in a belief about what is X can only make a difference in action if X enters into one’s motivational set in the right way. Since our agent seems to be a good person, it seems like good people should have thin moral motivations.<a href="#fn5" class="footnote-ref" id="fnref5" role="doc-noteref"><sup>5</sup></a></p>
<div class="no-row-height column-margin column-container"><li id="fn5"><p><sup>5</sup>&nbsp;In the previous section I noted that the proponent of the WMP has an easy explanation of the appeal of moral reflection, since the agent who is motivated to engage in moral reflection is not in equilibrium. Since the SMP is not restricted to agents in equilibrium states, such an appeal will not work in defence of it.</p></li></div><p>My response to this kind of case will be very similar to what <span class="citation" data-cites="ArpalySchroeder2014">Arpaly and Schroeder (<a href="references.html#ref-ArpalySchroeder2014" role="doc-biblioref">2014, 185ff</a>)</span> say about moral reflection. When our agent tries to figure out what morality requires of her, she won’t start with highly abstract theorising. She will start with her concrete commitments concerning how she should engage with the world around her, and work out how those commitments apply to difficult or contested cases. As Michael Smith puts the point</p>
<blockquote class="blockquote">
<p>[N]ot only is it a platitude that rightness is a property that we can discover to be instantiated by engaging in rational argument, it is also a platitude that such arguments have a certain characteristic coherentist form. &nbsp;<span class="citation" data-cites="Smith1994">(<a href="references.html#ref-Smith1994" role="doc-biblioref">Smith 1994, 40</a>)</span></p>
</blockquote>
<p>When good people use thin moral concepts in their reasoning, it is not because they are aiming at the good as such, but because these concepts are useful tools to use in sorting and clarifying their commitments, and making sure that they promote and respect the things they actually care about. We see this in other walks of life too. A competitor in a sporting event may steer their strategy towards moves that maximise expected returns. That’s not because they care about expected returns; they want to win. It is because using the concept of an expected return is a good way to manage your thoughts when you want to think about how to win. And, in practice, this is often a very good way to manage your thoughts, so good strategists will use the concept. Similarly, it may turn out to be useful to use the concepts of goodness and rightness when trying to promote and respect the things that really matter, and so it isn’t a surprise that we see good people using them.</p>
</section>
<section id="againstmotivationbymorality" class="level3" data-number="3.7.2">
<h3 data-number="3.7.2" class="anchored" data-anchor-id="againstmotivationbymorality"><span class="header-section-number">3.7.2</span> Against Motivation by Morality</h3>
<p>If moral concepts are useful tools for good people to use in promoting and respecting good aims, then we should expect that, like all tools, they have their limits. And indeed those limits are not hard to find. Moral reasoning is a kind of equilibrium reasoning. And equilibrium reasoning has clear strengths and weaknesses. There are cases when it is essential. Trying to work out the effect of a natural disaster on the market for widgets is practically impossible without doing at least some equilibrium reasoning. But there are also cases when it can go badly awry if not used extremely carefully, and in which very small errors in the inputs can lead to very large errors in the outputs. This is particularly the case when there are large feedback effects around. It is hard to use equilibrium reasoning to work out the effect of a rise in the price of labour, because changing the price of labour changes the demand curve for all goods, and hence raising the demand for labour. This isn’t an insuperable modelling difficulty; but it means that it will take more than the back of a napkin to work out even approximately what will happen when the price of labour changes. Similarly, weather forecasting using equilibrium models is possible, but has to be done very carefully because very small errors in the initial inputs can push the modeller to an equilibrium that is far removed from reality.</p>
<p>We see the same problems when reasoning about morality. The method of reflective equilibrium, that characteristic coherentist form of reasoning, is the best method we’ve got for working out what is right and wrong. And it is very powerful. But it is an equilibrium method, and we are in a territory where there are very strong feedback effects. Whether one things X’s treatment of Y is right or wrong will depend a lot on other moral judgments. If X is imprisoning Y, then that is probably very seriously wrong, unless Y has themselves done something seriously wrong, and X has been empowered (preferably by a good set of institutions) to deal with that kind of wrongdoing. Given there are this many feedback effects, we should expect that whether moral reflection leads people closer to, or away from, the truth is in part a function of how close they start to the moral truth. And this is, I think, what we see. To the extent moral reflection strikes us as a basically good practice, it is because we imagine it being used by people who have basically good motivations to start with. But in those cases moral reasoning will help smooth out the rough edges; it won’t correct major faults.</p>
<p>And this suggests a problem with having morality itself as one of one’s motivations: it is dangerous. Unless one starts with basically good motivations, thinking about the good and aiming for it could very well make things worse; perhaps catastrophically worse. We should acknowledge that in the hands of good people, moral reasoning can be a useful tool. The person who doesn’t use that tool will almost certainly fail to optimise unless they have the sentiments of a saint. But someone whose aims include respect for others and their rights, freeing people from deprivation, promoting friendship and education, and being honest in their dealings, will usually act fairly well, even if they never engage in moral reflection. They may get the balance between these aims wrong from time to time, sometimes in ways that moral reflection would prevent. But they will typically avoid moral disaster. The person who aims for the good, as such, is more likely to land in disaster. One of the most dangerous things in the world is a wrongdoer with the courage of their convictions. Thinking about how and why equilibrium analyses can fail reinforces how dangerous this trap is.</p>
<p>But it’s not just theory that tells us this is dangerous. The fanatic who thinks the individual is irrelevant, who will sacrifice any number of individuals to an idea, who will destroy villages in order to save them, is a recurring character in history. In some cases they are tragic figures; people who really did start out with praiseworthy aims but who refused to compromise when it turned out that those aims couldn’t be realised without much suffering. And sometimes they are self-centred jerks, who feel empty unless they are trying to steer the whole world to their vision, whatever the costs. But what all of them teach us is that aiming for the good, and just the good, can go terribly, horribly, wrong.</p>
</section>
<section id="backtosymmetryandmoraluncertainty" class="level3" data-number="3.7.3">
<h3 data-number="3.7.3" class="anchored" data-anchor-id="backtosymmetryandmoraluncertainty"><span class="header-section-number">3.7.3</span> Back to Symmetry, and Moral Uncertainty</h3>
<p>Let’s turn away from these ideologues, and towards a positive picture of what a good but flawed person should look like. Our hero will mostly desire things that are actually valuable, and by and large desire them to the extent that they are actually valuable. They will have a well-functioning belief-desire psychology, so they will act so as to promote or respect those valuable things they desire. They will, from time to time, think about what is good and what is valuable, and form largely true beliefs about the good and the valuable. But since we are not supposing they are perfect, we will not assume these beliefs are inevitably true. And these moral beliefs, even the true ones, will not necessarily lead to much change in their action, because they don’t connect up with any desire in the right kind of way. It is normal for a mismatch between desires and moral beliefs to lead to some unease, and to think that it might be wise to reform one’s beliefs or one’s desires. But depending on how deep the disagreement is, this reform program need not be a particularly high priority. And when it is carried out, there is no guarantee that the two will be brought into line by changing desires, as opposed to by changing beliefs. What there is a guarantee of is that if the moral beliefs conflict with other first order desires that the hero has, such as a desire that mass killings not happen, those other first order desires will play a powerful role in stopping the moral beliefs from taking control.</p>
<p>It is a thought almost as old as European philosophy that there is a good analogy between the well functioning polis and the well functioning mind. Although it is much less old, it is by now a venerable idea that the well functioning polis includes a separation of powers. And one of the virtues of such a separation of powers is that it limits the damage that can be done by a sudden swing in opinion among the powers that be. This is not a panacea; some states are rotten to the core, and no amount of institutional design will help. But it will prevent, or at least moderate, certain kinds of wrong. To put it in late 18th Century terms, the Alien and Sedition Acts were bad; the Reign of Terror was worse. It’s worth thinking about what checks and balances in moral psychology would be, and more generally what a Madisonian moral psychology would look like.</p>
<p>My best guess is that competing desires, such as desires to promote welfare and alleviate suffering, and desires to keep promises and respect rights, are the appropriate kinds of balance to each other. But for current purposes it doesn’t matter exactly how one ought implement checks and balances, only that it is good that there are some. Because if moral uncertainty should be treated the same way as factual uncertainty, then there will be no checks and balances at all. When we firmly believe that some fact is true, then the thing to do is simply act as if that’s true. We only hedge against the possibility that something is false when there is a possibility that it is false; not when we are certain that it is true. The symmetry view says that we should do the same with moral (un)certainty. But if that’s the case, then there is no space for any check or balance on our moral views at all; when we are certain of them, they are guiding. That is wrong, and dangerous, so the symmetry view is also wrong.</p>
<p>Sometimes good people get the moral facts wrong. Perhaps they get bad advice, or bad evidence. Perhaps they start just a little wrong and equilibrium reasoning takes them to a place that is very wrong. When that happens, they have mechanisms to stop them acting seriously wrongly. I’ve been arguing that the moral mistakes shouldn’t have any direct effect on action, because they won’t aim at the good. But as I’ve noted already, I don’t need anything that strong for the main argument of this book. What I need is that there should be some other forces that prevent action from lining up perfectly with moral belief when moral belief is seriously mistaken. A natural suggestion is that desires for things that are actually good can be that force. But even if that suggestion is wrong, as long as there should be some other force, then the symmetry claim fails.</p>
</section>
</section>
<section id="motivationthroughthickandthin" class="level2" data-number="3.8">
<h2 data-number="3.8" class="anchored" data-anchor-id="motivationthroughthickandthin"><span class="header-section-number">3.8</span> Motivation Through Thick and Thin</h2>
<p>In this section I’m going to run through some interesting test cases for WMP and SMP. I have two aims here. First, I want to strengthen the case for WMP. Second, I want to raise some cases that are useful intuition checks for testing the plausibility of the SMP. I know from talking to many people about the cases that I have different views about them to most people. So while I think the cases are evidence for a fairly strong version of the SMP, I know that they won’t strike many people that way. Still, I hope the cases are useful ones for thinking about what’s at issue in debating the SMP, and in particular thinking about how we should interpret the phrase ‘moderately thin’ in it if we want the principle to be plausible. But let’s start with a case purely about maximally thin moral properties.</p>
<p><span data-acronym-label="Milan" data-acronym-form="singular+short">Milan</span> is torn between two theories, and two actions. He gives some credence to an agent-neutral form of consequentialism, and some credence to a Kantian ethical theory. And he is torn between making a moderate donation to charity, one of 3% of his income, and a much larger donation to charity, one of 30% of his income (which is all he can reasonably afford). He thinks that if the Kantian theory is true, then he isn’t obliged to give more than 3%, and really doesn’t want to give any more than he has to give. But he knows that if the consequentialist theory is true, then he is obliged to give (at least) the much larger amount.</p>
<p>Now <span data-acronym-label="Milan" data-acronym-form="singular+short">Milan</span> thinks most of the arguments favour the Kantian theory. But he has one remaining worry. He knows that the theory relies on having a workable notion of what it is for different people to do the same thing. And he worries that we don’t have such a workable notion, for reasons familiar from philosophy &nbsp;<span class="citation" data-cites="Goodman1955">(<a href="references.html#ref-Goodman1955" role="doc-biblioref">Goodman 1955</a>)</span> and game theory &nbsp;<span class="citation" data-cites="ChoKreps1987">(<a href="references.html#ref-ChoKreps1987" role="doc-biblioref">Cho and Kreps 1987</a>)</span>. So he sets out to do some philosophical research, reading about work on the notion of same action, and thinking about whether any such notion can generate a version of the categorical imperative that agrees with its intuitive content, and is not trivial. As often happens when working through a philosophical problem, his views on which side is stronger changes frequently. All the time, he has a web browser open getting ready to hit send on a donation. And as he changes his mind on whether the grue paradox ultimately defeats Kant’s theory, he keeps adding and deleting a final zero from the amount in the box saying how much he will donate.</p>
<p>The WMP says that moral agents are not obliged to be like <span data-acronym-label="Milan" data-acronym-form="singular+short">Milan</span>. They don’t have to have their charitable actions be sensitive to their beliefs about technical problems for Kantian ethics. It is, I think, reasonable to have one’s credence in the correctness of Kantian ethics turn on beliefs about relatively technical problems. (For what it’s worth, I think the kind of problem Milan is worrying about is a genuine problem for some kinds of Kantian theory, particularly those that think the formality of the theory is an important virtue of it.) But an agent who is being epistemically reasonable need not have their actions be sensitive to their technical worries. And that’s because the agent need not be motivated by rightness as such.</p>
<p>If we change the case a little, we get an interesting test for SMP. Unlike <span data-acronym-label="Milan" data-acronym-form="singular+short">Milan</span>, <span data-acronym-label="Torin" data-acronym-form="singular+short">Torin</span> is convinced that some kind of Kantian theory is true. He also thinks there are technical problems with getting the formulation of the categorical imperative right. But he also thinks, sensibly enough, that these kind of technical problems are challenges, not reasons to reject the theory. Still, the way to solve the challenge will be to formulate different versions of the categorical imperative, and test them. And these different versions will have different consequences for which actions are required in certain circumstances. Is it reasonable for <span data-acronym-label="Torin" data-acronym-form="singular+short">Torin</span> to be differently motivated when he changes his views about which is quite the right formulation of the categorical imperative? I don’t feel that it is, but I can imagine that different people have different views here.</p>
<p>A slightly more natural case seems even trickier to come to a firm judgment about.<span data-acronym-label="Florentina" data-acronym-form="singular+short">Florentina</span> is trying to figure out what to do in a case where there are competing reasons in favour of two incompatible actions. She feels rather torn, but can’t settle on a particular choice. Then she notices something: one of the choices, but not the other, is incompatible with the categorical imperative. Is it reasonable for her to be now more motivated to do the one that is consistent? I think this is a somewhat strange mindset, but I suspect many will disagree. What makes this case tricky is that we have to distinguish two situations that are rather hard to keep apart. We aren’t interested in the case where <span data-acronym-label="Florentina" data-acronym-form="singular+short">Florentina</span> sees that a choice is incompatible with the categorical imperative, and by seeing this sees that she had been overvaluing its strengths or undervaluing its weaknesses. Rather, we are interested in the case where this fact about the categorical imperative is itself a new motivation, alongside all the old motivations, to not do a particular action. To the extent I can keep a clear grip on the case, I think this is not a reasonable stance for <span data-acronym-label="Florentina" data-acronym-form="singular+short">Florentina</span> to take. And that’s why I think that it is wrong to be motivated by an action’s compatibility or otherwise with the categorical imperative. What is reasonable is to see incompatibility with the categorical imperative as a reason for thinking there is something else wrong with the action, perhaps something we haven’t yet seen.</p>
<p><span data-acronym-label="Florentina" data-acronym-form="singular+short">Florentina</span>’s case is interesting even if you think that basing a whole moral theory around the categorical imperative is implausible. You can think that such a theory is surely wrong, but also think that Kant was nevertheless on to something important. Whether one could rationally will that everyone does X could be a factor in determining whether X is right or wrong, even if it is a long way from being a central factor. My default view in first-order ethics is a kind of muddy pluralism, which acknowledges that many distinct moral traditions have important insights into the nature of rightness and goodness, but which rejects any claim to comprehensiveness these theories may make. <span data-acronym-label="Florentina" data-acronym-form="singular+short">Florentina</span>’s case suggests that even if you have such a kind of pluralist view, you still could reject the view that conformity with the categorical imperative is a good motivation.</p>
<p>Let’s move to some cases that seem a little easier. (I owe the following case to discussions with Scott Hershowitz.) <span data-acronym-label="Mercurius" data-acronym-form="singular+short">Mercurius</span> is a professor in a large university. As with most professorial positions, <span data-acronym-label="Mercurius" data-acronym-form="singular+short">Mercurius</span> has a fair amount of control over how much work he does. Some of his colleagues do more for the department than anyone could reasonably require, some do less than anyone could think was reasonable. <span data-acronym-label="Mercurius" data-acronym-form="singular+short">Mercurius</span> is a reasonable department citizen, handling a perfectly fair share of the workload, but only just as much as fairness requires. Today, as sometimes happens, a request comes around from the chair for volunteers for an unexpected task. <span data-acronym-label="Mercurius" data-acronym-form="singular+short">Mercurius</span> does not find the task intrinsically interesting, but he knows that none of his colleagues will feel any differently. He knows he will feel a bit bad for whoever ends up shouldering the task, but will feel worse if it ends up being him. Still, he is worried he hasn’t done his fair share of the work. This is wrong, as I said he has done enough, but it isn’t an irrational belief since it is such a close call. So he volunteers, being motivated by a desire to do his fair share of the collective work.</p>
<p>This strikes me, and most people I’ve spoken about the case with, as a perfectly reasonable motivation. There is nothing objectionably fetishistic about being motivated to do one’s share of a task one values. And <span data-acronym-label="Mercurius" data-acronym-form="singular+short">Mercurius</span> does value the good functioning of his department, and knows that it requires that the members collectively take on some unpleasant tasks. So he acquires a motivation to take on this particular unpleasant task.</p>
<p>It isn’t easy to classify <span data-acronym-label="Mercurius" data-acronym-form="singular+short">Mercurius</span>’s desire using the terminology we discussed in the previous section. He certainly doesn’t have an intrinsic desire to do the unpleasant task. And it isn’t strictly speaking an instrumental desire. We can imagine that <span data-acronym-label="Mercurius" data-acronym-form="singular+short">Mercurius</span> knows that one of the usual suspects, the people who already do more than their fair share, will take on this unpleasant task if no one else does. And we don’t have to imagine that <span data-acronym-label="Mercurius" data-acronym-form="singular+short">Mercurius</span> values their time more than his. Nor is it quite right to say that <span data-acronym-label="Mercurius" data-acronym-form="singular+short">Mercurius</span>’s desire to do this job is a realizer desire of his desire that the department runs well. After all, if he had just taken on a similar task the previous week, he would not desire to take on this one, although its relationship to the good functioning of the department would be unchanged. The best thing to say is that <span data-acronym-label="Mercurius" data-acronym-form="singular+short">Mercurius</span> has an intrinsic desire to do his fair share of collective projects that he has joined, and given his (false) beliefs about his past actions, this creates a realizer desire to do this unpleasant task.</p>
<p>So that puts an upper bound on the extension of ‘moderately thin’ in SMP. There isn’t anything wrong with having a desire to do one’s fair share, i.e., being motivated by properties like fairness. But on the other hand, thinking about these ‘fair share’ or ‘good teammate’ motivations helps explain some otherwise tricky cases. Indeed, my suspicion is that most intuitive counterexamples to the WMP, or even the SMP, can be helpfully thought of as cases where the agent has some independent motivation for joining a team or a project, and then a desire to be a good member of that team or project.</p>
<p>That’s what I want to say about, for example, this case from Hallvard <span class="citation" data-cites="Lillehammer1997">Lillehammer (<a href="references.html#ref-Lillehammer1997" role="doc-biblioref">1997</a>)</span>.</p>
<blockquote class="blockquote">
<p>Consider next the case of the father who discovers that his son is a murderer, and who knows that if he does not go to the police the boy will get away with it, whereas if he does go to the police the boy will go to the gas-chamber. The father judges that it is right to go to the police, and does so. In this case it is not a platitude that a desire to do what is right, where this is read <em>de re</em>, is the mark of moral goodness. If what moves the father to inform on his son is a standing desire to do what is right, where this is read <em>de dicto</em>, then this could be as much of a saving grace as a moral failing. Why should it be an a priori demand that someone should have an underived desire to send his son to death? &nbsp;<span class="citation" data-cites="Lillehammer1997">(<a href="references.html#ref-Lillehammer1997" role="doc-biblioref">Lillehammer 1997, 192</a>)</span></p>
</blockquote>
<p>A well functioning justice system is a very valuable thing to have. There is nothing at all fetishistic about desiring that one’s state have such a system, and that it be maintained. Yet a well functioning justice system requires collective action, and this generates issues about whether one is doing one’s fair share. As noted above, it can be reasonable, and not at all inconsistent with WMP, to desire to do one’s fair share of a group project. Here the father who informs on his son should be motivated not be a desire to do what’s right as such, but by a desire to do one’s fair share of maintaining a good justice system.</p>
<p>If that’s the right analysis of the case, then the father should be less motivated the less difference his informing will make to whether the state has a well functioning justice system. We see this already in Lillehammer’s version of the case; the injustice of capital punishment is a reason for thinking that informing is not really a way of doing one’s share in maintaining a system of justice. But similarly, if the family lives in a state where justice is very much the exception, it’s reasonable to be less motivated to inform on one’s son. By analogy, if tasks like the one <span data-acronym-label="Mercurius" data-acronym-form="singular+short">Mercurius</span> is considering routinely go undone, so there is no good functioning to maintain, that’s a reason to be less motivated to take on this task.</p>
<p>Finally, consider a case about welfare, which has interesting lessons for moral motivations. <span data-acronym-label="Xue" data-acronym-form="singular+short">Xue</span> believes that human welfare is entirely constituted by health, happiness and friendship. And she is strongly motivated to promote her own health, happiness and friendships, which is natural enough given that belief. She is also motivated to help others–she is no moral monster–but for now we’re just interested in her prudential reasoning.</p>
<p><span data-acronym-label="Xue" data-acronym-form="singular+short">Xue</span> is told that bushwalking is good for your welfare, though she isn’t told whether it makes you healthier, happier or have better friendships. But the source of this information is very reliable, so <span data-acronym-label="Xue" data-acronym-form="singular+short">Xue</span> forms a desire to do more bushwalking. And this seems reasonable enough. Is this a case where <span data-acronym-label="Xue" data-acronym-form="singular+short">Xue</span> is motivated by welfare as such, and reasonably so?</p>
<p>I think it isn’t. We have to distinguish three possible states.</p>
<ol type="1">
<li><span data-acronym-label="Xue" data-acronym-form="singular+short">Xue</span> is motivated to do things that have the property <em>promote my health</em>, and is motivated to do things that have the property <em>promote my happiness</em>, and is motivated to do things that have the property <em>promote my friendships</em>.</li>
<li><span data-acronym-label="Xue" data-acronym-form="singular+short">Xue</span> is motivated to do things that have the disjunctive property <em>either promote my health, or promote my happiness, or promote my friendships</em>.</li>
<li><span data-acronym-label="Xue" data-acronym-form="singular+short">Xue</span> is motivated to do things that have the property <em>promote my welfare</em>.</li>
</ol>
<p>Assuming fairly minimal coherence, we can’t tell the difference between 1 and 2 by just looking at <span data-acronym-label="Xue" data-acronym-form="singular+short">Xue</span>’s actions. Whether 1 or 2 were correct, she would do the same things in almost all circumstances. Perhaps she would say different things if the issue of whether she had disjunctive or non-disjunctive motivations arose in conversation. But we need not assume she has any interests in such a question, or even a pre-existing disposition as to how she would answer it. But that doesn’t mean that there is no difference between the states. It is, in general, better practice to attribute non-disjunctive attitudes to agents rather than disjunctive ones &nbsp;<span class="citation" data-cites="Lewis1994b Weatherson2013Lewis">(<a href="references.html#ref-Lewis1994b" role="doc-biblioref">Lewis 1994</a>; <a href="references.html#ref-Weatherson2013Lewis" role="doc-biblioref">Weatherson 2013</a>)</span>. So we should think that we are in state 1 rather than state 2.</p>
<p>Similarly, given her beliefs about the nature of welfare, there won’t be much difference between the actions she is motivated to perform in state 1 and in state 3. So the fact that she responds to the information that bushwalking is good for her welfare by developing a desire for bushwalking is no evidence that we are in state 3. It might just be that we are in state 1. Since there is independent intutive reason to think it would be unreasonable for her to be in state 3, and her desire for bushwalking in this case is reasonable, we should think that we’re actually in state 1. In general, we should prefer to attribute a plurality of underlying motivations to agents, rather than disjunctive motivations (as in state 2), or higher-order motivations (as in state 3).</p>
</section>
<section id="mollersexample" class="level2 page-columns page-full" data-number="3.9">
<h2 data-number="3.9" class="anchored" data-anchor-id="mollersexample"><span class="header-section-number">3.9</span> Moller’s Example</h2>
<p>I’ll end this chapter by discussing an analogy D. <span class="citation" data-cites="Moller2011">Moller (<a href="references.html#ref-Moller2011" role="doc-biblioref">2011</a>)</span> offers to motivate something like symmetry.<a href="#fn6" class="footnote-ref" id="fnref6" role="doc-noteref"><sup>6</sup></a></p>
<div class="no-row-height column-margin column-container"><li id="fn6"><p><sup>6</sup>&nbsp;Though note that Moller’s own position is more moderate than the genuinely symmetric position; he thinks moral risk should play a role in reasoning, but not necessarily as strong as non–moral risk plays. In contrast, I’m advocating what he calls the “extreme view, [that] we never need to take moral risk into account; it is always permissible to take moral risks.” (435).</p></li></div><blockquote class="blockquote">
<p>Suppose <span data-acronym-label="Frank" data-acronym-form="singular+short">Frank</span> is the dean of a large medical school. Because his work often involves ethical complications touching on issues like medical experimentation and intellectual property, <span data-acronym-label="Frank" data-acronym-form="singular+short">Frank</span> has an ethical advisory committee consisting of 10 members that helps him make difficult decisions. One day <span data-acronym-label="Frank" data-acronym-form="singular+short">Frank</span> must decide whether to pursue important research for the company in one of two ways: plan A and plan B would both accomplish the necessary research, and seem to differ only to the trivial extent that plan A would involve slightly less paperwork for <span data-acronym-label="Frank" data-acronym-form="singular+short">Frank</span>. But then <span data-acronym-label="Frank" data-acronym-form="singular+short">Frank</span> consults the ethics committee, which tells him that although everyone on the committee is absolutely convinced that plan B is morally permissible, a significant minority - four of the members - feel that plan A is a moral catastrophe. So the majority of the committee thinks that the evidence favors believing that both plans are permissible, but a significant minority is confident that one of the plans would be a moral abomination, and there are practically no costs attached to avoiding that possibility. Let’s assume that <span data-acronym-label="Frank" data-acronym-form="singular+short">Frank</span> himself cannot investigate the moral issues involved - doing so would involve neglecting his other responsibilities. Let’s also assume that <span data-acronym-label="Frank" data-acronym-form="singular+short">Frank</span> generally trusts the members of the committee and has no special reason to disregard certain members’ opinions. Suppose that <span data-acronym-label="Frank" data-acronym-form="singular+short">Frank</span> decides to go ahead with plan A, which creates slightly less paperwork for him, even though, as he acknowledges, there seems to be a pretty significant chance that enacting that plan will result in doing something very deeply wrong and he has a virtually cost-free alternative. &nbsp;<span class="citation" data-cites="Moller2011">(<a href="references.html#ref-Moller2011" role="doc-biblioref">Moller 2011, 436</a>)</span></p>
</blockquote>
<p>The intuitions are supposed to be that this is a very bad thing for <span data-acronym-label="Frank" data-acronym-form="singular+short">Frank</span> to do, and that this illustrates that there’s something very wrong with ignoring moral risk. But once we fill in the details of the case, this can’t be the right diagnosis.</p>
<p>The first thing to note is that there is something special about decision making as the head of an organization. <span data-acronym-label="Frank" data-acronym-form="singular+short">Frank</span> doesn’t just have a duty to do what he thinks is best. He has a duty to reflect his school’s policies and viewpoints. A dean is not a dictator, not even an enlightened, benevolent one. Not considering an advisory committee’s report is bad practice qua dean of the medical school, whether or not <span data-acronym-label="Frank" data-acronym-form="singular+short">Frank</span>’s own decisions should be guided by moral risk.</p>
<p>We aren’t told whether A or B are moral catastrophes. If B is a moral catastrophe, and A isn’t, there’s something good about what <span data-acronym-label="Frank" data-acronym-form="singular+short">Frank</span> does. Of course, he does it for the wrong reasons, and that might undercut our admiration of him. But it does seem relevant to our assessment to know whether A or B are actually permissible.</p>
<p>Assuming that B is actually permissible, the most natural reading of the case is that <span data-acronym-label="Frank" data-acronym-form="singular+short">Frank</span> shouldn’t do A. Or, at least, that he shouldn’t do A for the reason he does. But that doesn’t mean he should be sensitive to moral risk. Unless the four members who think that A is a moral catastrophe are crazy, there must be some non-moral facts that make A morally risky. If <span data-acronym-label="Frank" data-acronym-form="singular+short">Frank</span> doesn’t know what those facts are, then he isn’t just making a decision under moral risk, he’s making a decision involving physical risk. And that’s clearly a bad thing to do.</p>
<p>If <span data-acronym-label="Frank" data-acronym-form="singular+short">Frank</span> does know why the committee members think that the plan is a moral catastrophe, his action is worse. Authorising a particular kind of medical experimentation, when you know what effects it will have on people, and where intelligent people think this is morally impermissible, on the basis of convenience seems to show a striking lack of character and judgment. Even if <span data-acronym-label="Frank" data-acronym-form="singular+short">Frank</span> doesn’t have the time to work through all the ins and outs of the case, it doesn’t follow that it is permissible to make decisions based on convenience, rather than based on some (probably incomplete) assessment of the costs and benefits of the program. (I’ll expand on this point in section 6.1, when I discuss in more detail what a normative externalist should say about hypocrisy.)</p>
<p>But having said all that, there’s one variant of this case, perhaps somewhat implausible, where it doesn’t seem that <span data-acronym-label="Frank" data-acronym-form="singular+short">Frank</span> should listen to the committee at all. Assume that both <span data-acronym-label="Frank" data-acronym-form="singular+short">Frank</span> and the committee have a fairly thick understanding of what’s involved in doing A and B. They know which actions maximise expected utility, they know that which acts are consistent with the categorical imperative, they know which people affected by the acts would be entitled to complain about our performance, or non-performance, of each act, they know which acts are such that everyone could rationally will it to be true that everyone believes those acts to be morally permitted, and so on. What they disagree about is what rightness and wrongness consist in. What’s common knowledge between <span data-acronym-label="Frank" data-acronym-form="singular+short">Frank</span>, the majority and the minority is that both A and B pass all these tests, with one exception: A is not consistent with the categorical imperative. And the minority members of the committee are committed Kantians, who think that they have a response to the best recent anti-Kantian arguments.</p>
<p>It seems to me, intuitively, that this shouldn’t matter one whit. I’m not resting the arguments of this book on the intuitiveness of my views. That’s in part due to doubts about the usefulness of intuition, but more due to how unintuitive normative externalism often is. But it is worth noting how counterintuitive the opposing internalist view is in this extreme case. A moral agent making a practical deliberation simply won’t care what the latest journal articles have been saying about the pros and cons of Kantianism. It’s possible (though personally I doubt it), that learning of an action that it violates the categorical imperative would be relevant to one’s motivations. It’s not possible that learning that some people you admire think the categorical imperative is central to morality could change one’s motivation to perform, or not perform, actions one knew all along violated the categorical imperative. At least that’s not possible without falling into the bad kind of moral fetishism that Smith rightly decries.</p>
<p>So here’s my general response to analogies of this kind, one that should not be surprising given the previous sections. Assuming the minority committee members are rational, either they know some facts about the impacts of A and B that <span data-acronym-label="Frank" data-acronym-form="singular+short">Frank</span> is unaware of, or they hold some philosophical theory that <span data-acronym-label="Frank" data-acronym-form="singular+short">Frank</span> doesn’t. If it’s the former, <span data-acronym-label="Frank" data-acronym-form="singular+short">Frank</span> should take their concerns into account; but that’s not because he should be sensitive to moral risk, it’s because he should be sensitive to non-moral risk. If it’s the latter, <span data-acronym-label="Frank" data-acronym-form="singular+short">Frank</span> shouldn’t take their concerns into account; that would be moral fetishism.</p>


<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list" style="display: none">
<div id="ref-Arpaly2003" class="csl-entry" role="listitem">
Arpaly, Nomy. 2003. <em>Unprincipled Virtue</em>. Oxford: Oxford University Press.
</div>
<div id="ref-ArpalySchroeder2014" class="csl-entry" role="listitem">
Arpaly, Nomy, and Timothy Schroeder. 2014. <em>In Praise of Desire</em>. Oxford: Oxford University Press.
</div>
<div id="ref-Buchak2013" class="csl-entry" role="listitem">
Buchak, Lara. 2014. <span>“Belief, Credence and Norms.”</span> <em>Philosophical Studies</em> 169 (2): 285–311. <a href="https://doi.org/10.1007/s11098-013-0182-y">https://doi.org/10.1007/s11098-013-0182-y</a>.
</div>
<div id="ref-ChoKreps1987" class="csl-entry" role="listitem">
Cho, In-Koo, and David M. Kreps. 1987. <span>“Signalling Games and Stable Equilibria.”</span> <em>The Quarterly Journal of Economics</em> 102 (2): 179–221. <a href="https://doi.org/10.2307/1885060">https://doi.org/10.2307/1885060</a>.
</div>
<div id="ref-Finnis2011" class="csl-entry" role="listitem">
Finnis, John. 2011. <em>Natural Law and Natural Rights</em>. Second. Oxford: Oxford University Press.
</div>
<div id="ref-Goodman1955" class="csl-entry" role="listitem">
Goodman, Nelson. 1955. <em>Fact, Fiction and Forecast</em>. Cambridge: Harvard University Press.
</div>
<div id="ref-Harman2014" class="csl-entry" role="listitem">
Harman, Elizabeth. 2015. <span>“The Irrelevance of Moral Uncertainty.”</span> <em>Oxford Studies in Metaethics</em> 10: 53–79. <a href="https://doi.org/10.1093/acprof:oso/9780198738695.003.0003">https://doi.org/10.1093/acprof:oso/9780198738695.003.0003</a>.
</div>
<div id="ref-Jackson1991" class="csl-entry" role="listitem">
Jackson, Frank. 1991. <span>“Decision Theoretic Consequentialism and the Nearest and Dearest Objection.”</span> <em>Ethics</em> 101: 461–82. <a href="https://doi.org/10.1086/293312">https://doi.org/10.1086/293312</a>.
</div>
<div id="ref-Lewis1988b" class="csl-entry" role="listitem">
Lewis, David. 1988. <span>“Desire as Belief.”</span> <em>Mind</em> 97 (387): 323–32. <a href="https://doi.org/10.1093/mind/XCVII.387.323">https://doi.org/10.1093/mind/XCVII.387.323</a>.
</div>
<div id="ref-Lewis1994b" class="csl-entry" role="listitem">
———. 1994. <span>“Reduction of Mind.”</span> In <em>A Companion to the Philosophy of Mind</em>, edited by Samuel Guttenplan, 412–31. Oxford: Blackwell. <a href="https://doi.org/10.1017/CBO9780511625343.019">https://doi.org/10.1017/CBO9780511625343.019</a>.
</div>
<div id="ref-Lewis1996a" class="csl-entry" role="listitem">
———. 1996. <span>“Desire as Belief <span>II</span>.”</span> <em>Mind</em> 105 (418): 303–13. <a href="https://doi.org/10.1093/mind/105.418.303">https://doi.org/10.1093/mind/105.418.303</a>.
</div>
<div id="ref-Lillehammer1997" class="csl-entry" role="listitem">
Lillehammer, Hallvard. 1997. <span>“Smith on Moral Fetishism.”</span> <em>Analysis</em> 57 (3): 187–95. <a href="https://doi.org/10.1111/1467-8284.00073">https://doi.org/10.1111/1467-8284.00073</a>.
</div>
<div id="ref-Markovits2010" class="csl-entry" role="listitem">
Markovits, Julia. 2010. <span>“Acting for the Right Reasons.”</span> <em>Philosophical Review</em> 119 (2): 201–42. <a href="https://doi.org/10.1215/00318108-2009-037">https://doi.org/10.1215/00318108-2009-037</a>.
</div>
<div id="ref-Moller2011" class="csl-entry" role="listitem">
Moller, D. 2011. <span>“Abortion and Moral Risk.”</span> <em>Philosophy</em> 86 (3): 425–43. <a href="https://doi.org/10.1017/S0031819111000222">https://doi.org/10.1017/S0031819111000222</a>.
</div>
<div id="ref-Moore1903" class="csl-entry" role="listitem">
Moore, G. E. 1903. <em>Principia Ethica</em>. Cambridge: Cambridge University Press.
</div>
<div id="ref-Palmer1941" class="csl-entry" role="listitem">
Palmer, R. R. 1941. <em>Twelve Who Ruled</em>. Princeton, NJ: Princeton University Press.
</div>
<div id="ref-RussellHawthorne2016" class="csl-entry" role="listitem">
Russell, Jeffrey Sanford, and John Hawthorne. 2016. <span>“General Dynamic Triviality Theorems.”</span> <em>Philosophical Review</em> 125 (3): 307–39. <a href="https://doi.org/10.1215/00318108-3516936">https://doi.org/10.1215/00318108-3516936</a>.
</div>
<div id="ref-Smith1994" class="csl-entry" role="listitem">
Smith, Michael. 1994. <em>The Moral Problem</em>. Oxford: Blackwell.
</div>
<div id="ref-Smith1996" class="csl-entry" role="listitem">
———. 1996. <span>“The Argument for Internalism: Reply to Miller.”</span> <em>Analysis</em> 56 (3): 175–84. <a href="https://doi.org/10.1111/j.0003-2638.1996.00175.x">https://doi.org/10.1111/j.0003-2638.1996.00175.x</a>.
</div>
<div id="ref-Svavarsdottir1999" class="csl-entry" role="listitem">
Svavarsdóttir, Sigrún. 1999. <span>“Moral Cognition and Motivation.”</span> <em>Philosophical Review</em> 108 (2): 161–219. <a href="https://doi.org/10.2307/2998300">https://doi.org/10.2307/2998300</a>.
</div>
<div id="ref-Weatherson2013Lewis" class="csl-entry" role="listitem">
Weatherson, Brian. 2013. <span>“The Role of Naturalness in Lewis’s Theory of Meaning.”</span> <em>Journal for the History of Analytical Philosophy</em> 1 (10): 1–19. <a href="https://doi.org/10.4148/jhap.v1i10.1620">https://doi.org/10.4148/jhap.v1i10.1620</a>.
</div>
<div id="ref-Zimmerman2008" class="csl-entry" role="listitem">
Zimmerman, Michael J. 2008. <em>Living with Uncertainty: The Moral Significance of Ignorance</em>. Cambridge: Cambridge University Press.
</div>
</div>
</section>


</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
    const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
    const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
    let newTheme = '';
    if(darkModeDefault) {
      newTheme = isAlternate ? baseTheme : alternateTheme;
    } else {
      newTheme = isAlternate ? alternateTheme : baseTheme;
    }
    const changeGiscusTheme = () => {
      // From: https://github.com/giscus/giscus/issues/336
      const sendMessage = (message) => {
        const iframe = document.querySelector('iframe.giscus-frame');
        if (!iframe) return;
        iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
      }
      sendMessage({
        setConfig: {
          theme: newTheme
        }
      });
    }
    const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
    if (isGiscussLoaded) {
      changeGiscusTheme();
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  const darkModeDefault = false;
  let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
    toggleGiscusIfUsed(toAlternate, darkModeDefault);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    const typesetMath = (el) => {
      if (window.MathJax) {
        // MathJax Typeset
        window.MathJax.typeset([el]);
      } else if (window.katex) {
        // KaTeX Render
        var mathElements = el.getElementsByClassName("math");
        var macros = [];
        for (var i = 0; i < mathElements.length; i++) {
          var texText = mathElements[i].firstChild;
          if (mathElements[i].tagName == "SPAN") {
            window.katex.render(texText.data, mathElements[i], {
              displayMode: mathElements[i].classList.contains('display'),
              throwOnError: false,
              macros: macros,
              fleqn: false
            });
          }
        }
      }
    }
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        typesetMath(container);
        return container.innerHTML
      } else {
        typesetMath(note);
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      typesetMath(note);
      return note.innerHTML;
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./internalism.html" class="pagination-link  aria-label=" &lt;span="" about="" internalism&lt;="" span&gt;"="">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">All About Internalism</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./dilemma.html" class="pagination-link" aria-label="<span class='chapter-number'>4</span>&nbsp; <span class='chapter-title'>A Dilemma for Internalism</span>">
        <span class="nav-page-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">A Dilemma for Internalism</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




</body></html>