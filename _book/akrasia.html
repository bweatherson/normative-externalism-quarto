<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.523">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Normative Externalism - 10&nbsp; Akrasia</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./screening.html" rel="next">
<link href="./circles.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="site_libs/bootstrap/bootstrap-dark.min.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<link rel="stylesheet" href="https://use.typekit.net/uzz2drx.css">

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

</head>

<body class="nav-sidebar floating slimcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./level.html">Epistemology</a></li><li class="breadcrumb-item"><a href="./akrasia.html"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Akrasia</span></a></li></ol></nav>
        <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Normative Externalism</a> 
        <div class="sidebar-tools-main tools-wide">
    <a href="https://github.com/bweatherson/normative-externalism-quarto" title="Source Code" class="quarto-navigation-tool px-1" aria-label="Source Code"><i class="bi bi-github"></i></a>
    <div class="dropdown">
      <a href="" title="Download" id="quarto-navigation-tool-dropdown-0" class="quarto-navigation-tool dropdown-toggle px-1" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download"><i class="bi bi-download"></i></a>
      <ul class="dropdown-menu" aria-labelledby="quarto-navigation-tool-dropdown-0">
          <li>
            <a class="dropdown-item sidebar-tools-main-item" href="./Normative-Externalism.pdf">
              <i class="bi bi-bi-file-pdf pe-1"></i>
            Download PDF
            </a>
          </li>
          <li>
            <a class="dropdown-item sidebar-tools-main-item" href="./Normative-Externalism.epub">
              <i class="bi bi-bi-journal pe-1"></i>
            Download ePub
            </a>
          </li>
          <li>
            <a class="dropdown-item sidebar-tools-main-item" href="./Normative-Externalism.docx">
              <i class="bi bi-bi-file-word pe-1"></i>
            Download Docx
            </a>
          </li>
      </ul>
    </div>
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./introduction.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction</span></span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">
 <span class="menu-text">Ethics</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./internalism.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">All About Internalism</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./symmetry.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Against Symmetry</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./dilemma.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">A Dilemma for Internalism</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./blame.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Blame and Moral Ignorance</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./double.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Double Standards</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true">
 <span class="menu-text">Epistemology</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./level.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Level-Crossing Principles</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./higher.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Higher-Order Evidence</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./circles.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Circles, Epistemic and Benign</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./akrasia.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Akrasia</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./screening.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Screening and Regresses</span></span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./disagreement.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Disagreement</span></span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./epilogue.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Epilogue</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">References</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar"><div class="quarto-margin-header"><div class="margin-header-item">
<p>&nbsp;</p>
</div></div>
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">In this chapter:</h2>
   
  <ul>
  <li><a href="#thepossibilityofakrasia" id="toc-thepossibilityofakrasia" class="nav-link active" data-scroll-target="#thepossibilityofakrasia"><span class="header-section-number">10.1</span> The Possibility of Akrasia</a></li>
  <li><a href="#threelevel-crossingprinciples" id="toc-threelevel-crossingprinciples" class="nav-link" data-scroll-target="#threelevel-crossingprinciples"><span class="header-section-number">10.2</span> Three Level-Crossing Principles</a></li>
  <li><a href="#whynotbeakratic" id="toc-whynotbeakratic" class="nav-link" data-scroll-target="#whynotbeakratic"><span class="header-section-number">10.3</span> Why Not Be Akratic</a></li>
  <li><a href="#self-awarenessandrationalreflection" id="toc-self-awarenessandrationalreflection" class="nav-link" data-scroll-target="#self-awarenessandrationalreflection"><span class="header-section-number">10.4</span> Self-Awareness and Rational Reflection</a></li>
  <li><a href="#akrasiaandoddstatements" id="toc-akrasiaandoddstatements" class="nav-link" data-scroll-target="#akrasiaandoddstatements"><span class="header-section-number">10.5</span> Akrasia and Odd Statements</a></li>
  <li><a href="#desireasbeliefreprise" id="toc-desireasbeliefreprise" class="nav-link" data-scroll-target="#desireasbeliefreprise"><span class="header-section-number">10.6</span> Desire as Belief (Reprise)</a></li>
  </ul>
<div class="toc-actions"><ul><li><a href="https://github.com/bweatherson/normative-externalism-quarto/issues/new" class="toc-action"><i class="bi bi-github"></i>Report an issue</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content page-columns page-full" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./level.html">Epistemology</a></li><li class="breadcrumb-item"><a href="./akrasia.html"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Akrasia</span></a></li></ol></nav>
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Akrasia</span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<p>The normative externalist seems to be committed to the following possibility. An agent, we’ll call her <span data-acronym-label="Aki" data-acronym-form="singular+short">Aki</span>, has been given excellent arguments in favour of a false sceptical thesis. For concreteness, we’ll assume the scepticism in question is testimonial scepticism. Nothing turns on the particular choice of sceptical thesis. But something does turn on whether there can be excellent arguments for any false sceptical thesis, and we’ll return to this assumption below. For now we’ll assume that <span data-acronym-label="Aki" data-acronym-form="singular+short">Aki</span> is confident that one cannot get reasons to believe propositions on the basis of testimony. And she is rational to be confident in this; it’s what her philosophical evidence supports. But, we’ll also assume, testimonial scepticism is false.</p>
<p><span data-acronym-label="Aki" data-acronym-form="singular+short">Aki</span> now learns the proposition that a long-time friend, who has not lied to her in the past, said that <em>p</em>. She has weak probabilistic reasons to have greater credence in ¬<em>p</em> than <em>p</em>, but these are the kinds of background reasons that are routinely overturned by testimony. The details don’t matter, but if it helps to make the case concrete, imagine that <em>p</em> is the proposition that the home team won last night’s baseball game, when it was known in advance that the away team was stronger, and was favoured to win. Upsets happen all the time in baseball, so a friend’s testimony that the home team won should be only mildly surprising, and cause one to believe that the home team won. Since in this case the friend’s testimony was caused by the fact that the home team did indeed win, it is doubly true that one should believe the friend.</p>
<p>And this is what <span data-acronym-label="Aki" data-acronym-form="singular+short">Aki</span> does. Despite her philosophical leanings, she can’t bring herself to not believe what her friend says. That she can’t follow her own views in this way shouldn’t be surprising. The ancient sceptical texts are filled with both arguments for scepticism, and techniques for putting one’s sceptical conclusions into practice. It was never assumed that mere belief in a sceptical view would suffice for control over one’s mental states &nbsp;<span class="citation" data-cites="Morison2014">(<a href="references.html#ref-Morison2014" role="doc-biblioref">Morison 2014</a>)</span>. <span data-acronym-label="Aki" data-acronym-form="singular+short">Aki</span> is just like the people that the ancient sceptics were writing for; people who believed their views but could not put them into practice.</p>
<p>And of course, it’s a good thing <span data-acronym-label="Aki" data-acronym-form="singular+short">Aki</span> does not have her theoretical doubts govern her beliefs. She gets a well-confirmed, and true, belief by trusting the testimony. Does she get knowledge? That’s a hard question, turning on whether one thinks that knowledge is incompatible with this kind of mistake by one’s own lights. I’m going to set that aside, and just focus on the fact that she gets a well-supported true belief. I think, though this is controversial, she gets a rational belief. So <span data-acronym-label="Aki" data-acronym-form="singular+short">Aki</span> is an epistemological case of what Arpaly calls inadvertent virtue. She forms the right belief, for the right reasons, while thinking these are bad reasons.</p>
<p>Normative externalism, of the kind I prefer, says that <span data-acronym-label="Aki" data-acronym-form="singular+short">Aki</span> is doing as well as she can in the circumstances. She is believing what her evidence supports. She violates a level-crossing principle, but since I’m arguing against level-crossing principles, I don’t take this to be a problem. Good for <span data-acronym-label="Aki" data-acronym-form="singular+short">Aki</span>, a paragon of rationality!</p>
<p>This take on <span data-acronym-label="Aki" data-acronym-form="singular+short">Aki</span>’s situation strikes many philosophers as implausible. Some philosophers go so far as to say that <span data-acronym-label="Aki" data-acronym-form="singular+short">Aki</span>’s situation is literally impossible; we cannot truly believe of <span data-acronym-label="Aki" data-acronym-form="singular+short">Aki</span> that she both believes <em>p</em> and believes that this is an irrational belief &nbsp;<span class="citation" data-cites="Hurley1989 Owens2002 Adler2002">(<a href="references.html#ref-Hurley1989" role="doc-biblioref">Hurley 1989</a>; <a href="references.html#ref-Owens2002" role="doc-biblioref">Owens 2002</a>; <a href="references.html#ref-Adler2002" role="doc-biblioref">Adler 2002</a>)</span>. Many others think that <span data-acronym-label="Aki" data-acronym-form="singular+short">Aki</span> is possible but irrational; rationality requires that <span data-acronym-label="Aki" data-acronym-form="singular+short">Aki</span> keep her first-order and higher-order beliefs coherent, so if she has this combination of beliefs, she is irrational &nbsp;<span class="citation" data-cites="Hookway2001 Ribeiro2011 Smithies2012 Greco2014 Horowitz2014 Titelbaum2015 Littlejohn2015">(<a href="references.html#ref-Hookway2001" role="doc-biblioref">Hookway 2001</a>; <a href="references.html#ref-Ribeiro2011" role="doc-biblioref">Ribeiro 2011</a>; <a href="references.html#ref-Smithies2012" role="doc-biblioref">Smithies 2012</a>; <a href="references.html#ref-Greco2014" role="doc-biblioref">Greco 2014</a>; <a href="references.html#ref-Horowitz2014" role="doc-biblioref">Horowitz 2014</a>; <a href="references.html#ref-Titelbaum2015" role="doc-biblioref">Titelbaum 2015</a>; <a href="references.html#ref-Littlejohn2015" role="doc-biblioref">Littlejohn 2018</a>)</span>.</p>
<p>So we get the following argument.</p>
<ol type="1">
<li>If normative externalism is true, then some akratic attitudes are rational.</li>
<li>No akratic attitudes are rational.</li>
<li>So, normative externalism is false.</li>
</ol>
<p>The short version of my response is that there is no understanding of ‘akratic’ that makes this argument plausible. We have to have a fairly expansive understanding of what akrasia is for premise 1 to be true. And on that understanding, premise 2 is implausible.</p>
<p>Note I’m using ‘attitude’ in a fairly expansive sense here. If one believes <em>p</em> and believes that it is irrational to believe <em>p</em> in one’s situation, I’ll call that combination an akratic attitude. This is perhaps non-standard - maybe we should say that’s a pair of attitudes that only become a single attitude if one forms the conjunctive belief that <em>p</em> is true and irrational to believe. But distinguishing belief in a conjunction and belief in each conjunct would be needlessly distracting in this context. Put in other terminology, the best version of premise 2 will be a ‘wide-scope’ principle, saying that it is irrational to both believe <em>p</em> and believe that this very belief is irrational or otherwise defective.</p>
<section id="thepossibilityofakrasia" class="level2" data-number="10.1">
<h2 data-number="10.1" class="anchored" data-anchor-id="thepossibilityofakrasia"><span class="header-section-number">10.1</span> The Possibility of Akrasia</h2>
<p>I’m going to mostly assume that it is at least possible to, as <span data-acronym-label="Aki" data-acronym-form="singular+short">Aki</span> does, hold a belief while believing that very belief is in some way improper. I’ve tacitly given the argument for that assumption already. It draws on a very similar argument by Brian <span class="citation" data-cites="Ribeiro2011">Ribeiro (<a href="references.html#ref-Ribeiro2011" role="doc-biblioref">2011</a>)</span>. In practice there is a gap between, on the one hand, coming to accept a sceptical argument and being motivated to adjust one’s mental life around it, and making those adjustments effectively. The very existence of Pyrrhonian techniques for resisting belief in propositions that one’s theory says one should not believe is evidence of this gap. Anyone who falls into that gap, like <span data-acronym-label="Aki" data-acronym-form="singular+short">Aki</span>, will be akratic.</p>
<p>Could it be said that <span data-acronym-label="Aki" data-acronym-form="singular+short">Aki</span> doesn’t really believe that sceptical arguments work? As David <span class="citation" data-cites="Owens2002">Owens (<a href="references.html#ref-Owens2002" role="doc-biblioref">2002</a>)</span> points out, we don’t want to just rely on <span data-acronym-label="Aki" data-acronym-form="singular+short">Aki</span>’s firm avowals that she endorses testimonial scepticism; it takes more than talk to form a belief. But if <span data-acronym-label="Aki" data-acronym-form="singular+short">Aki</span> says that she endorses the sceptical arguments, and she tries to convince others of them, and she, for example, carefully studies Sextus Empiricus for strategies for putting her testimonial scepticism into effect, it seems plausible that she really does believe in testimonial scepticism. And that’s true even if she lacks whatever it would take to put this sceptical doubt into full practice.</p>
<p>Is <span data-acronym-label="Aki" data-acronym-form="singular+short">Aki</span>, so described, akratic? Owens says that she is not, because she does not freely and deliberately choose to believe that the home team won last night, against her better judgment. Most other authors say, or perhaps just assume, that epistemic akrasia does not require freely and deliberately choosing one’s beliefs. I’m not going to take a stand on the substantive question here. If we’re trying to find a plausible version of the anti-externalist argument, it is best to not use ‘akrasia’ the way Owens does. That’s because given Owens’s usage, premise 1 is clearly false. Normative externalism makes no commitments at all concerning what it is rational to freely and deliberately believe. So let’s assume we’re working with a notion of akrasia that is not so demanding, and in particular that ‘akrasia’ applies to all cases where an agent believes against their better judgment.</p>
</section>
<section id="threelevel-crossingprinciples" class="level2" data-number="10.2">
<h2 data-number="10.2" class="anchored" data-anchor-id="threelevel-crossingprinciples"><span class="header-section-number">10.2</span> Three Level-Crossing Principles</h2>
<p>But even that characterisation is unclear on a key point. Here are three formulations of anti-akrasia principles that you could read as precisifications of the idea.</p>
<ul>
<li>“No situation rationally permits any overall state containing both an attitude A and the belief that A is rationally forbidden in one’s current situation.” &nbsp;<span class="citation" data-cites="Titelbaum2015">(<a href="references.html#ref-Titelbaum2015" role="doc-biblioref">Titelbaum 2015, 261</a>)</span></li>
<li>“It can never be rational to have high confidence in something like <em>P, but my evidence doesn’t support P</em>.” &nbsp;<span class="citation" data-cites="Horowitz2014">(<a href="references.html#ref-Horowitz2014" role="doc-biblioref">Horowitz 2014, 718</a>)</span></li>
<li>“If we use <em>Cr</em> for an agent’s credences and Pr for the credences that would be maximally rational for someone in that agent’s epistemic situation [then] <em>Cr</em>(<em>A</em>&nbsp;|&nbsp;Pr(<em>A</em>)&nbsp;=&nbsp;<em>n</em>)&nbsp;=&nbsp;<em>n</em>” &nbsp;<span class="citation" data-cites="Christensen2010b">(<a href="references.html#ref-Christensen2010b" role="doc-biblioref">Christensen 2010, 122</a>)</span></li>
</ul>
<p>Titelbaum calls the principle he puts forward the ‘Akratic Principle’. I don’t want to use that name because part of what we’re discussing is whether it is the most helpful way to understand akrasia. So I’ll just call it Titelbaum’s principle. Horowitz calls her principle the ‘Non-Akrasia Constraint’. For similar reasons, I’ll instead call it Horowitz’s principle. The principle Christensen puts forward is commonly called <em>Rational Reflection</em>, and I’ll follow that usage.</p>
<p>Rational Reflection is, in practice, considerably stronger than Titelbaum’s principle. Imagine that <span data-acronym-label="Aki" data-acronym-form="singular+short">Aki</span> is having doubts about her testimonial scepticism. She doesn’t fully endorse it. But she is still pretty confident in it; her credence in testimonial scepticism is 0.9. And she thinks that if testimonial scepticism is right, then the rational credence in the proposition that the home team won last night is below one-half. But she still has a very high confidence that the home team won, while thinking this is most likely irrational. This is a violation of Rational Reflection, but not of Titelbaum’s principle. After all, there is no attitude that <span data-acronym-label="Aki" data-acronym-form="singular+short">Aki</span> both has and believes that it is irrational to have.</p>
<p>That doesn’t show that Rational Reflection is logically stronger than Titelbaum’s principle. Maybe there are states that violate Titelbaum’s principle but not Rational Reflection. Whether this is so turns out to turn on difficult questions about the relationship between credence and belief. I’m not going to get into those questions here, in part because I have rather idiosyncratic views on them. On almost all theories about that relationship, however, it is impossible to violate Titelbaum’s principle without violating Rational Reflection. That’s what I mean by saying that in practice, Rational Reflection is a stronger principle.</p>
<p>Whether Rational Reflection is also stronger than Horowitz’s principle is a little less clear. At first glance, it seems like it must be. Imagine someone whose credences are given by the following table:</p>
<table class="table">
<thead>
<tr class="header">
<th style="text-align: center;">Proposition</th>
<th style="text-align: center;">Credence</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;"><em>p</em></td>
<td style="text-align: center;">0.7</td>
</tr>
<tr class="even">
<td style="text-align: center;">The rational credence for me to have in <em>p</em> is 0.7</td>
<td style="text-align: center;">0.9</td>
</tr>
<tr class="odd">
<td style="text-align: center;">The rational credence for me to have in <em>p</em> is 0</td>
<td style="text-align: center;">0.1</td>
</tr>
</tbody>
</table>
<p>Such an agent violates Rational Reflection. Rational Reflection implies that an agent’s credence in a proposition equals their expectation of the rational credence in that proposition. And the agent’s rational expectation of the rational credence in <em>p</em> is, from the last two lines of the table, 0.63. But on the face of it, it doesn’t look like they violate Horowitz’s principle. There is no proposition they are both confident in, and confident their evidence does not support. So it looks like Rational Reflection is stronger than Horowitz’s principle too. But the arguments below concerning iterated cases may cause us to doubt whether that’s ultimately the case.</p>
<p>My view is that all three of these principles are false. It’s a little trickier to say exactly which of the principles are inconsistent with normative externalism, and so must be rejected by anyone who accepts normative externalism. The simplest thing to say here uses the framework developed at the end of Part I, concerning core and peripheral commitments of normative externalism.</p>
<p>It is a core commitment of normative externalism that Rational Reflection is false. Rational Reflection offers a bidirectional link between what it is rational to believe, and what one believes about what it is rational to believe. And, at least as I read the proponents of the principle, the direction of explanation goes (at least in part) from the subject’s beliefs about what is rational to facts about what is rational.</p>
<p>Just what to say about Horowitz’s principle and normative externalism is less clear, because we need to see exactly how it applies in some tricky cases to get a sense of its scope. We’ll return to this below.</p>
<p>On the other hand, it is a relatively peripheral commitment that Titelbaum’s principle is false. Titelbaum’s principle is only a one way connection. And it is at least possible to endorse it while thinking the order of explanation goes in an externalist friendly way. One might think that if one believes A, it is irrational to believe that it is irrational to believe A in part in virtue of having that very first order belief. So there is at least a version of Titelbaum’s principle for which the answers to all of the questions posed at the end of Part I is “No”, and that makes it an extremely peripheral violation.</p>
<p>We get this very externalist friendly version of Titelbaum’s principle if we think that rational beliefs must be true, at least when the belief is about the normative. Why might we think that? One way to motivate that view is to start with the arguments given by Clayton <span class="citation" data-cites="Littlejohn2012">Littlejohn (<a href="references.html#ref-Littlejohn2012" role="doc-biblioref">2012</a>)</span> that only true beliefs can be justified, and try to either reason from there to the conclusion that only true beliefs are rational, or to amend the arguments so as that conclusion falls out. But another way is to argue that there is something special to normative beliefs. While descriptive beliefs can be false and rational, normative beliefs cannot. That is the lesson Titelbaum draws from his principle (which remember he calls the ‘Akratic Principle’).</p>
<blockquote class="blockquote">
<p>Ultimately, we need a story that squares the Akratic Principle with standard principles about belief support and justification. How is the justificatory map arranged such that one is never all-things-considered justified in both an attitude A and the belief that A is rationally forbidden in one’s current situation? The most obvious answer is that every agent possesses a priori, propositional justification for true beliefs about the requirements of rationality in her current situation. An agent can reflect on her situation and come to recognize facts about what that situation rationally requires. Not only can this reflection justify her in believing those facts; the resulting justification is also empirically indefeasible. &nbsp;<span class="citation" data-cites="Titelbaum2015">(<a href="references.html#ref-Titelbaum2015" role="doc-biblioref">Titelbaum 2015, 276</a>)</span></p>
</blockquote>
<p>But even if Titelbaum’s principle were true, it wouldn’t support a conclusion nearly that strong. The inference here is of the form: Agents can’t rationally form false beliefs about a particular topic, so agents have a priori justification for all possible true beliefs about that topic. And there are all sorts of ways to block that. We could say that all rational beliefs are true, as noted. Or we could simply say that for this topic, the truth of a proposition is a reason to believe it that is always strong enough to defeat rational justification to fully believe its negation. There are a lot of spaces between the claim that a proposition has a priori justification that can never be overridden, and the claim that that proposition can never be rationally believed to be false.</p>
<p>The upshot is that there are two distinct ways out, for the externalist, from the challenge posed by akrasia. One could adopt an extremely externalist epistemology of normative beliefs, as Titelbaum does. That will accept that akrasia is irrational, but deny that the core commitments of externalism entail that akrasia may be rational. Or one could accept that some forms of akrasia, such as violations of Rational Reflection, are rationally possible, and deny they are problematic. I’m going to take this second path. That’s in part because it gives us a stronger form of externalism and I want to show how a strong form of externalism may be defended. And it’s in part because that’s the path I think is correct. Let’s turn, then, to reasons that have been given for thinking that all forms of epistemic akrasia are problematic.</p>
</section>
<section id="whynotbeakratic" class="level2" data-number="10.3">
<h2 data-number="10.3" class="anchored" data-anchor-id="whynotbeakratic"><span class="header-section-number">10.3</span> Why Not Be Akratic</h2>
<p>I’m going to briefly discuss a simple, but bad, argument for thinking that all akratic agents are irrational. I’ll call this the <strong>Argument from the Ideal</strong>. I don’t think anyone in the current literature endorses this argument, so it should be uncontroversial that it fails. Indeed, I suspect it is relatively uncontroversial why it fails. But working through the argument will be helpful for getting to our main task, discussing the <strong>Argument from Weirdness</strong>. This argument turns on the following premise.</p>
<dl>
<dt>Weirdness is Irrational</dt>
<dd>
Akratic agents will say or do weird things, and only irrational agents would say or do those weird things.
</dd>
</dl>
<p>I think Weirdness is Irrational is false, but the following similar principle is true.</p>
<dl>
<dt>Weirdness is Non-Ideal</dt>
<dd>
Akratic agents will say or do weird things, and no ideal agent would say or do those weird things.
</dd>
</dl>
<p>Different forms of the argument from weirdness will occupy the rest of the chapter, and in every case my reply will have this form. Akratic agents do some odd things, weird things even, but this is evidence of their not being ideal, not of their being irrational.</p>
<p>But let’s start with the Argument from the Ideal. Imagine a perfect agent, who is all knowing and perfectly good. For convenience, call this agent God. God will never be akratic. That’s because God only believes things that are strongly supported by His evidence, and only believes truths, so He believes (truthfully!) that everything He believes is supported by His evidence. This suggests a simple argument.</p>
<ol type="1">
<li>God is not akratic.</li>
<li>Rational people will, so far as they can, replicate God’s properties.</li>
<li>So rational people will not be akratic.</li>
</ol>
<p>The problem is that premise 2 has any number of counterexamples. As well as not being akratic, God is <em>opinionated</em>. By this, I mean that for any <em>p</em>, God will either believe <em>p</em> or believe ¬<em>p</em>. (I’m assuming here that if God exists then a kind of realism is true.) Does it follow that all rational people are opinionated? No, of course not. I don’t know what the weather is like where you, dear reader, are. In many cases, I don’t even know who you are, or when you are reading. So far, we might think this is just a failure of omniscience. But it doesn’t mean that rationality requires that I be opinionated about who you are, where you are, when you are, or what the weather is like there then. Indeed, rationality requires that I not be opinionated about these questions. And that’s true even though I know if I were ideal, I would be opinionated.</p>
<p>The point is not just that premise 2 of the Argument from the Ideal is false. It’s that once we have the distinction between what would be ideal, and what would be rational in non-ideal circumstances, we can see how a lot of other arguments fail too. So let’s start working through some of the Arguments from Weirdness with this distinction in mind.</p>
<p>It is plausible that in <span data-acronym-label="Aki" data-acronym-form="singular+short">Aki</span>’s situation, where she believes <em>p</em> and believes the evidence does not support it, that she should say <em>p, but my evidence does not support p</em>. And this kind of Moore-paradoxical utterance is absurd, say some philosophers &nbsp;<span class="citation" data-cites="Smithies2012 Greco2014">(<a href="references.html#ref-Smithies2012" role="doc-biblioref">Smithies 2012</a>; <a href="references.html#ref-Greco2014" role="doc-biblioref">Greco 2014</a>)</span>; it’s not something a rational person could say. And it’s certainly weird, and non-ideal. But we can see that it could be rational by working through some other non-ideal cases.</p>
<p><span data-acronym-label="Bulan" data-acronym-form="singular+short">Bulan</span> isn’t sure who she is. She is highly confident that <span data-acronym-label="Bulan" data-acronym-form="singular+short">Bulan</span>’s evidence is <em>E<sub>B</sub></em>. This is rational, though not quite right. She knows that <em>E<sub>B</sub></em> is weak evidence for <em>q</em>, and that her evidence is <em>E<sub>A</sub></em>, and that <em>E<sub>A</sub></em> is good evidence for <em>q</em>, and that <em>q</em> is true. And that’s all good, because all of those things are true. She says <em>q, but Bulan’s evidence does not support q</em>. It’s hard to see what’s wrong with that claim, and indeed even opponents of epistemic akrasia should not say it is irrational. It’s only the distinctively first-personal claim, the one that we get when <span data-acronym-label="Bulan" data-acronym-form="singular+short">Bulan</span> thinks her attitude is mistaken under a first-personal mode of presentation, that is problematic. That’s interesting in itself; the Argument from Weirdness seems to rely on a view about the distinctiveness of first-personal thought and talk. So there is a potential line of defence for the normative externalist that denies the critic’s assumption that first-personal belief is special &nbsp;<span class="citation" data-cites="CappelenDever2014">(<a href="references.html#ref-CappelenDever2014" role="doc-biblioref">Cappelen and Dever 2014</a>)</span>. But let’s grant the assumption that first-person thought and talk is special, and see what other ways we can raise problems for the Argument.</p>
<p>Imagine that <span data-acronym-label="Bulan" data-acronym-form="singular+short">Bulan</span> now learns who she is. Since she can’t hold on to all of the claims that she is <span data-acronym-label="Bulan" data-acronym-form="singular+short">Bulan</span>, that her evidence is <em>E<sub>A</sub></em>, and that <span data-acronym-label="Bulan" data-acronym-form="singular+short">Bulan</span>’s evidence is <em>E<sub>B</sub></em>, she drops the middle claim. She instead holds on to the first and third claim, and infers that her evidence is <em>E<sub>B</sub></em>. Since she knows that <em>E<sub>B</sub></em> is weak evidence for <em>q</em>, she now believes that her evidence for <em>q</em> is weak. But since the fact that she is <span data-acronym-label="Bulan" data-acronym-form="singular+short">Bulan</span> is no evidence against <em>q</em>, she also holds onto her belief that <em>q</em>. So now she thinks that <em>q, but my evidence does not support q</em>. And this is meant to be problematic, at least according to some opponents of epistemic akrasia. But it isn’t at all clear which step was mistaken. I think that proponents of the Argument from Weirdness have to say that at the last step, one of two things must happen. Either <span data-acronym-label="Bulan" data-acronym-form="singular+short">Bulan</span> must not resolve the tension in her beliefs by dropping the belief that her evidence is <em>E<sub>A</sub></em>, or she must take the fact that she is <span data-acronym-label="Bulan" data-acronym-form="singular+short">Bulan</span> to be a reason to lose her belief in <em>q</em>, although her identity is probabilistically independent of whether <em>q</em> is true. Neither option seems appealing, and it’s striking that proponents of the argument are forced into it.</p>
<p>Let’s go back to the question of just what <span data-acronym-label="Aki" data-acronym-form="singular+short">Aki</span> (or Bulan) should say given their beliefs. Even if epistemic akrasia is possible, it doesn’t immediately follow that rational agents will make these weird utterances. If it is only appropriate to say things if one knows them, as <span class="citation" data-cites="Williamson2000">Williamson (<a href="references.html#ref-Williamson2000" role="doc-biblioref">2000</a>)</span> argues, and one can only know something if one’s evidence supports it, then it can never be appropriate to say <em>p, but my evidence does not support p</em>. If one knows one evidence does not support <em>p</em>, then by the factivity of knowledge, one’s evidence does not support <em>p</em>, so one does not know <em>p</em>, so one should not assert it. On this view, <span data-acronym-label="Aki" data-acronym-form="singular+short">Aki</span> shouldn’t say <em>My evidence does not support p</em>, even if that proposition is supported by her evidence.</p>
<p>We don’t need anything as strong as the rule <em>Only say what you know</em> to make the argument of the last paragraph work. Assume that for descriptive claims, the rule is <em>Only say what your evidence supports</em>, and for normative claims the rule is <em>Only say what is true</em>. Then if <em>p</em> is descriptive, it won’t be permissible for <span data-acronym-label="Aki" data-acronym-form="singular+short">Aki</span> to say <em>p, but my evidence does not support p</em>. She will be able to say this if <em>p</em> is itself a normative claim. But the evidence that her assertion would be absurd in such cases is weak; there seem to be cases where this is exactly the right thing for her to say &nbsp;<span class="citation" data-cites="WeathersonMaitra2010">(<a href="references.html#ref-WeathersonMaitra2010" role="doc-biblioref">Maitra and Weatherson 2010</a>)</span>.</p>
<p><span class="citation" data-cites="Horowitz2014">Horowitz (<a href="references.html#ref-Horowitz2014" role="doc-biblioref">2014</a>)</span> carefully designs her akratic principle so as to ensure the arguments for it can’t be so easily deflected. Imagine that <span data-acronym-label="Aki" data-acronym-form="singular+short">Aki</span> is more careful to not commit to anything that might be false. So she says <em>I’m confident that p, and I’m confident my evidence does not support p</em>. It is not plausible to say that one should only be confident in a proposition, or should only announce one’s confidence in that proposition, if one knows the proposition to be true. For every lottery ticket in a large, fair lottery, I’m confident it will lose, yet I can’t know each ticket will lose. (Perhaps I can’t know any ticket will lose.) Horowitz argues that even this qualified utterance of <span data-acronym-label="Aki" data-acronym-form="singular+short">Aki</span>’s is defective.</p>
<p>Notably, she doesn’t just argue for this on the basis of intuitions about how weird the assertion itself sounds. There is a good dialectical reason for her to reason this way. The anti-akratic thinks that it is wrong to both be confident in <em>p</em> and in the proposition that the evidence for <em>p</em> is not strong, no matter which proposition <em>p</em> is, and no matter what the agent’s background. It’s hard to see how getting intuitions going about a few token utterances could support a universal generalisation that sweeping. So Horowitz offers some more careful arguments, ones that have at least the potential to generalise in the needed way.</p>
<p>Horowitz argues that <span data-acronym-label="Aki" data-acronym-form="singular+short">Aki</span> should be in a position to conclude, on the basis of her evidence, that her evidence is misleading, and that she was lucky to become so confident in the truth. And this, Horowitz thinks, is wrong. One needs independent reason to think that one’s evidence is misleading, so it’s wrong for <span data-acronym-label="Aki" data-acronym-form="singular+short">Aki</span> to conclude that on the basis of this very evidence. But that last premise seems too strong. Sometimes parts of one’s evidence can be sufficient ground for thinking one’s overall evidence is misleading. That’s indeed what happens in <span data-acronym-label="Aki" data-acronym-form="singular+short">Aki</span>’s case. There is no one part of her evidence that is both grounds for something and (complete) grounds for thinking those very grounds are misleading. The internal relations between the different parts of her evidence provide all the independent support we need for a reasonable judgment that other parts are misleading.</p>
<p>Horowitz has another argument that <span data-acronym-label="Aki" data-acronym-form="singular+short">Aki</span> will be in an untenable position. Imagine she is offered a bet that wins a small amount if <em>p</em> is true, and loses a larger amount if it is false. <span data-acronym-label="Aki" data-acronym-form="singular+short">Aki</span> takes the bet, as she should given that she has excellent reason to believe <em>p</em> is true. But she is then asked why she is doing this, she’ll say that she should not be doing it; she has no good reason to believe the bet will win. Is this, doing something while saying one should not be doing it, problematic? Once we’ve seen other cases of inadvertent virtue, we can see why the answer is no. <span data-acronym-label="Huck" data-acronym-form="singular+short">Huck</span> Finn should help Jim escape, and should say he’s doing the wrong thing while doing so. <span data-acronym-label="Aki" data-acronym-form="singular+short">Aki</span>’s predicament is no worse.</p>
<p>Recently, Clayton <span class="citation" data-cites="Littlejohn2015">Littlejohn (<a href="references.html#ref-Littlejohn2015" role="doc-biblioref">2018</a>)</span> argued for an anti-akrasia view by suggesting that <span data-acronym-label="Aki" data-acronym-form="singular+short">Aki</span> would end up with a distinct kind of untenable attitude. He imagines a conversation between <span data-acronym-label="Aki" data-acronym-form="singular+short">Aki</span> and her epistemic conscience with the following punchline. (Note in Littlejohn’s example, the first order evidence supports not believing in <em>p</em>, and the higher-order evidence supports belief in <em>p</em>. This is the reverse of the case I’ve started with, but that doesn’t matter much. What matters is that the levels diverge, and Aki follows the first-order evidence.)</p>
<blockquote class="blockquote">
<p>EC: You agree that it’s irrational for you not to believe <em>p</em>. You agree that it’s rational for you to agree on this point. You acknowledge that you don’t believe <em>p</em>. You just don’t yet see that this calls for any sort of change.<br>
<span data-acronym-label="Aki" data-acronym-form="singular+short">Aki</span>: Right. &nbsp;<span class="citation" data-cites="Littlejohn2015">(<a href="references.html#ref-Littlejohn2015" role="doc-biblioref">Littlejohn 2018, 12</a>, reference to preprint)</span></p>
</blockquote>
<p>And this last statement of <span data-acronym-label="Aki" data-acronym-form="singular+short">Aki</span>’s is untenable, thinks Littlejohn. And I suspect he is right about that. But it doesn’t matter, because that’s not what <span data-acronym-label="Aki" data-acronym-form="singular+short">Aki</span> should be saying. She should say that there is a “call for change”, and she should think that there is such a call. After all, she thinks that she is not following her evidence, and that one should in general follow one’s evidence. At the very least, that seems like reason to stop and have a think about how one got into this situation, and see if there wasn’t some big mistake made along the way.</p>
<p>If <span data-acronym-label="Aki" data-acronym-form="singular+short">Aki</span> doesn’t stop and reflect on her odd situation, that would be somewhat strange behaviour. But even the normative externalist can say that she should stop and reflect. It’s true that she she isn’t doing anything wrong. But whether one should stop and reflect is not entirely a function of whether one is doing anything particularly wrong. If one’s cognitions or activities (or the conjunction of these) resemble those of people who are making mistakes, one has a reason to be think through what one has done. Of course, if <span data-acronym-label="Aki" data-acronym-form="singular+short">Aki</span> were ideal, she wouldn’t need to stop and reflect, since she would know she is responding optimally to being in a strange situation. But if she were ideal, i.e., if she were God, she wouldn’t be in that situation in the first place.</p>
<p>So we still haven’t seen anything that <span data-acronym-label="Aki" data-acronym-form="singular+short">Aki</span> should do or say, given normative externalism, that is weird in a way that is inconsistent with rationality. She should perhaps say one thing and do another, just like <span data-acronym-label="Huck" data-acronym-form="singular+short">Huck</span> Finn. And she should say that <span data-acronym-label="Aki" data-acronym-form="singular+short">Aki</span>’s evidence doesn’t support what she herself believes, just like <span data-acronym-label="Bulan" data-acronym-form="singular+short">Bulan</span> (in the original case) should say that <span data-acronym-label="Bulan" data-acronym-form="singular+short">Bulan</span>’s evidence doesn’t support what she herself believes. But <span data-acronym-label="Huck" data-acronym-form="singular+short">Huck</span> Finn, and <span data-acronym-label="Bulan" data-acronym-form="singular+short">Bulan</span>, aren’t problematic. And the attempts to get <span data-acronym-label="Aki" data-acronym-form="singular+short">Aki</span> to say weirder things so far haven’t worked; they’ve got her making assertions that violate norms of assertion even by the externalist’s lights.</p>
</section>
<section id="self-awarenessandrationalreflection" class="level2" data-number="10.4">
<h2 data-number="10.4" class="anchored" data-anchor-id="self-awarenessandrationalreflection"><span class="header-section-number">10.4</span> Self-Awareness and Rational Reflection</h2>
<p>In the previous section I argued that there was nothing distinctively weird about akratic agents. They say and do weird things that other non-ideal but rational agents do. In this section I’ll continue the argument a little, with more focus on two particular principles. In particular, I’ll argue for these two claims:</p>
<ol type="1">
<li>Cases where agents do not know exactly what their situation is generate counterexamples to Rational Reflection, and to Horowitz’s principle.</li>
<li>There is no reason to believe that these principles hold in cases where agents do know what their evidence is, since there is no reason to think that violations of the principles are more problematic in cases where agents do know what their evidence is.</li>
</ol>
<p>I’ll start with two relatively plausible assumptions:</p>
<ol type="1">
<li>What attitudes it is rational for an agent to have depend on features of her situation that vary from agent to agent and time to time.</li>
<li>The features that are relevant in point 1 are not luminous; agents might possess them without knowing that they do.</li>
</ol>
<p>My view is that the ‘features’ in assumption 1 are just the agent’s evidence, but I’m not assuming that. I’m just assuming that what’s rational depends on the circumstances.</p>
<p>Premise 2 follows from the anti-luminosity arguments introduced by <span class="citation" data-cites="Williamson2000">Williamson (<a href="references.html#ref-Williamson2000" role="doc-biblioref">2000</a>)</span>, and defended recently by Hawthorne and Magidor <span class="citation" data-cites="HawthorneMagidor2009 HawthorneMagidor2011">(<a href="references.html#ref-HawthorneMagidor2009" role="doc-biblioref">2009</a>, <a href="references.html#ref-HawthorneMagidor2011" role="doc-biblioref">2011</a>)</span> and by <span class="citation" data-cites="Srinivasan2015">Srinivasan (<a href="references.html#ref-Srinivasan2015" role="doc-biblioref">2015</a>)</span>. I don’t need the full blown anti-luminosity principle to complete the argument. All I need is that luminosity fails for some of the features that are relevant to rational belief. So if there are some luminous states, as I’ve argued elsewhere &nbsp;<span class="citation" data-cites="Weatherson2004">(<a href="references.html#ref-Weatherson2004" role="doc-biblioref">Weatherson 2004</a>)</span>, that won’t matter unless all features relevant to rationality are luminous. And that’s not particularly plausible.</p>
<p>Even if all rational agents know exactly what is rationally required in all possible situations, as Titelbaum argues they do, there will still be failures of Rational Reflection. That is because an agent need not know what situation they are actually in. It is possible for an agent to have perfect knowledge of the function from situations to the rational status of states in such a situation, and not know what is rational for them. If rather extreme rational states are only permissible in rare situations, and the agent is in such a rare situation, then Rational Reflection will fail.</p>
<p>The abstract possibility described in the previous sentence is realized in Williamson’s case of the unmarked clock &nbsp;<span class="citation" data-cites="Williamson2011 Williamson2014">(<a href="references.html#ref-Williamson2011" role="doc-biblioref">Williamson 2011</a>, <a href="references.html#ref-Williamson2014" role="doc-biblioref">2014</a>)</span>. I’ll work through Horowitz’s variant, her case of the unmarked dartboard, because it provides a useful platform for setting up Horowitz’s criticisms of the example, and my reply.</p>
<p>A dart is thrown at a dartboard that is infinite in height and width. The dartboard has gridlines on it running up-down and left-right. Due to magnets in the dart and the board, we know in advance that it will land on the intersection of two gridlines. The agent, we’ll call her <span data-acronym-label="Siiri" data-acronym-form="singular+short">Siiri</span>, can almost, but not quite, make out where it lands, and she knows in advance this will be the case.</p>
<p>Say that the ‘distance’ between two grid points, ⟨<em>x</em><sub>1</sub>,&nbsp;<em>y</em><sub>1</sub>⟩ and ⟨<em>x</em><sub>2</sub>,&nbsp;<em>y</em><sub>2</sub>⟩ is |<em>x</em><sub>1</sub> - <em>x</em><sub>2</sub>| + |<em>y</em><sub>1</sub> - <em>y</em><sub>2</sub>|. This is not the straight-line distance between the points; it is the shortest path between them on gridlines. <span data-acronym-label="Siiri" data-acronym-form="singular+short">Siiri</span> knows in advance that if the dart lands on ⟨<em>x</em>,&nbsp;<em>y</em>⟩, then she’ll know it is on ⟨<em>x</em>,&nbsp;<em>y</em>⟩ or one of the four points distance 1 away from it. And she knows in that situation it will be rational to have equal credence that it is on each of those five points.</p>
<p>Assume the dart lands on ⟨8,&nbsp;3⟩, and consider her credence in the proposition that it is on ⟨7,&nbsp;3⟩, ⟨8,&nbsp;4⟩, ⟨9,&nbsp;3⟩ or ⟨8,&nbsp;2⟩. Call that proposition <em>p</em>. After getting visual evidence of where the dart is, her credence in <em>p</em> should be 0.8. But she should have credence 0.8 in <em>p</em> iff the dart is on ⟨8,&nbsp;3⟩, and credence 0.2 in <em>p</em> if the dart is on any of the other four squares she thinks it might be on. So given her situation, the expected rational credence in <em>p</em> is 0.32. So Rational Reflection fails, even though <span data-acronym-label="Siiri" data-acronym-form="singular+short">Siiri</span> knows exactly the function from situations to rational credences.</p>
<p>Horowitz argues that this is a special case. She thinks that a restricted version of Rational Reflection can be crafted that is immune to such a counterexample. There is something odd about the example. We’re interested in a proposition <em>p</em> that is in a very odd class. Consider all propositions of the form <em>the dart lands distance 1 from point</em> ⟨x, y⟩. <span data-acronym-label="Siiri" data-acronym-form="singular+short">Siiri</span> knows in advance that she will be very confident in such a proposition iff it is false. And that is odd. Here is how Horowitz puts the point. (Note that I’ve adjusted the terminology slightly to match what’s here, and what she calls ‘akrasia’ is being highly confident in <em>p, but my evidence doesn’t support p</em>.)</p>
<blockquote class="blockquote">
<p>In Dartboard, however, the evidence is <em>not</em> truth-guiding, at least with respect to propositions like <em>p</em>. Instead, it is <em>falsity</em>-guiding. It supports high confidence in <em>p</em> when <em>p</em> is false—that is, when the dart landed at ⟨8,&nbsp;3⟩. And it supports low confidence in <em>p</em> when <em>p</em> is true—that is, when the dart landed at ⟨7,&nbsp;3⟩, ⟨8,&nbsp;4⟩, ⟨9,&nbsp;3⟩ or ⟨8,&nbsp;2⟩. This is an unusual feature of Dartboard. And it is only because of this unusual feature that epistemic akrasia seems rational in Dartboard. You should think that you should have low confidence in <em>p</em> precisely <em>because</em> you should think <em>p</em> is probably true—and because your evidence is falsity-guiding with respect to <em>p</em>. Epistemic akrasia is rational precisely because we should take into account background expectations about whether the evidence is likely to be truth-guiding or falsity-guiding. &nbsp;<span class="citation" data-cites="Horowitz2014">(<a href="references.html#ref-Horowitz2014" role="doc-biblioref">Horowitz 2014, 738</a>, notation altered, emphasis in original)</span></p>
</blockquote>
<p>Surprisingly, it isn’t essential to the example that the evidence is falsity-guiding in Horowitz’s sense. This feature of the case is a byproduct of its simplicity; more complicated cases don’t have this feature.</p>
<p>Imagine instead that when the dart lands at a particular spot ⟨<em>x</em>,&nbsp;<em>y</em>⟩, all spots whose distance from ⟨<em>x</em>,&nbsp;<em>y</em>⟩ is 10 or less are open epistemic possibilities for <span data-acronym-label="Siiri" data-acronym-form="singular+short">Siiri</span>. But they are not equal possibilities; her probability distribution is peaked at ⟨<em>x</em>,&nbsp;<em>y</em>⟩ itself. For any grid point distance <em>d</em> from ⟨<em>x</em>,&nbsp;<em>y</em>⟩, her posterior probability that it landed there is:</p>
<p><span class="math display">\[
\frac{4^{10-d}}{2,912,692}
\]</span></p>
<p>The denominator there is just what’s needed to make the probabilities add to 1. The intuitive idea is for each step further away from the center we get, the probability of being in that particular cell falls by a factor of 4. Now assume again the dart lands on ⟨8,&nbsp;3⟩, though of course <span data-acronym-label="Siiri" data-acronym-form="singular+short">Siiri</span> does not know this, and let <em>q</em> be the proposition that the distance between the dart and ⟨8,&nbsp;3⟩ is either 0 or 3.</p>
<p>The evidence is not falsity-guiding with respect to <em>q</em>. Given what we said about <span data-acronym-label="Siiri" data-acronym-form="singular+short">Siiri</span>, then among the worlds that are epistemically possible for her, her credence in <em>q</em> would be higher if <em>q</em> were true than if it were false. More precisely, her credence in <em>q</em> would somewhere between 0.413 and 0.44 if she were in one of the worlds that made <em>q</em>, and at most 0.307 if she were in one of the worlds that made <em>q</em> false. (The calculations to confirm the facts I’ll run through about the example are tedious, but trivial, to verify with a computer.) The evidence supports higher confidence in <em>q</em> when <em>q</em> is true than than when <em>q</em> is false. That’s unlike the original example. But this case also generates violations of Rational Reflection. <span data-acronym-label="Siiri" data-acronym-form="singular+short">Siiri</span>’s credence in <em>q</em> is about 0.4275, but her expectation of the rational credence in it is about 0.3127.</p>
<p>Now you might think that’s not a huge difference. Perhaps this is a counter-example to Rational Reflection, but not to Horowitz’s principle that it is irrational to be highly confident in a proposition while also being highly confident that one is irrational to be so confident. But if we iterate the example, we get a counterexample to that principle too.</p>
<p>Imagine <span data-acronym-label="Siiri" data-acronym-form="singular+short">Siiri</span> starts off (rationally) certain that repeated throws at the board are independent. And imagine that the dart is removed after each throw, so she can’t see that successive darts land at the same spot. And imagine that her ability to detect where it lands doesn’t improve, indeed doesn’t change, over repeated throws. Finally imagine (somewhat improbably!) that repeated throws keep landing on ⟨8,&nbsp;3⟩. Let <em>r</em> be the proposition that at least 35 percent of throws are either distance 0 or distance 3 from ⟨8,&nbsp;3⟩. As the number of throws increases, she should get more and more confident that is true, and get more and more confident that it is irrational to think that it is true. After 100 throws, for example, her credence in <em>r</em> should be over 0.95, but her expectation of the rational credence in <em>r</em> should be under 0.25. This kind of iteration of examples can be used to turn any dartboard-like counterexample to Rational Reflection into a counterexample to Horowitz’s principle.</p>
</section>
<section id="akrasiaandoddstatements" class="level2" data-number="10.5">
<h2 data-number="10.5" class="anchored" data-anchor-id="akrasiaandoddstatements"><span class="header-section-number">10.5</span> Akrasia and Odd Statements</h2>
<p>So Horowitz’s explanation of why cases like <span data-acronym-label="Siiri" data-acronym-form="singular+short">Siiri</span>’s are special, that they are cases where agents know evidence is not truth-conducive, doesn’t work. And that raises doubts for any attempt to separate <span data-acronym-label="Aki" data-acronym-form="singular+short">Aki</span>’s case from <span data-acronym-label="Siiri" data-acronym-form="singular+short">Siiri</span>’s.</p>
<p>A large part of the motivation for thinking <span data-acronym-label="Aki" data-acronym-form="singular+short">Aki</span>’s state is irrational is that <span data-acronym-label="Aki" data-acronym-form="singular+short">Aki</span> says weird things, like <em>p is true, although my evidence supports p being false</em>. But <span data-acronym-label="Siiri" data-acronym-form="singular+short">Siiri</span> says similar things, and they are the right things for <span data-acronym-label="Siiri" data-acronym-form="singular+short">Siiri</span> to say. So the very fact that <span data-acronym-label="Aki" data-acronym-form="singular+short">Aki</span> says them can’t show that her position is incoherent; she is, in this respect, just like the perfectly coherent (if unfortunate) <span data-acronym-label="Siiri" data-acronym-form="singular+short">Siiri</span>.</p>
<p><span data-acronym-label="Siiri" data-acronym-form="singular+short">Siiri</span> might regard it as a lucky break that she has a true belief despite not following her evidence. Of course, <span data-acronym-label="Aki" data-acronym-form="singular+short">Aki</span> could feel the same way. She should think that the home team won, think that her evidence doesn’t support this, and from those claims think it is lucky that she has a correct belief despite not following the evidence. But <span data-acronym-label="Siiri" data-acronym-form="singular+short">Siiri</span> will think something structurally similar. Horowitz argues that <span data-acronym-label="Siiri" data-acronym-form="singular+short">Siiri</span> doesn’t have to regard herself as implausibly lucky. In the original version of the case <span data-acronym-label="Siiri" data-acronym-form="singular+short">Siiri</span> knows the evidence is not truth-conducive, so it isn’t a lucky break that not following the evidence (as it seems) leads to truth. But in the revised case, <span data-acronym-label="Siiri" data-acronym-form="singular+short">Siiri</span> has to think she’s just as lucky as <span data-acronym-label="Aki" data-acronym-form="singular+short">Aki</span>. And if it is reasonable for <span data-acronym-label="Siiri" data-acronym-form="singular+short">Siiri</span> to think she is lucky, it is also reasonably for <span data-acronym-label="Aki" data-acronym-form="singular+short">Aki</span> to think she is.</p>
<p>Let’s take stock. <span data-acronym-label="Siiri" data-acronym-form="singular+short">Siiri</span>’s case shows that Rational Reflection fails, and that it can be rational to be confident in something while also being confident that one’s evidence does not support this view. It does not show that it can be rational to be confident in a falsehood about what rationality itself requires, as opposed to what one’s situation is. That is, one could be certain about all the truths about what rationality requires in each situation, and still end up like <span data-acronym-label="Siiri" data-acronym-form="singular+short">Siiri</span>. Indeed, we assumed she was certain about all the truths about what rationality requires in each situation, and still got a strange result falling out. So <span data-acronym-label="Siiri" data-acronym-form="singular+short">Siiri</span>’s case does not directly tell against the most plausible version of Titelbaum’s principle.</p>
<p>But the arguments for Titelbaum’s principle (or anything like it) are all Arguments from Weirdness. And <span data-acronym-label="Siiri" data-acronym-form="singular+short">Siiri</span>’s case does undermine the force of those arguments. For she says a lot of weird things too, and they are the right thing to say. So the fact that violations of Titelbaum’s principle will lead to people saying weird, akratic things is no reason to think that Titelbaum’s principle is a requirement of rationality. In weird situations, rational people are weird. Ideal people aren’t weird, but that’s only because they know things about their situation that are hidden from normal, rational, people. Normative externalism does imply that rational people will be akratic, and be weird, and be non-ideal. But none of that is surprising; the kinds of weirdness and non-idealness we see are just what we should independently expect in rational, but non-ideal, people.</p>
</section>
<section id="desireasbeliefreprise" class="level2 page-columns page-full" data-number="10.6">
<h2 data-number="10.6" class="anchored" data-anchor-id="desireasbeliefreprise"><span class="header-section-number">10.6</span> Desire as Belief (Reprise)</h2>
<p>The dartboard example is relevant to more than debates over akrasia. It also helps illustrate a point I alluded to frequently in part one, without ever setting out in detail. Proponents of the idea that moral uncertainty matters to rational decision making seem to be committed to a kind of ‘desire as belief’ thesis. David <span class="citation" data-cites="Lewis1988b Lewis1996a">(<a href="references.html#ref-Lewis1988b" role="doc-biblioref">Lewis 1988</a>, <a href="references.html#ref-Lewis1996a" role="doc-biblioref">1996</a>)</span> raised some technical problems for such theories, and recently those problems have been expanded by <span class="citation" data-cites="RussellHawthorne2016">Russell and Hawthorne (<a href="references.html#ref-RussellHawthorne2016" role="doc-biblioref">2016</a>)</span>. I’m not going to add anything to the arguments they have offered. But I think it might be helpful to translate those arguments into the idioms that are more familiar in the moral uncertainty debates, since participants in that debate have not always appreciated the significance of these formal results. The only philosopher I know who has connected the moral uncertainty debates with the desire as belief debates is Ittay <span class="citation" data-cites="NissanRozen2015">Nissan-Rozen (<a href="references.html#ref-NissanRozen2015" role="doc-biblioref">2015</a>)</span>, and he takes an externalist position on moral uncertainty. My focus will be on the argument Russell and Hawthorne give, because it would be too much of a digression to investigate whether the ‘desire by necessity’ response that Huw <span class="citation" data-cites="Price1989">Price (<a href="references.html#ref-Price1989" role="doc-biblioref">1989</a>)</span> gives to Lewis’s arguments is successful.</p>
<p>Let’s assume that we want moral uncertainty to play an important role in decision making. We should be able to provide some kind of semantics for claims about moral uncertainty. In particular, we would like a semantics for claims of the form <em>A is better than B</em> that satisfies the following four constraints.</p>
<ol type="1">
<li>Claims like <em>A is better than B</em> should be the kind of thing that can be believed, and that one can have higher or lower credences in. So that claim should be associated with a set of worlds, or a set of n-tuples, where the first member of that tuple is a world. (The latter disjunction is relevant if one thinks, perhaps following <span class="citation" data-cites="Lewis1979">Lewis (<a href="references.html#ref-Lewis1979" role="doc-biblioref">1979</a>)</span>, that the objects of belief are something like centred worlds.)</li>
<li>These attitudes in moral ‘propositions’ (or whatever else is picked out by <em>A is better than B</em>) should be updated in the way that credal attitudes are usually updated. Ideally that would be by conditionalisation, or by some other update rule that can be given independent motivation.</li>
<li>The semantics should associate with <em>A is better than B</em> a set of worlds (or tuples or whatever) that at least roughly corresponds with what those words ordinarily mean in English.</li>
<li>The claim should be action guiding, so (perhaps barring exceptional circumstances) conditional on <em>A is better than B</em>,&nbsp;<em>A</em> should be more choice-worthy than <em>B</em>.</li>
</ol>
<p>And it turns out to be incredibly hard to find a semantics that satisfies these four constraints. In fact, there are principled reasons to think that no such semantics is possible.</p>
<p>There is one technical complication that we need to address first. Whether <em>A</em> is better than <em>B</em> depends on one’s evidence. So if <em>A</em> is that I get a (typical) lottery ticket, and <em>B</em> is that I get a penny, then <em>A</em> is better than <em>B</em>, from my perspective, iff I don’t know that <em>A</em> is a losing ticket. It is far from trivial to represent claims about what one’s evidence is in a semantic model. That’s in part because facts about what one’s evidence is are ‘first-personal’ facts that are tricky to represent in standard models, and in part because what one’s evidence is changes over time, and it’s hard to represent changes over time in standard models.</p>
<p>Here’s how I’ll try to deal with, or at least sidestep, these problems. Instead of thinking of beliefs as attitudes to sets of worlds, we’ll think of them as attitudes to world-evidence-morality triples: ⟨<em>w</em>,&nbsp;<em>e</em>,&nbsp;<em>m</em>⟩. And we’ll assume that <em>e</em> determines (perhaps among many other things) a function from times to one’s evidence at that time. Just how it does that, and just how it attitudes distributed over <em>e</em> are updated, will be left as a black-box. (See <span class="citation" data-cites="Titelbaum2016">Titelbaum (<a href="references.html#ref-Titelbaum2016" role="doc-biblioref">2016</a>)</span> for an excellent survey of the options for how the self-locating parts of one’s credal state might be updated.)</p>
<p>I’ll assume <em>m</em> is just a number, perhaps subject to enough constraints that we don’t end up in the paradoxes of unbounded utility<a href="#fn1" class="footnote-ref" id="fnref1" role="doc-noteref"><sup>1</sup></a>. And what we want is that the value of a proposition is the expected value of <em>m</em> given that the proposition is true. So <em>A</em> is better than <em>B</em>, given some evidence, just in case the expected value of <em>m</em> given <em>A</em> and that evidence is greater than the expected value of <em>m</em> given <em>B</em> and that evidence. But expected values change with evidence, and evidence changes with time, so this doesn’t settle what <em>m</em> should be. It turns out that while there are a few ways one could go here, any choice ends up violating one of the four constraints I proposed.</p>
<div class="no-row-height column-margin column-container"><li id="fn1"><p><sup>1</sup>&nbsp;I’m assuming here that the moral value of a world can be represented as a number. That’s not particularly plausible, but without this assumption the internalist views I’m opposing are very hard to state or defend.</p></li></div><p>Assume, first, that the evidence is highly malleable. I mean two things by that. One is that when we conditionalise on some proposition <em>c</em>, then <em>c</em> gets added to the evidence. The other is that the time in question (and remember that <em>e</em> is a function from times to evidence sets) is the time any relevant decision has to be made. This pair of assumptions has a very nice feature - it guarantees that the fourth constraint is met. (This turns out to be harder to do than you might think.) Conditional on <em>A is better than B</em>, thus interpreted, I should choose <em>A</em> over <em>B</em>, no matter what the other evidence is.</p>
<p>The problem with this assumption is that it violates the third constraint rather dramatically. The following example is a version of the objection that <span class="citation" data-cites="RussellHawthorne2016">Russell and Hawthorne (<a href="references.html#ref-RussellHawthorne2016" role="doc-biblioref">2016, 315–16</a>)</span> make to the principle they call <strong>Comparative Value</strong>. Consider the following substitutions for <em>A</em> and <em>B</em>.</p>
<dl>
<dt>A1</dt>
<dd>
I get a can of frosty ice-cold Foster’s Lager in five minutes time.
</dd>
<dt>B1</dt>
<dd>
I get a poke in the eye with a burnt stick in five minutes time.
</dd>
</dl>
<p>I think that <strong>A1</strong> is better than <strong>B1</strong>. And I even think that conditional on them both being true, which I hope they aren’t. But on this model, we can’t have that. Because conditional on them both being true, the expected value of <em>m</em> conditional on either of them is the same as the expected value <em>m</em> simpliciter. So conditional on their both being true, it isn’t true that <strong>A1</strong> is better than <strong>B1</strong>.</p>
<p>This is already a violation of constraint 3. But as Russell and Hawthorne go on to point out, a lot of strange things start to follow if we don’t want to violate constraint 2 as well. We just proved that conditional on <strong>A1</strong> ∧ <strong>B1</strong>, it must be false that <strong>A1</strong> is better than <strong>B1</strong>. That is, conditional on <strong>A1</strong> ∧ <strong>B1</strong>, the probability of <strong>A1</strong> is better than <strong>B1</strong> must be 0. If the way to update on <strong>A1</strong> ∧ <strong>B1</strong> is by conditionalisation, it follows that the current probability of the conjunction of <strong>A1</strong>,&nbsp;<strong>B1</strong> and <strong>A1</strong> is better than <strong>B1</strong> must be 0. So conditional on <strong>A1</strong> is better than <strong>B1</strong>, which is surely true, the conjunction of <strong>A1</strong> and <strong>B1</strong> must have probability 0. And that’s true for any <em>A, B</em> such that right now it’s known that <em>A</em> is better than <em>B</em>. This is all absurd. Now perhaps this isn’t a violation of constraint 2, because I’m assuming here that update is by conditionalisation, and maybe there is a principled way to reject that in cases like this. In any case, this option for how to understand <em>e</em> fails constraint 3, so it must be wrong.</p>
<p>The way this option failed suggested a distinct move. What’s true about <strong>A1</strong> and <strong>B1</strong> is not that given they are both true,&nbsp;<strong>A1</strong> will make the world better than <strong>B1</strong> will. After all, given they are both true, they won’t make any (further) difference to the world. So perhaps when assessing <strong>A1</strong> and <strong>B1</strong> for value, we should look at their initial value, or their value given the (absolutely) prior probability.</p>
<p>The problem with this approach is that it doesn’t allow learning. Assume we learn <em>C</em>, than if I get poked in the eye with a burnt stick in five minutes, then malaria will be cured. Then it would be false that <strong>A1</strong> is better than <strong>B1</strong>, and indeed true that <strong>B1</strong> is better than <strong>A1</strong>. (Although, owww!) So this approach also violates constraint 3. And, for the same reason, it violates constraint 4.</p>
<p>Maybe the approach is to rigidify. What it means to say that <em>A is better than B</em> is that given the actual evidence I currently have,&nbsp;<em>A</em> has a higher expected <em>m</em> value than <em>B</em>. This will handle the the Foster’s/poke case fairly well. But it leads to other problems. The following is a simple variant of the Rembrant case <span class="citation" data-cites="RussellHawthorne2016">Russell and Hawthorne (<a href="references.html#ref-RussellHawthorne2016" role="doc-biblioref">2016, 331</a>)</span> offer.</p>
<p>Imagine we’re in the simpler of the dart cases. When a dart lands on ⟨<em>x</em>,&nbsp;<em>y</em>⟩, then each of the five possibilities that it is on that very spot, or that it is one spot up, down, left or right are equally likely. And the dart did in fact land on ⟨8,&nbsp;3⟩. At the same time, two fair coins have been tossed, although the results of them are hidden. Now compare the following options:</p>
<dl>
<dt>A2</dt>
<dd>
I get a Vegemite sandwich if the dart landed on ⟨8,&nbsp;4⟩, ⟨8,&nbsp;2⟩, ⟨7,&nbsp;3⟩ or ⟨9,&nbsp;3⟩, and nothing otherwise.
</dd>
<dt>B2</dt>
<dd>
I get a Vegemite sandwich if at least one of the coins landed heads, and nothing otherwise.
</dd>
</dl>
<p>Right now <strong>A2</strong> is better than <strong>B2</strong>. That’s because given my evidence,&nbsp;<strong>A2</strong> gets me a 0.8 chance of a Vegemite sandwich, and <strong>B2</strong> gets me a 0.75 chance. (Assuming, as is completely obvious, that more Vegemite sandwiches are better than fewer.) But conditional on <strong>A2</strong> is better than <strong>B2</strong>, I should prefer <strong>B2</strong>. That’s because the only worlds where <strong>A2</strong> is better than <strong>B2</strong> are worlds where the dart landed on ⟨8,&nbsp;3⟩. And in those worlds, I don’t get a Vegemite sandwich from <strong>A2</strong>.</p>
<p>So this rigid interpretation of ‘better’ violates constraint 4: it makes betterness judgments not be action guiding. I prefer <strong>A2</strong> to <strong>B2</strong>, but conditional on <strong>A2</strong> being better than <strong>B2</strong>, I prefer <strong>B2</strong>. Personally, I think this is the best interpretation of ‘better’, but that’s because I think our choices shouldn’t be guided by our beliefs about, or our evidence about, what’s better than what.</p>
<p>I haven’t given a watertight proof here that there is no way to interpret ‘better’ in this kind of model, or any other kind of model, that satisfies the four constraints. But philosophers who think moral uncertainty matters for decision making haven’t typically appreciated how hard it is to get a model that does satisfy these constraints. The ‘desire as belief’ results are fairly surprising, and when combined with anti-luminosity principles, they make it very hard to see how moral uncertainty could be relevant to decision making.</p>


<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list" style="display: none">
<div id="ref-Adler2002" class="csl-entry" role="listitem">
Adler, Jonathan E. 2002. <span>“Akratic Believing?”</span> <em>Philosophical Studies</em> 110: 1–27. <a href="https://doi.org/10.1023/A:1019823330245">https://doi.org/10.1023/A:1019823330245</a>.
</div>
<div id="ref-CappelenDever2014" class="csl-entry" role="listitem">
Cappelen, Herman, and Josh Dever. 2014. <em>The Inessential Indexical</em>. Oxford: Oxford University Press.
</div>
<div id="ref-Christensen2010b" class="csl-entry" role="listitem">
Christensen, David. 2010. <span>“Rational Reflection.”</span> <em>Philosophical Perspectives</em> 24: 121–40. <a href="https://doi.org/10.1111/j.1520-8583.2010.00187.x">https://doi.org/10.1111/j.1520-8583.2010.00187.x</a>.
</div>
<div id="ref-Greco2014" class="csl-entry" role="listitem">
Greco, Daniel. 2014. <span>“A Puzzle about Epistemic Akrasia.”</span> <em>Philosophical Studies</em> 167: 201–19. <a href="https://doi.org/10.1007/s11098-012-0085-3">https://doi.org/10.1007/s11098-012-0085-3</a>.
</div>
<div id="ref-HawthorneMagidor2009" class="csl-entry" role="listitem">
Hawthorne, John, and Ofra Magidor. 2009. <span>“Assertion, Context, and Epistemic Accessibility.”</span> <em>Mind</em> 118 (470): 377–97. <a href="https://doi.org/10.1093/mind/fzp060">https://doi.org/10.1093/mind/fzp060</a>.
</div>
<div id="ref-HawthorneMagidor2011" class="csl-entry" role="listitem">
———. 2011. <span>“Assertion and Epistemic Opacity.”</span> <em>Mind</em> 119 (476): 1087–1105. <a href="https://doi.org/10.1093/mind/fzq093">https://doi.org/10.1093/mind/fzq093</a>.
</div>
<div id="ref-Hookway2001" class="csl-entry" role="listitem">
Hookway, Christopher. 2001. <span>“Epistemic Akrasia and Epistemic Virtue.”</span> In <em>Virtue Epistemology: Essays on Epistemic Virtue and Responsibility</em>, edited by Abrol Fairweather and Linda Trinkaus Zagzebski, 178–99. Oxford: Oxford University Press.
</div>
<div id="ref-Horowitz2014" class="csl-entry" role="listitem">
Horowitz, Sophie. 2014. <span>“Epistemic Akrasia.”</span> <em>No<span>û</span>s</em> 48 (4): 718–44. <a href="https://doi.org/10.1111/nous.12026">https://doi.org/10.1111/nous.12026</a>.
</div>
<div id="ref-Hurley1989" class="csl-entry" role="listitem">
Hurley, Susan. 1989. <em>Natural Reasons</em>. Oxford: Oxford University Press.
</div>
<div id="ref-Lewis1979" class="csl-entry" role="listitem">
Lewis, David. 1979. <span>“Attitudes <em>de Dicto</em> and <em>de Se</em>.”</span> <em>Philosophical Review</em> 88 (4): 513–43. <a href="https://doi.org/10.2307/2184843">https://doi.org/10.2307/2184843</a>.
</div>
<div id="ref-Lewis1988b" class="csl-entry" role="listitem">
———. 1988. <span>“Desire as Belief.”</span> <em>Mind</em> 97 (387): 323–32. <a href="https://doi.org/10.1093/mind/XCVII.387.323">https://doi.org/10.1093/mind/XCVII.387.323</a>.
</div>
<div id="ref-Lewis1996a" class="csl-entry" role="listitem">
———. 1996. <span>“Desire as Belief <span>II</span>.”</span> <em>Mind</em> 105 (418): 303–13. <a href="https://doi.org/10.1093/mind/105.418.303">https://doi.org/10.1093/mind/105.418.303</a>.
</div>
<div id="ref-Littlejohn2012" class="csl-entry" role="listitem">
Littlejohn, Clayton. 2012. <em>Justification and the Truth-Connection</em>. Cambridge: Cambridge University Press.
</div>
<div id="ref-Littlejohn2015" class="csl-entry" role="listitem">
———. 2018. <span>“Stop Making Sense? On a Puzzle about Rationality.”</span> <em>Philosophy and Phenomenological Research</em> 96 (2): 257–72. <a href="https://doi.org/10.1111/phpr.12271">https://doi.org/10.1111/phpr.12271</a>.
</div>
<div id="ref-WeathersonMaitra2010" class="csl-entry" role="listitem">
Maitra, Ishani, and Brian Weatherson. 2010. <span>“Assertion, Knowledge and Action.”</span> <em>Philosophical Studies</em> 149 (1): 99–118. <a href="https://doi.org/10.1007/s11098-010-9542-z">https://doi.org/10.1007/s11098-010-9542-z</a>.
</div>
<div id="ref-Morison2014" class="csl-entry" role="listitem">
Morison, Benjamin. 2014. <span>“Sextus Empiricus.”</span> In <em>The Stanford Encyclopedia of Philosophy</em>, edited by Edward N. Zalta, Spring 2014. Metaphysics Research Lab, Stanford University. <a href="http://plato.stanford.edu/archives/spr2014/entries/sextus-empiricus/">http://plato.stanford.edu/archives/spr2014/entries/sextus-empiricus/</a>.
</div>
<div id="ref-NissanRozen2015" class="csl-entry" role="listitem">
Nissan-Rozen, Ittay. 2015. <span>“Against Moral Hedging.”</span> <em>Economics and Philosophy</em> 31 (3): 349–69. <a href="https://doi.org/10.1017/S0266267115000206">https://doi.org/10.1017/S0266267115000206</a>.
</div>
<div id="ref-Owens2002" class="csl-entry" role="listitem">
Owens, David. 2002. <span>“Epistemic Akrasia.”</span> <em>The Monist</em> 85 (3): 381–97.
</div>
<div id="ref-Price1989" class="csl-entry" role="listitem">
Price, Huw. 1989. <span>“Defending Desire-as-Belief.”</span> <em>Mind</em> 98 (389): 119–27. <a href="https://doi.org/10.1093/mind/XCVIII.389.119">https://doi.org/10.1093/mind/XCVIII.389.119</a>.
</div>
<div id="ref-Ribeiro2011" class="csl-entry" role="listitem">
Ribeiro, Brian. 2011. <span>“Epistemic Akrasia.”</span> <em>International Journal for the Study of Scepticism</em> 1: 18–25. <a href="https://doi.org/10.1163/221057011X554151">https://doi.org/10.1163/221057011X554151</a>.
</div>
<div id="ref-RussellHawthorne2016" class="csl-entry" role="listitem">
Russell, Jeffrey Sanford, and John Hawthorne. 2016. <span>“General Dynamic Triviality Theorems.”</span> <em>Philosophical Review</em> 125 (3): 307–39. <a href="https://doi.org/10.1215/00318108-3516936">https://doi.org/10.1215/00318108-3516936</a>.
</div>
<div id="ref-Smithies2012" class="csl-entry" role="listitem">
Smithies, Declan. 2012. <span>“Moore’s Paradox and the Accessibility of Justification.”</span> <em>Philosophy and Phenomenological Research</em> 85 (2): 273–300. <a href="https://doi.org/10.1111/j.1933-1592.2011.00506.x">https://doi.org/10.1111/j.1933-1592.2011.00506.x</a>.
</div>
<div id="ref-Srinivasan2015" class="csl-entry" role="listitem">
Srinivasan, Amia. 2015. <span>“<span>A</span>re <span>W</span>e <span>L</span>uminous?”</span> <em><span>P</span>hilosophy and <span>P</span>henomenological <span>R</span>esearch</em> 90 (2): 294–319. <a href="https://doi.org/10.1111/phpr.12067">https://doi.org/10.1111/phpr.12067</a>.
</div>
<div id="ref-Titelbaum2015" class="csl-entry" role="listitem">
Titelbaum, Michael. 2015. <span>“Rationality’s Fixed Point (or: In Defence of Right Reason).”</span> <em>Oxford Studies in Epistemology</em> 5: 253–94. <a href="https://doi.org/10.1093/acprof:oso/9780198722762.003.0009">https://doi.org/10.1093/acprof:oso/9780198722762.003.0009</a>.
</div>
<div id="ref-Titelbaum2016" class="csl-entry" role="listitem">
———. 2016. <span>“Self-Locating Credences.”</span> In <em>Oxford Handbook of Probability and Philosophy</em>, edited by Alan Hájek and Christopher Hitchcock, 666–80. <span>O</span>xford <span>U</span>niversity <span>P</span>ress. <a href="https://doi.org/10.1093/oxfordhb/9780199607617.013.34">https://doi.org/10.1093/oxfordhb/9780199607617.013.34</a>.
</div>
<div id="ref-Weatherson2004" class="csl-entry" role="listitem">
Weatherson, Brian. 2004. <span>“Luminous Margins.”</span> <em>Australasian Journal of Philosophy</em> 82 (3): 373–83. <a href="https://doi.org/10.1080/713659874">https://doi.org/10.1080/713659874</a>.
</div>
<div id="ref-Williamson2000" class="csl-entry" role="listitem">
Williamson, Timothy. 2000. <em><span class="nocase">Knowledge and its Limits</span></em>. Oxford University Press.
</div>
<div id="ref-Williamson2011" class="csl-entry" role="listitem">
———. 2011. <span>“<span>I</span>mprobable <span>K</span>nowing.”</span> In <em><span>E</span>videntialism and Its <span>D</span>iscontents</em>, edited by T. Dougherty, 147–64. <span>O</span>xford <span>U</span>niversity <span>P</span>ress. <a href="https://doi.org/10.1093/acprof:oso/9780199563500.003.0010">https://doi.org/10.1093/acprof:oso/9780199563500.003.0010</a>.
</div>
<div id="ref-Williamson2014" class="csl-entry" role="listitem">
———. 2014. <span>“Very Improbable Knowing.”</span> <em>Erkenntnis</em> 79 (5): 971–99. <a href="https://doi.org/10.1007/s10670-013-9590-9">https://doi.org/10.1007/s10670-013-9590-9</a>.
</div>
</div>
</section>


</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
    const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
    const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
    let newTheme = '';
    if(darkModeDefault) {
      newTheme = isAlternate ? baseTheme : alternateTheme;
    } else {
      newTheme = isAlternate ? alternateTheme : baseTheme;
    }
    const changeGiscusTheme = () => {
      // From: https://github.com/giscus/giscus/issues/336
      const sendMessage = (message) => {
        const iframe = document.querySelector('iframe.giscus-frame');
        if (!iframe) return;
        iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
      }
      sendMessage({
        setConfig: {
          theme: newTheme
        }
      });
    }
    const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
    if (isGiscussLoaded) {
      changeGiscusTheme();
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  const darkModeDefault = false;
  let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
    toggleGiscusIfUsed(toAlternate, darkModeDefault);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    const typesetMath = (el) => {
      if (window.MathJax) {
        // MathJax Typeset
        window.MathJax.typeset([el]);
      } else if (window.katex) {
        // KaTeX Render
        var mathElements = el.getElementsByClassName("math");
        var macros = [];
        for (var i = 0; i < mathElements.length; i++) {
          var texText = mathElements[i].firstChild;
          if (mathElements[i].tagName == "SPAN") {
            window.katex.render(texText.data, mathElements[i], {
              displayMode: mathElements[i].classList.contains('display'),
              throwOnError: false,
              macros: macros,
              fleqn: false
            });
          }
        }
      }
    }
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        typesetMath(container);
        return container.innerHTML
      } else {
        typesetMath(note);
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      typesetMath(note);
      return note.innerHTML;
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./circles.html" class="pagination-link  aria-label=" &lt;span="" epistemic="" and="" benign&lt;="" span&gt;"="">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Circles, Epistemic and Benign</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./screening.html" class="pagination-link" aria-label="<span class='chapter-number'>11</span>&nbsp; <span class='chapter-title'>Screening and Regresses</span>">
        <span class="nav-page-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Screening and Regresses</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




</body></html>