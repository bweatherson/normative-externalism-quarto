## Double Standards {#doublestandards}

This chapter wraps up three loose ends. First, I discuss whether hypocrisy is a vice. I'm going to argue that it isn't, and say why this matters to the broader issue of normative externalism. Second, I'm going to say why I haven't relied on arguments about inter-theoretic value comparison to argue for normative externalism. Roughly, I think those arguments over-generalise, so it is a mistake to use them here. And finally, I'll say something about which aspects of normative externalism are central to the view, and which are peripheral. This will serve as a summing up of this part of the book, and help bring into focus how the different parts fit together.

### Hypocrites

[Janus]{acronym-label="Janus" acronym-form="singular+short"} has the following odd set of views. He has basically correct views about the physiology of animals that are used for livestock. On the basis of these views, and some straightforward philosophical reflection, he has concluded that meat eating is almost certainly impermissible. Given the philosophical evidence available to him, this isn't a particularly irrational view to have, but it is false in the world he is in. And this is good luck for [Janus]{acronym-label="Janus" acronym-form="singular+short"}, since he eats meat at every opportunity.

Here's a natural objection to the simple externalism I have so far defended.

1.  [Janus]{acronym-label="Janus" acronym-form="singular+short"} is, in some way or other, criticisable.

2.  According to simple forms of normative externalism, he is not criticisable, since what he does is not wrong.

3.  So simple forms of normative externalism are wrong.

I'm going to primarily push back against premise 1 here. While there is some intuitive pull to the idea that [Janus]{acronym-label="Janus" acronym-form="singular+short"} is criticisable, I will argue that intuition can easily be explained away. But first, I'll start with a couple of clarifications of the case.

#### Why hypocrisy? {#whyhypocrisy}

Some readers may be wondering why I'm talking about [Janus]{acronym-label="Janus" acronym-form="singular+short"}'s hypocrisy, rather than his akrasia. After all, 'akrasia' is the standard philosophers' term for a person who acts against their better judgment. And hypocrisy is attached to doing other than what one says is right, as much as doing what one doesn't think is right.

On that last point, I think hypocrisy applies to more people than just the character who says one thing and does another. It seems fine to me to describe Robinson Crusoe as hypocritical if he comes to a firm opinion that some action is wrong, and then goes and does it. Perhaps we can understand this case as Crusoe making a speech to himself, and then being hypocritical for acting against his (inner) speech. But that feels at best like a forced reading of the case. It is more natural to say that actions can be hypocritical even if they don't conflict with any prior speech of the agent, if they do conflict in some way with her judgments.

Still, why not describe this as akrasia? Well, for one thing the term 'akrasia' is barely a term of English. There is the English expression 'weakness of will', but this has very little to do with the phenomenon we're considering here Â [@Holton1999]. To the extent we understand what it is to be akratic, we understand it stipulatively. But as we'll see below, there are some tricky borderline cases of hypocrisy. I would like to use our intuitive judgments to help clarify those cases. But I can hardly ask the reader to share intuitions about akrasia, since it is a notion introduced by stipulation.

#### The Hypocrite and the Rationaliser {#thehypocriteandtherationaliser}

I've known the occasional person like [Janus]{acronym-label="Janus" acronym-form="singular+short"}, but in many ways he seems like a rather foreign character. A much more common character, at least in the circles I typically move in, is the person who comes up with rationalizations for their particular behaviour. (I'm drawing heavily in this subsection on what Eric @Schwitzgebel2011 says about rationalizations.) It is not obvious why one would think that that making these rationalizations is a moral improvement. Indeed, I suspect I prefer the character who faces up to their own moral failures to the one who constantly finds a spurious reason to justify their own behaviour.

I only bring this up to note that if you're like me, it might be a little hard to make firm judgments about [Janus]{acronym-label="Janus" acronym-form="singular+short"}. After all, [Janus]{acronym-label="Janus" acronym-form="singular+short"} is so foreign, so Other, that he doesn't attract our normal sympathies, and without those sympathies we aren't great at moral judgments. I'm not going to lean heavily on this point, but I do think that it is a reason to suspect that we might not be the best judge of people like [Janus]{acronym-label="Janus" acronym-form="singular+short"}.

#### Recklessness and Character {#recklessnessandcharacter}

My preferred thing to say about [Janus]{acronym-label="Janus" acronym-form="singular+short"} is that his action is not in itself criticisable, but that actions like this are revealing of a character flaw that is worrying. (This diagnosis borrows from some suggestions @HawthorneSrinivasan2013 make about how to analyse a parallel case in epistemology.) The character flaw is not taking the interests of others as seriously as one should, especially in comparison to one's own interests. One way to do that is adopt theories or standards that are helpful to oneself. Another is simply to ignore what one thinks are the appropriate standards in one's actions.

Now [Janus]{acronym-label="Janus" acronym-form="singular+short"} is not, by hypothesis, doing anything wrong. He puts his own desire for meat above the interests of the animals who are killed to provide the meat. And by hypothesis that's fine, since his interests are sufficiently more significant. But humans are notoriously bad at balancing their own interests with the interests of others. Someone who acts so as to promote their own pleasure over the interests of others, even in cases where they have judged the others' interests to be more significant, seems very prone to selfish action. We want people to act against their own interests, when the interests of others are sufficiently strong. It is true that [Janus]{acronym-label="Janus" acronym-form="singular+short"} does not violate this desideratum. But since he thinks he violates it, it is likely that he will actually violate it next time he gets a chance. It is reasonable to worry about the character of such a person, even if the particular thing they are doing is not objectionably selfish.

To support this interpretation of the case, let's compare [Janus]{acronym-label="Janus" acronym-form="singular+short"} to someone whose actions against their moral judgments are not self-serving. [Yori]{acronym-label="Yori" acronym-form="singular+short"} is both a parent and an academic. It's hiring season, and [Yori]{acronym-label="Yori" acronym-form="singular+short"} has a bunch of job applications to read. He has read them all closely, but worries that he really should go back and look at a few a bit more closely before tomorrow's meeting. But he doesn't have time to do that and attend his child's soccer game, and he knows his presence at the game will mean a lot to his child. [Yori]{acronym-label="Yori" acronym-form="singular+short"} thinks that his professional obligations are stronger than his parental obligations, so he should re-read the files. But he can't bring himself to disappoint his child in this way, so he goes to the soccer game. He doesn't get any pleasure from this. He finds the soccer deathly boring. And while he would feel guilty if he skipped the game, and this feeling would not be pleasurable, as it is he feels equally bad about the files. Now it turns out [Yori]{acronym-label="Yori" acronym-form="singular+short"} has a bad theory of duty. Given the work he has already put in, his parental duties are stronger than his professional duties, so he does the right thing. And he even does the right thing for basically the right reason, being motivated by his child's feelings. (I'm assuming here that being unable to bring oneself to disappoint a child is a perfectly acceptable way to be moved by a child's feelings. If you don't agree, you may have to change the story, but for what it's worth I think that assumption is true.)

While we might criticise [Yori]{acronym-label="Yori" acronym-form="singular+short"} for his false moral theory, we should not criticise his action in any way. He does the right thing, and does it for the right reason, even if he falsely believes that this very reason is not a strong enough reason. [Yori]{acronym-label="Yori" acronym-form="singular+short"} is, just like [Huck]{acronym-label="Huck" acronym-form="singular+short"}leberry Finn, a case of inadvertent virtue.

[Yori]{acronym-label="Yori" acronym-form="singular+short"} is like [Janus]{acronym-label="Janus" acronym-form="singular+short"} in one respect; he acts against his judgment of what is best to do. And he is unlike [Janus]{acronym-label="Janus" acronym-form="singular+short"} in a different respect; he does not act selfishly. The appropriate attitudes to take towards [Yori]{acronym-label="Yori" acronym-form="singular+short"} and [Janus]{acronym-label="Janus" acronym-form="singular+short"} are very different; the kind of negative attitude that is natural to take towards [Janus]{acronym-label="Janus" acronym-form="singular+short"} is uncalled for when it comes to [Yori]{acronym-label="Yori" acronym-form="singular+short"}.

And this suggests that the explanation for that negative attitude towards [Janus]{acronym-label="Janus" acronym-form="singular+short"} comes from the respect in which he differs from [Yori]{acronym-label="Yori" acronym-form="singular+short"}, not from the respect in which the two of them are alike. That is to say, [Janus]{acronym-label="Janus" acronym-form="singular+short"} is criticisable, to the extent he is, because he acts selfishly, not because he acts against his best judgment.

Selfish action is not always wrong. Sometimes, you should put yourself first. Happily, [Janus]{acronym-label="Janus" acronym-form="singular+short"} is in such a situation. So why do we criticise him? It is not because he does something wrong, but because he reveals bad character. If he does something wrong, it is something that [Yori]{acronym-label="Yori" acronym-form="singular+short"} too does wrong; yet [Yori]{acronym-label="Yori" acronym-form="singular+short"} does nothing wrong. [Janus]{acronym-label="Janus" acronym-form="singular+short"}'s actions reveal a worryingly selfish personality. Even if this very action wasn't selfish, it's a good bet that he will soon act in a way that's objectionably selfish. That's not true about [Yori]{acronym-label="Yori" acronym-form="singular+short"}.

And this is all evidence that hypocrisy isn't in itself a vice. [Yori]{acronym-label="Yori" acronym-form="singular+short"} is hypocritical; he thinks he be reading job applications, but instead finds himself at a children's soccer game. But this isn't something bad about his actions, or even his character. Indeed, it would have been worse to act in accord with his false views about duty.

And that is the key thing for normative externalists to say about hypocrisy. Often, the hypocrite does something bad, and that should be criticised. In many other cases, the hypocrite reveals a character flaw that will, quite probably, lead to bad actions in the near future. That too should be criticised, at least with the aim of preventing the bad actions from happening in the near future. But sometimes the hypocrite simply does the right thing, and ignores their false moral views. That isn't bad, and isn't even a character flaw. There is nothing wrong with simply doing the right thing, even if one doesn't recognise it.

### Value Comparisons {#valuecomparisons}

There is a prominent argument against normative internalism that I have not discussed here. This is the problem of inter-theoretic value comparisons Â [@Sepielli2009; @Hedden2015]. I haven't discussed it because I don't think it is as big a problem for internalism as some of my fellow externalists do. But it is an interesting problem, and thinking about how it could be solved shows some constraints on the form of a viable internalism.

[Ulysses]{acronym-label="Ulysses" acronym-form="singular+short"} is trying to decide between two problematic forms of action. If he does action A, he will break a promise to his dear wife, [Penelope]{acronym-label="Penelope" acronym-form="singular+short"}, but he will also improve the welfare of hundreds of people on the island he is visiting. If he does action B, he will be able to keep the promise, but he will lose the opportunity to help the people around him. [Ulysses]{acronym-label="Ulysses" acronym-form="singular+short"} is also torn between two moral theories. One is a welfare consequentialist theory that says he should do action A, and the other is a deontological theory that says he should do action B. Let's assume that he is reasonable in being so torn. (This is a huge simplification, but the problem doesn't change with fewer simplifications, it just becomes harder to state.) What should he do?

The externalist says that we need to know whether the consequentialist or the deontological theory is correct, and that will determine what [Ulysses]{acronym-label="Ulysses" acronym-form="singular+short"} should do. But some internalists don't like this answer. They note, correctly, that it is really hard to work out what the right moral theory is. And they think that it shouldn't be so hard to work out what to do. So [Ulysses]{acronym-label="Ulysses" acronym-form="singular+short"} must be able to do something with just the knowledge he has. (Or so say the internalists. I obviously disagree, but we'll set aside my disagreement for the moment.)

What options does [Ulysses]{acronym-label="Ulysses" acronym-form="singular+short"} have? If he knew one of the moral theories was more likely than the other, perhaps he could just do the thing recommended by the more likely moral theory. But we've assumed that [Ulysses]{acronym-label="Ulysses" acronym-form="singular+short"} knows no such thing. So perhaps the thing to do is to maximise expected moral value. To do that, we just need to know whether $x > y$, where $x$ and $y$ are defined as follows:

-   $x$ = the amount which action A is better than action B, according to the version of consequentialism [Ulysses]{acronym-label="Ulysses" acronym-form="singular+short"} takes seriously.

-   $y$ = the amount which action B is better than action A, according to the deontological moral theory that [Ulysses]{acronym-label="Ulysses" acronym-form="singular+short"} takes seriously.

The problem is, how are we going to find out whether $x > y$? We can't look to either of the moral theories that [Ulysses]{acronym-label="Ulysses" acronym-form="singular+short"} takes seriously. They can only answer questions internal to themselves; they can't say how to compare something that's wrong by their lights to a kind of wrongness taken seriously by a rival theory. What we need is a comparison of wrongness across theories. That is, we need an inter-theoretic comparison of wrongness. Or, as it is sometimes put, we need an inter-theoretic value comparison. (It sometimes seems to me that there is an implicit consequentialism built into this way of putting the problem, but set that worry aside.)

Now there are a number of moves that have been proposed for how to get around this impasse, and a number of criticisms of each of them. What I'm interested in here is the following argument.

1.  If normative internalism is true, there is a solution to the problem of inter-theoretic value comparison.

2.  There is no solution to the problem of inter-theoretic value comparison.

3.  So, normative internalism is false.

Premise 2 of this argument is false. I don't say that because I know the solution, or because I have an argument in favour of a particular solution. What I do have is an argument that a solution must exist. The argument turns on considerations about democracy and representation.

[Saraswati]{acronym-label="Saraswati" acronym-form="singular+short"} is a good democratic representative. She currently faces a tricky decision between two options. One option will maximise welfare, but breach some moral principles that are often held to be important. The other option will do neither of these things. Now as it turns out, the true moral theory in [Saraswati]{acronym-label="Saraswati" acronym-form="singular+short"}'s world is a kind of pluralism that says it is morally permissible to make either choice when acting for oneself, and making this kind of choice. But [Saraswati]{acronym-label="Saraswati" acronym-form="singular+short"} isn't acting for herself, she is a representative. And representatives have a duty to represent, at least in cases where the people want them to act in morally permissible ways. And it turns out [Saraswati]{acronym-label="Saraswati" acronym-form="singular+short"}'s constituents are torn. Half of them are committed welfarist consequentialists, the other half are deontologists. Assume further that [Saraswati]{acronym-label="Saraswati" acronym-form="singular+short"} has not promised, either implicitly or explicitly, to make one choice rather than the other in this kind of situation.

Given all those assumptions, what [Saraswati]{acronym-label="Saraswati" acronym-form="singular+short"} should do turns on the correct answer to the problem of inter-theoretic value comparison. What she should do depends, at least in part, on whether the welfare loss matters more to her welfarist constituents than the principle violation matters to her principled constituents. That is to say, what she should do turns on exactly the same kind of question that [Ulysses]{acronym-label="Ulysses" acronym-form="singular+short"} faced when he was deciding whether $x > y$.

Now as an externalist, I don't think [Saraswati]{acronym-label="Saraswati" acronym-form="singular+short"} has to in any sense solve the problem of inter-theoretic value comparison. She just has to do the right thing for the right reasons. And one can do the right thing for the right reasons without knowing they are the right reasons, or even without having any general disposition to act rightly in similar cases. But I do think that we as theorists need to solve the problem in order to say anything evaluative about [Saraswati]{acronym-label="Saraswati" acronym-form="singular+short"}'s actions. And even if we can't do that, if we believe there is a fact of the matter about whether [Saraswati]{acronym-label="Saraswati" acronym-form="singular+short"} did the right thing, then we are committed to thinking that there is a solution to the problem of inter-theoretic value comparisons.

So premise 2 in the externalist argument above is not true. There is a way, somehow, of solving the problem of inter-theoretic value comparisons. That's not to say it will be easy. Personally, I suspect it is one of the hardest problems in all of ethics. None of the remotely viable solutions to it seem either obvious to the lay actor, or easy to implement.

The difficulty of solving the problem does not show that normative internalism is false. But this difficulty does undermine a popular motivation for internalism. If the idea behind internalism is that there should be a sense of 'should' in which ordinary people can usually tell what they should do, that can't be a sense of 'should' which is sensitive to the correct solution to the problem of inter-theoretic value comparisons. So it is incoherent to motivate internalism by saying that externalism makes it too hard to know what to do, and then develop a theory of right action that requires a solution to the problem of inter-theoretic value comparisons.

As we've seen, this isn't the only way to motivate internalism. Some theorists motivate internalism by an analogy to the wrongness of reckless action. Those theorists often need there to be a solution to the problem of inter-theoretic value comparison, but they don't need this solution to be in any way transparent. And reflection on cases like [Saraswati]{acronym-label="Saraswati" acronym-form="singular+short"}'s makes me think that the externalist must concede that such a solution must exist, and so cannot rely on its non-existence in arguing against internalists.

It's worth noting just how strong a conclusion we could draw from the inter-theoretic value comparisons argument. Assume, for reductio, that we really couldn't make sense of any kind of inter-theoretic value comparison. It would follow that there is no way to define hypocrisy in probabilistic terms. Someone could only be counted as a hypocrite if they fully believed that what they were doing was wrong. But this doesn't seem right.

Imagine that someone faces a choice about whether to betray a confidence. The betrayal would be extremely disrespectful, but they think there would be a small gain to the welfare of the world if they did so. And while they mostly think respect is central to morality, then have a non-zero credence that welfare consequentialism is the correct moral theory. They break the confidence. Are they hypocritical? I think they probably are, even if we can't give an algorithm for weighing the downside of the betrayal on the moral theory they think is probably right against the welfarist upside on the theory they give a small credence to. If we think the problem of inter-theoretic welfare comparisons is not solvable in principle, then we can't even define a notion of hypocrisy that applies in cases like this. And that would be a very strong result. I don't think the arguments that hypocrisy is no vice are nearly as strong as the arguments against more systematic forms of internalism in chapters 2--4. So I suspect the argument from inter-theoretic value comparisons proves too much. It doesn't just rule out views like *The best thing to do is maximise expected goodness*, it also rules out views like *It's at least a minor vice to not live up to your own principles*. And that feels like too much weight for the argument to bear.

### The Externalist's Commitments {#theexternalistscommitments}

I'm going to finish up this part by saying a bit about what I take to be the more and less central parts of normative externalism. Like any -ism, the view not only makes many different commitments, those commitments differ greatly in strength. Setting out these commitments serves a few useful functions. It helps us see how the different parts of the view hang together. And it is good practice to say ahead of subsequent refutations what retreats would be minor setbacks, and what would amount to fleeing the field[^38]. It's very tempting when a part of one's view is shown to be flawed to insist that it was only a peripheral aspect of the view to begin with. Writing down which commitments are central and which are peripheral before the flaws are made visible is a way to avoid this temptation.

[^38]: I'm assuming here that there will indeed be subsequent refutations, but this follows from a version of the pessimistic induction.

The core idea is that moral norms are independent of both what one thinks the moral norms are, and what one should think the moral norms are. Here are a few ways that could fail that would threaten the periphery of the view; we'll then move to seeing what a catastrophic failure would look like.

First, there could be some one-way dependencies between moral norms and (rational) beliefs about moral norms. For instance, a view that said being true to oneself was one moral requirement among many would violate one direction of the externalist's independence constraint. It would say that believing that something is wrong is sufficient, but not necessary, to make performing the action wrong. And the view discussed in chapter five, where believing that an action is not wrong excuses it, violated the other direction. It says that believing that something is wrong is necessary, but not sufficient, for the performance to be blameworthy.

Second, there could be some dependencies that concern minor aspects of morality. The most natural versions of this possibility combine it with the one-way dependencies of the previous paragraph. Consider a view that said that hypocrisy is a minor vice. Such a view might say that it's bad to do what you think is wrong, but unless the belief is true, this is not a major vice. Or consider a view where false moral beliefs are partial excuses. These are paradigms of the 'peripheral' failures I was talking about above. What I want ultimately to argue for is that morality is about respect, welfare, rights and so on, and not about conformity to one's own principles. A view that says that morality is almost entirely about respect, welfare, rights and so on, but conformity to one's own principles has a small role too, is inconsistent with my preferred view, but the differences are minor.

The third kind of peripheral failure takes a little more setup. Consider again Descartes' view of the good person, and compare it with Kant's view. (I'm simplifying both thinkers here, but the caricatures are useful for setting out the philosophical point.) Both of them think that the good person will do what they think is right. But Descartes thinks this because he thinks that resoluteness is one of the supreme virtues. Kant, on the other hand, thinks this because he thinks that the nature of the moral law is visible to good people. So because the moral law is the way it is, the good person will both act a certain way, and have correlated beliefs about morality. For Descartes, the fact that the person beliefs that they should do X explains why it is good that they do X. For Kant, the fact that the moral law is the way it is explains both why it is good that the person does X, and good that they believe that X is good to do. In Descartes' case, but not Kant's, the moral beliefs explain the moral status of the action.

More generally, we can distinguish amongst views that say there is a connection between morality law and what one (reasonably) believes about morality. Some such views say that (reasonable) beliefs about morality explain why actions have the moral status they do. Other views say that the moral status of the actions explain why certain beliefs are actual or, more likely, reasonable. Yet other views say that some third thing explains both the moral status of the actions and the actual or reasonable beliefs about their moral status. What I'm really committed to denying is the first of these options, where actual or reasonable beliefs about morality explain the moral status of actions.

We can put all this in terms of a checklist. Ideally, from the point of view of normative externalism, there would be no necessary connections between moral properties, on the one hand, and actual or reasonable moral beliefs on the other hand. If, however, there is such a connection, we can ask three questions about it.

1.  Is the connection two-way, as opposed to moral beliefs providing merely a necessary or a sufficient condition for the moral property?

2.  Is the moral feature morally central, as opposed to being, say, a minor vice or virtue?

3.  Does the (actual or reasonable) moral belief explain why the moral property is instantiated, as opposed to the explanation going the other way, or some third factor explaining the connection?

The more 'yes' answers we give, the worse things are for normative externalism. The view I want to defend is that there are no necessary connections between moral belief and morality. But if there are such connections, I want to defend the view that these are one-way, or are minor, or that the moral belief does not explain the moral property. Being true to yourself is not part of morality. But if it is, it is a small part, and actions that are true to yourself aren't good because they are true to yourself.

This last possibility, the one about surprising orders of explanation, is a useful segue into epistemology. Here's another way that normative externalism could strictly speaking fail, without threatening the core commitments of the theory. There has been a pronounced 'factive turn' in recent epistemology. Many epistemologists think that our most important epistemological concepts are factive. The most important ways for beliefs to be good are such that if a belief is good in that way, it must be true. One way to implement the 'factive turn' is to make knowledge central to epistemology. But another way, not inconsistent with the first, is to argue that other epistemological notions are factive. And that turns out to have consequences for normative externalism.

Let's say that one thought, on quite general grounds, that only true beliefs could be rational, or that only truths could be well supported by evidence. I don't think either of those things, and I'll say a little more in the next part as to why, but for now I just want the view on the table. That would imply there is a necessary connection between rational moral beliefs and morality. If one rationally believes that lying is wrong, then it must be that lying is wrong. But that's not because the rationality of the belief explains the wrongness, or that the having of the belief explains the wrongness. It's because the wrongness of the lying is a necessary precondition of rationally believing that lying is wrong.

This kind of view would not show us anything special about morality. On such a view, if one rationally believes that lying is common, then it must be that lying is common. And it doesn't threaten the central commitments of normative externalism. But it does mean there is a necessary connection between morality and rational moral belief. So it's a small defeat, but one we can absorb without too much distress. When we turn to epistemology, we'll have to pay more attention to this kind of possibility.
