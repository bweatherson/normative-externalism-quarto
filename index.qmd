# Preface {#preface .unnumbered}

Philosophy is hard. Ethics is hard; epistemology is hard; decision theory is hard; logic is hard. All the parts of philosophy are hard, but those four are going to be particularly relevant to the story I'm telling here. They matter because they are all evaluative. Someone who violates ethical principles is immoral; someone who violates epistemological principles is irrational; someone who violates the principles of decision theory is imprudent; someone who violates logical principles is illogical. And to say that someone is immoral, irrational, imprudent or illogical is to negatively evaluate them.

But it is easy to feel uneasy with this set of facts. If it is so hard to figure out the truth in these fields, why should we negatively evaluate someone for failing to conform to these hard to find standards? Doesn't fairness require that we only judge people by standards they can know about? I'm going to argue this is not right - that to evaluate someone is necessarily to impose a standard on them, and they may not even know what the standard is. Indeed, they may not have any reason to believe the truth about what the standard is, and in extreme cases may have good reason to endorse a false standard.

This position is uncomfortable, since it is easy to feel the unfairness of holding someone to a standard that they do not accept, and could not reasonably accept. Many philosophers think that we should either supplement or replace these external standards with internal standards. An 'internal standard' here is one that the person being evaluated either accepts, or has good reason to accept. To supplement the external standards is to say that there are two ways to evaluate people. It is good to live up to the correct standards in ethics, epistemology and decision theory, and bad to violate them. But it is also, say the supplementers, good to live up to one's own standards, and bad to violate them. The replacers say that conformity to one's own standards is more important than conformity to external standards; in some deep sense (at least some of) the heroes of ethics, epistemology and decision theory are people who abide by their own standards.

I am going to press two problems against this kind of view. The problems are most pressing for the replacers, but they undermine the position of the supplementers too.

The first problem is that this kind of view has problems with fanatics and ideologues. Every ideologue who thought that they had figured out the one true way things must be done and reacted violently against those who didn't agree were doing well by their own lights. It's not good, in any way, to be that kind of ideologue. We shouldn't look back at the Reign of Terror and say, "Well, at least [Robespierre]{acronym-label="Robespierre" acronym-form="singular+short"} and [Saint-Just]{acronym-label="Saint-Just" acronym-form="singular+short"} were living in accordance with their own values." Aiming to fit the world to one's own values is a dangerous game; it's only worth playing if you've got the values right. When we focus our attention on ideologues who have gone off the rails, the idea that it is unfair to hold people to a standard they can't see feels like something that's problem in theory but not in practice.

The second problem with the the internal view is that it leads to a nasty regress. It is, to be sure, hard to tell what the true values are. But choosing some values does not end our problems. Morality is hard even once you've settled on a moral theory. This is a point familiar from, for example, Sartre's discussion of the young man torn between duty to his mother and his country.

> What could help him make that choice? The Christian doctrine? No. The Christian doctrine tells us we must be charitable, love our neighbour, sacrifice ourselves for others, choose the "narrow way," et cetera. But what is the narrow way? Whom should we love like a brother--the solider or the mother? $\dots$ Who can decide that *a priori*? No one. No code of ethics on record answers that question. Â [@Sartre1946 31]

We can evaluate the young man by his own lights and still be in a way unfair to him. Perhaps it turns out that the truly Christian thing to do is to fight Nazis, but the young man concludes (reasonably but falsely) that it is to help his mother. And he does that. If we are moved by the unfairness of holding him to a standard he does not endorse, we should also find it unfair to hold him to a consequence of his own standard that he doesn't recognise. But now what is left of the internal standard? It must be that it is good to do not what is best by one's own lights, but what one thinks is best by one's own lights. But perhaps one could even be wrong about *that*. (I'll discuss an example of this in chapter 1.) And the internal view collapses into the view that we should evaluate people by what they think they think they think $\dots$ their own views support.

This is all absurd, and it makes the problem with fanatics and ideologues even worse. Perhaps we could argue that some ideologues take actions that are incompatible with what they say their values are. But they do not act against what they think their own values require.

Perhaps we can motivate the importance of the internal point of view not by thinking about fairness, but by focussing on an analogy with reckless agents. If I fire a cannon down Fifth Avenue at peak hour, I do something morally horrible even if miraculously I don't hit anyone. My action is wrong because it is reckless. Perhaps if I do something that is probably morally wrong, I am morally reckless in just the same way. And that's true even if my action turns out not to be wrong. So what matters is not just what is right and wrong, but probabilities of rightness and wrongness. I think this kind of reasoning fails too, and there are important asymmetries between physical risk (as is involved in firing cannons down busy streets) and moral risk. I'll spend chapters three and four outlining these asymmetries, and why they tell against the idea that there is a distinctive wrong of moral recklessness.

The first half of the book discusses the significance of the internal point of view in ethics. As I've indicated, I don't think it is particularly important, though we'll spend a bit of time towards the end of part one looking at some more limited, and hence more plausible, claims for its usefulness. The second part of the book turns to epistemology, and to the idea that one cannot reasonably have beliefs that one believes (or should believe) to be unreasonable.

Again, the issue turns on how important is conformity to one's own standards. The most common philosophical view around here is a kind of supplementing view, not a replacing view. It is important, say several philosophers, to have beliefs that are both actually reasonable and also reasonable by one's own lights. And I'm going to push back against that. One reason comes from work by Timothy Williamson. What's reasonable to believe turns on empirical facts about one's situation. Since we don't have God-like perfect access to our own empirical situation, we might not realise what is reasonable to do in our own situation just because we don't know precisely what situation we are in. In such cases, it seems we should react to the situation we are actually in, not to our best guess about what situation that is.

There will be two primary themes of part two of the book. One echoes the first part of the book. Sometimes we cannot know what it would be to be reasonable by our own lights. So adding a requirement that reasonable people are doing well by their own lights threatens to trigger a vicious regress. I'm going to argue that this threat is realised. The other theme is that the phenomena that philosophers have thought could only be explained by adding an internal constraint onto belief can be adequately explained by a more careful attention to the nature of evidence, and what it takes for one to have evidence and for that evidence to support a belief. I'll argue that such explanations are preferable to explanations in terms of internal constraints (such as only believe what you believe is reasonable to believe). This is in part because they avoid regress and implausible knowledge about one's own situation; in part because they only commit us to things we are independently committed to; and in part because they explain a much broader range of cases than are explained by the alleged internal constraints.

I have more people to thank for help with this book than I could possibly list here. I'm not even sure at which point of time I should start the thanks. Twenty-odd years ago as a graduate student at Monash I wasn't working on *this* project. But the picture that pervades this book, that in philosophy everything is contestable and there are no safe stopping points, owes a lot to the amount of time I spent as a graduate student thinking about, and being taught about, heterodox approaches to logic and to decision theory.

Most of the best feedback I've received on the various parts of the book has come from graduate students. Some of the second part of the book is based on an epistemology seminar I taught at Rutgers. I taught a graduate seminar at Michigan off an early draft of the book manuscript. And I've taught several mini-courses at St Andrews, and presented at even more workshops and symposia there, off parts of the book. In every case the feedback I received from colleagues and, even more frequently, graduate students, changed the book for the better.

Parts of the book are based on presentations at or organised by the University of Aberdeen, University of Oxford, University of Vienna, University of Konstanz, University of Zurich, University of Graz, Massachusetts Institute of Technology, Princeton University, Ohio State University, University of Sydney, Australian National University and University of Melbourne. I've presented parts of it at the Bellingham Summer Philosophy Conference, the Night of Philosophy in New York City and the Australasian Association of Philosophy annual conference. And I've discussed it with the Corridor Reading Group in New York, and the Ethics Lunch group in Ann Arbor. I'm very grateful for all the feedback I got at those presentations.

As well as all those audiences, I'd like to particularly thank Derek Ball, Jessica Brown, Sarah Buss, Herman Cappelen, Ruth Chang, Stewart Cohen, Josh Dever, Tom Donaldson, Andy Egan, Claire Field, Katherine Hawley, Scott Hershowitz, Torfinn Huvenes, Jonathan Jenkins Ichikawa, Jim Joyce, Zoe Johnson King, Maria Lasonen-Aarnio, Ben Levinstein, Julia Markovits, Matthew McGrath, Sarah Moss, Jill North, Caroline Perry, Quentin Pharr, Lewis Ross, Andrew Sepielli, Joe Shin, Holly Smith, Martin Smith and Elia Zardini for particularly valuable feedback. (And I'm already dreading finding out who I should have included on this list but didn't.) Ralph Wedgwood read the whole manuscript and provided comments that improved it in innumerable ways. Thanks to him, and to Peter Momtchiloff for making such an astute choice of reader for the manuscript.

The idiosyncratic workflow I used for writing this would have been impossible without Fletcher Penney's Multimarkdown (both the language and the Composer software) and John MacFarlane's Pandoc, and I'm very grateful to both of them for building such valuable tools. Much of the book was drafted under the dome in the La Trobe Reading Room at the State Library of Victoria, and I'm so grateful that Victoria has maintained that space, and that building.

Early in the development of this book project, I was honoured to become the first Marshall M. Weinberg Professor of Philosophy at the University of Michigan, Ann Arbor. Without the support Marshall has provided to my research, and to the research project of the University of Michigan more broadly, this project would have been unimaginable. My inaugural lecture was "Running Risks Morally", most of which appears in one way or another in part one of the book. The first draft of the book was written while on a sabbatical funded through the Weinberg Professorship. But beyond that, the vibrant intellectual community here at Michigan relies in ever so many ways on Marshall's support. I couldn't tell you how much this book relies on feedback from graduate students who have received Weinberg fellowships, or who came to Michigan in part because of the Weinberg Center for Cognitive Science. While this is by no means a work of cognitive science, it is influenced in many ways by what I've learned from cognitive scientists talking at the Weinberg Center. And I really cannot thank Marshall enough for his support for Michigan, and for its research.

Finally, I'd like to thank Ishani Maitra and Nyaya Maitra Weatherson for, well, everything. Ishani didn't just talk through all the things in this book with me, and improved it in so many ways, but she also talked through all the things I cut from the book. And she improved those portions too.
