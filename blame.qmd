# Blame and Moral Ignorance {#blameandmoralignorance}

If an argument from premises concerning symmetry to a conclusion about internalism worked, we would get a very strong conclusion. It would turn out that true morality is irrelevant to our judgment of actions and persons. All we should use, when judging someone's actions, is the moral compass that they have. Or, perhaps, the moral compass that they should have given their evidence. As I have stressed though, the arguments for symmetry might undermine the availability of this fallback. It really looks like that if symmetry proves anything, it proves that the only moral standard (and indeed only epistemic standard) is (perceived) consistency with one's own values.

Put so baldly, it perhaps it isn't surprising that symmetry-based internalism as it was developed in the last three chapters ended up looking like a hopeless project. So it is time to look at alternative motivations for internalism, ones that suggest somewhat weaker forms of internalism. The views we looked at so far said that being true to one's own self (in one way or another) was both necessary and sufficient for the applicability of some key moral concept. Over the next two chapters, we'll look at views that drop one or other direction of that connection. So in this chapter, we'll look at views which say that conformity to one's own values is a sufficient condition for blamelessness. And in the next chapter, we'll look at views which say that conformity to one's own values is a necessary condition for avoiding all vices.

## Does Moral Ignorance Excuse? {#doesmoralignoranceexcuse}

In recent work on moral responsibility, many philosophers have argued that that blameless ignorance of what's right and wrong is exculpatory. Something is exculpatory if it provides a full excuse; it makes an agent not blameworthy for a wrong action they perform. So slightly more precisely, what these philosophers have argued for is a version of the following view.

> **Moral Ignorance Excuses (MIE)**\
> If agent S does act *X*, even if *X* is wrong, S is not blameworthy for this if:
>
> 1\. S believes that *X* is not wrong; and\
> 2. This belief of S's is not itself blameworthy; and\
> 3. The belief is tied in the right way to the performance of *X*.

The second and third clauses are vague, and getting clear on whether there is a way of resolving the vagueness that makes the theory viable is going to be a big part of the story to follow. But the vagueness also makes it plausible to attribute MIE to a lot of philosophers. A classic statement of MIE, that I'll return to at some length below, is in "Reproach and Responsibility" by Cheshire @Calhoun1989. But the view has been more recently defended by Gideon Rosen [-@Rosen2003; -@Rosen2004], Michael @Zimmerman2008 and Neil @Levy2009. And I plan to argue against all of these views.

Although I'll focus on philosophers such as Rosen and Zimmerman who have openly defended MIE, I've crafted the definition of MIE so that it is endorsed by many of their critics. In taking on MIE, then, I'm taking on a much broader range of philosophers than those who describe themselves as holding that moral ignorance excuses.

MIE is not a reductive account of blameworthiness; it uses the notion of blameworthy belief right there in the second clause. And through the 1990s and 2000s, much of the debate around MIE turned on how to understand that clause. Rosen and Zimmerman use MIE to argue for a very strong view. They think that mistaken moral beliefs are very rarely blameworthy, so they think MIE implies that people are rarely blameworthy. Or, at least, there are very few cases where we can be confident someone is blameworthy. This view is rejected by, for example, [Alex]{acronym-label="Alex" acronym-form="singular+short"}ander @Guerrero2007 and William @Fitzpatrick2008. Looking back to the earlier debate, Michelle @MoodyAdams1994 similarly rejects some of the practical conclusions that @Calhoun1989 draws. But all of these rejections are accompanied by acceptance of something like MIE. The complaint these philosophers are making is not that MIE fails, but that philosophers have been too generous in their application of clause 2. I'm arguing for the stronger claim, that MIE itself fails.

In recent years more philosophers have adopted the more radical view that MIE itself is false. Elizabeth Harman [-@Harman2011a; -@Harman2014] has argued against the view that moral mistakes can be exculpatory. Since Harman thinks that moral mistakes are themselves blameworthy, her view is in a technical sense consistent wth MIE. But that's only because she thinks that strictly speaking, it never applies. And the broader view on responsibility I'm adopting draws on work by Nomy @Arpaly2003, Angela @AngelaSmith2005 and Julia @Markovits2010.

Harman notes that the debate has been misnamed. When we talk about moral ignorance excusing, what we really mean is that moral *mistakes* might excuse. If someone is extremely confident that *X* is wrong, but not quite confident enough to know it, few philosophers would say that mental state is exculpatory when *X* is done. If they have a justified true belief that *X* is wrong, but don't strictly know this because their belief is in some other way defective, no one takes their lack of knowledge to be exculpatory. What matters are cases of moral mistake; cases where an agent firmly and reasonably has a moral belief that's simply false. Harman notes that this point is at least implicit in Guerrero's response to Rosen  [@Guerrero2007], and a similar point is made by Rik @Peels2010.

In order to keep terminological consistency with most of the debate, while avoiding getting caught up on the point of the last paragraph, I'll make some more terminological stipulations. Say that a person is **thoroughly ignorant** of a truth *p* iff she believes ¬*p*. And then the live issue is whether thorough moral ignorance excuses. I'll assume that when other writers hypothesise that moral ignorance excuses, the term 'thorough' has been elided. And I will join them in this way of writing.

## Why Believe MIE? {#whybelievemie}

There are three main classes of arguments that have been given for MIE. The first is what I'll call the Argument from Symmetry, defended by @Rosen2003 [64] and @Zimmerman2008 [192].

1.  Cases like Adelajdra's and [Billie]{acronym-label="Billie" acronym-form="singular+short"}'s show us that mistakes about matters of fact can excuse wrongdoing.
2.  Moral mistakes and non-moral mistakes should be treated the same way.
3.  So moral mistakes can excuse wrongdoing.

I've in effect already offered two responses to this argument. Adelajdra and [Billie]{acronym-label="Billie" acronym-form="singular+short"} don't do anything wrong, so they don't need an excuse, so they aren't reasons to think that non-moral mistakes are excuses. And in general non-moral mistakes are not excuses. Borrowing some terms from jurisprudence, mistakes of fact are defences, not excuses; they are reasons to find someone not guilty, rather than reasons to not punish them despite their guilt. And chapters 3 and 4 are long arguments for thinking that premise 2 of this argument is wrong.

The second is an argument from motivation, which we could put as follows.

1.  It is good, or at least blameless, to do *X* because one thinks *X* is the thing to do.
2.  If an action is blameworthy, this blame must be traceable to some stage that led to the production of the action.
3.  So if the belief that *X* was the thing to do is blameless, then so is the performance of *X*.

The long argument that Michael Zimmerman gives for a version of MIE is, I think, a version of an argument from motivation  [@Zimmerman2008 175ff]. And the argument plays a central role in Gideon Rosen's discussion. He describes a character[Bonnie]{acronym-label="Bonnie" acronym-form="singular+short"} who is, as he puts it, an "unreconstructed selfish creep" (77) [Bonnie]{acronym-label="Bonnie" acronym-form="singular+short"} cuts in front of a father waiting in the rain for a cab with his family, for no good reason other than she wanted to get uptown in more of a hurry. It turns out later that [Bonnie]{acronym-label="Bonnie" acronym-form="singular+short"} has been suffering from a virus, and one effect of this virus is that she ceases to view considerations involving others as giving her reasons for action. But it did so, remarkably, in a way that left [Bonnie]{acronym-label="Bonnie" acronym-form="singular+short"} in a relatively coherent state. She reflectively endorses her self-centred behaviour, and dismisses the importance of traditional moral considerations. Indeed, she apparently can hold her own in philosophical argumentation when confronted with the standard arguments against the kind of nihilism or egoism (it isn't exactly clear which) she now espouses. Rosen argues it is reasonable for her to take arguments for conventional morality seriously, but she does that, so to get her act well we will need her to do more.

> But is it reasonable to expect more? Here is [Bonnie]{acronym-label="Bonnie" acronym-form="singular+short"}. She blamelessly thinks that she has most reason to steal the cab. What do you expect her to do? To set that judgment aside? To act on what she blamelessly takes to be the weaker reason? To expect this is to expect her to act unreasonably by her own lights. This is certainly a possibility, but is it fair to expect it or demand it? Is it reasonable to subject an agent to sanctions for failing to exhibit akrasia in this sense? When these questions are raised explicitly, the answers can seem self-evident. No, it is not reasonable to expect a person to do what she blamelessly thinks she has less reason to do. No, it's not fair to subject someone to sanctions for 'pursuing the apparent good' when it is clear that she is blameless for the good's appearing as it does.  [@Rosen2003 79-80]

Given what I've said about moral fetishism, I have to think premise 1 of the motivation argument fails. It is not good to be motivated by the good as such. What is good, or at least what is best, is to be motivated by that which is good. We expect [Bonnie]{acronym-label="Bonnie" acronym-form="singular+short"} to be motivated by good reasons, even if she falsely takes them to be bad reasons. And premise 2 is, as Manuel @Vargas2005 argues, far from obvious. Maybe every blameworthy act is downstream from a move that is blameworthy in isolation, but it isn't obvious why we should assume this.[^33]

[^33]: When Guildernstern says "There must have been a moment at the beginning, where we could have said---no. Somehow we missed it."  [@Stoppard1967 125] he is voicing something like premise 2. And it's not obvious that Guildernstern is right.

Now I should note that there is an exception I noted in chapter 3 to the general rule that it is best to not act on the basis of thin moral beliefs. And that exception provides a possible way to defend something like MIE in a very narrow range of cases. I'll come back to this in the discussion below of Calhoun's view.

The third argument for MIE comes from cases where an agent acts from moral ignorance, and apparently it is intuitive that they are blameless. Many of these cases do not elicit anything like clear intuitions. And in the cases that do elicit relatively clear intuitions, it is a further step to say the correct explanation of that intuition is that the moral ignorance explains the blameworthiness.

For example, consider [JoJo]{acronym-label="JoJo" acronym-form="singular+short"}, as described by Susan @Wolf1987. [JoJo]{acronym-label="JoJo" acronym-form="singular+short"} is the son of Jo, a vicious dictator. Jo rose through the ranks to become dictator in a coup, and we aren't supposed to feel any hesitation in blaming him for his misdeeds. But [JoJo]{acronym-label="JoJo" acronym-form="singular+short"} was born in the palace, and raised to be ruler. He hasn't known any life other than the life of the vicious dictator, and has never been exposed to other moral systems. Many philosophers intuit that when Jo ascends to the throne, and continuous the family business of being vicious dictators, he is less blameworthy than Jo.

But to get to MIE, we need two stronger assumptions, neither of which we can get from raw intuition. One is that [JoJo]{acronym-label="JoJo" acronym-form="singular+short"} is not just less blameworthy than his father, but that he is blameless. The other is that [JoJo]{acronym-label="JoJo" acronym-form="singular+short"} is blameless because he is morally ignorant. I'm going to argue that neither of these extra assumptions is correct. When we return to [JoJo]{acronym-label="JoJo" acronym-form="singular+short"} at the end of the chapter, I will draw on some insightful things that Elinor @Mason2015 says about cases like [JoJo]{acronym-label="JoJo" acronym-form="singular+short"}'s to argue that MIE is the wrong conclusion to draw cases from like his.

## Chapter Plan {#chapterplan}

The argument here is going to be a little more roundabout than in other chapters, so let's have a road-map to see where we're going.

-   In sections 4 and 5, I'll set out some very general features of blame that I'll be taking mostly for granted in the discussion that follows.
-   Sections 6 through 9 will discuss the idea that moral ignorance only excuses if it is connected to action in the right way. I'll argue that most of the ways we might try to make this vague notion of 'connected in the right way' precise lead to implausible theories. The only version of MIE that survives being precisified is very weak.
-   Sections 10 and 11 will discuss two kinds of cases that this weak version of MIE might still cover: wrong actions that are done habitually, and wrong actions by people in very different moral cultures. In each case, I'll argue that there are better explanations than MIE for why blame might be eliminated on reduced in these cases.
-   Finally, I'll return to the picture of blame that results from these discussions, and go over how it handles a number of difficult cases.

## Blame and Desire {#blameanddesire}

The main aim of the chapter is to argue that MIE is false. It posits a necessary connection between (rationally) believing actions have a certain moral property, and actions actually having some similar property. Since I'm in the business of rejecting all such necessary connections, it's my job to argue against it.

I think MIE fails for a fairly systematic reason. It makes beliefs central to whether someone is blameworthy, but blameworthiness is a matter of having the wrong desires. Here I'm following a version of the view defended by @ArpalySchroeder2014. Blameworthy people either desire things that are bad, or fail to (sufficiently) desire things that are good. Actions are blameworthy (or praiseworthy) to the extent that they manifest bad (or good) desires to have. While I'm directly following Arpaly and Schroeder, what I say here owes a lot to the broader tradition on moral responsibility that traces back to @Strawson1962.

One might think that a desire-based view of blame would immediately rule out MIE: it says that beliefs are relevant to blame, but in fact only desires are relevant to blame. And beliefs and desires are distinct existences, so beliefs can't be relevant to blame. But that's too quick. After all, which desires an action manifests is a property of the beliefs of the actor. So it could be that moral beliefs matter because they affect which desires are manifest by an action.

Here's one (implausible) way that moral beliefs could matter to blame. Assume that the good person has one and only one desire: to do the right thing. Then if a person thinks that what they are doing is right, it shows that they are manifesting the one and only desire that a good person has, so they are blameless. That is a way to make MIE compatible with the desire-based view of blame. But it's implausible twice over. For reasons we've discussed already, it's not true that the *only* thing a good person wants is to do what's right. And this view would say that acts of misguided conscience are not just blameless, they are positively praiseworthy, since they manifest the one and only good desire.

We don't need such an implausible view to get something like MIE though, within a broadly Strawsonian view on blame. Even if good people have more than one desire, we might suppose that one of their desires is to do the right thing. Assume someone has some bad desires, and perform an act that manifests those bad desires, but also desires to do the right thing, and this very action also manifests that desire. Then a plausible version of the desire-based view of blame is that their bad action will be less blameworthy than a similar bad action by someone who only has the bad desires. To that extent, the false moral belief will be something that reduces blameworthiness. And if we call anything that reduces blameworthiness an excuse, then the false moral belief will be an excuse. It won't be a full excuse, which is what most defenders of the MIE want, but it will be excusing.

There is another, even more plausible, way that false moral beliefs could be related to blame.[^34] Assume that false moral beliefs are somehow connected to false beliefs about practical reasoning. ('Connected' here is deliberately vague, and the vagueness will matter in what follows.) People who make mistakes in or about practical reasoning tend to manifest different desires than we might have thought they did. And that could turn out to matter.

[^34]: I only realised the importance of these cases in discussions with Claire Field about her work on blame and normative ignorance. I'll return to these cases in section 10.

We can see this with non-moral examples. [Abbott]{acronym-label="Abbott" acronym-form="singular+short"} and [Costello]{acronym-label="Costello" acronym-form="singular+short"} are each offered a deal. If they take the deal, it will gain them \$10 straight away, and then lose \$1 every day for the next 30 days. Both of them take the deal. But they do so for different reasons. [Abbott]{acronym-label="Abbott" acronym-form="singular+short"} has a really steep discount function. He values \$10 now much more than the loss of \$30 over the next month. [Costello]{acronym-label="Costello" acronym-form="singular+short"} is practically irrational; the deal makes him worse off by his own lights, but he does not realise this. I've stipulated that [Abbott]{acronym-label="Abbott" acronym-form="singular+short"} and [Costello]{acronym-label="Costello" acronym-form="singular+short"} value the deal differently, but in practice we can often detect these values without stipulation. Imagine we point out to [Abbott]{acronym-label="Abbott" acronym-form="singular+short"} and [Costello]{acronym-label="Costello" acronym-form="singular+short"} that taking the deal will leave them \$20 worse off at the end of the month. [Abbott]{acronym-label="Abbott" acronym-form="singular+short"} will say, "Who cares? I want the money right now." [Costello]{acronym-label="Costello" acronym-form="singular+short"} will say, "Huh, I hadn't realised that. I wonder if I can back out of the deal." On a desire based view of blame, [Abbott]{acronym-label="Abbott" acronym-form="singular+short"} is to blame for his own misfortune when in a month's time he is \$20 worse off than he might have been. But [Costello]{acronym-label="Costello" acronym-form="singular+short"} is not blameworthy, since his desires are not defective.

In general, people who are practically irrational might be blameless for what seem like wrong acts, because the act does not reflect their underlying desires. This isn't exactly the same thing as saying that normative ignorance excuses, but it is very close. The following two groups are not identical as a matter of conceptual necessity, but they have a huge overlap.

-   People whose actions do not reflect their desires.
-   People who do not know what actions are best given their desires.

Indeed, many people who are in both groups would cease being in the first group as soon as they ceased being in the second. The view I'm going to be defending is that whether someone is in the second group does not directly matter to how blameworthy they are. That is, MIE is false. But whether someone is in the first group matters a lot, and whether someone is in the first group might in practice depend on whether they are in the second group. So normative ignorance will in many real world cases be indirectly relevant to blame.

## Blame, Agents and Time {#blameagentsandtime}

I'm not going to try to present a full theory of blameworthiness, and then derive results about ignorance and blameworthiness from it. But I will record with two important general points about blame that will matter in what follows.

The first is that it is agents, not actions or outcomes, which are the primary subjects of praise and blame. I will still say, and have already said, that agents can be blameworthy for actions. (Peter A. @Graham2012, in the course of offering a plausible general theory of blame, denies even this.) But it is the agent, not the act, that is the focus of blame.

The second point, which has not received sufficient attention in the recent literature, is that blameworthiness is time sensitive. It seems very bizarre to say that a particular action, performed at *t*~1~, is wrong at *t*~2~ but not wrong at *t*~3~. Perhaps that is even contradictory. But it is certainly not contradictory to say that the agent of that action is blameworthy for the action at *t*~2~ but not at *t*~3~. Indeed, such claims are often true, as in the following case.

[Glyn]{acronym-label="Glyn" acronym-form="singular+short"} is a twelve year old boy. He steals [Mehdi]{acronym-label="Mehdi" acronym-form="singular+short"}'s expensive new jacket. [Glyn]{acronym-label="Glyn" acronym-form="singular+short"} does not need a new jacket, he is not suffering from any kind of duress or compulsion, and he knows it is wrong to steal. But he wants the jacket, so he steals it. At the time he steals it, he is blameworthy for the theft.

Fast forward forty years, and [Glyn]{acronym-label="Glyn" acronym-form="singular+short"} is now a middle aged man. He has not gone onto a life of crime. He is no moral saint, but an ordinary mostly moral-law-abiding member of society. It would be wrong to still blame him for the theft. Indeed, it is overdetermined that [Glyn]{acronym-label="Glyn" acronym-form="singular+short"} is no longer blameworthy. Typically, adults are not blameworthy for the wrongs committed by their juvenile selves. And typically, people are not blameworthy for the wrongs they committed in the distant past. We can test this by varying [Glyn]{acronym-label="Glyn" acronym-form="singular+short"}'s case in different ways. If [Glyn]{acronym-label="Glyn" acronym-form="singular+short"} turns into a decent 19 year old, it seems wrong to blame him for the actions of his 12 year old self. And if he steals the jacket at 22, it seems wrong to blame his 52 year old self for the theft.

The law backs up many of these intuitions. Except for cases of severe wrongdoing, we typically give people a clean slate when they become adults. Records of juvenile wrongdoing are sealed, so as to prevent past misdeeds being held against someone. In the UK, this principle is taken further. The *Rehabilitation of Offenders Act 1974* makes it the case that after a certain length of time, even adult convictions for minor to moderately serious offences are *spent*. It can be defamatory to describe someone as a convicted criminal, if their conviction is spent. The law recognises that after a while, people are not responsible for the misdeeds of their earlier selves. More generally, whether someone is blameworthy for an action might change over time.

In some cases, I suspect this change of status can happen rather quickly. Change [Glyn]{acronym-label="Glyn" acronym-form="singular+short"}'s case so that a few weeks later, he has a change of heart. He sheepishly returns the jacket to [Mehdi]{acronym-label="Mehdi" acronym-form="singular+short"}, and apologises. And, crucially, [Mehdi]{acronym-label="Mehdi" acronym-form="singular+short"} accepts the apology. Now [Glyn]{acronym-label="Glyn" acronym-form="singular+short"} is no longer blameworthy for the theft. He was blameworthy, but in a case where the misdeed was not too excessive, where only one person was harmed, and that person has accepted an apology, the period of moral responsibility has passed. [Glyn]{acronym-label="Glyn" acronym-form="singular+short"} was blameworthy for the theft, but he is no longer.

What's crucial is that blameworthiness can be time limited, not anything in particular I've said about apologies, or even about juvenile wrongdoing. We should reject the 'branding' model of blameworthiness, that once a person is blameworthy for something, they are branded with a moral cross, and must carry this mark for eternity. Rather, blameworthiness can ebb and, occasionally, flow.

This matters for one of the arguments Rosen gives concerning [Bonnie]{acronym-label="Bonnie" acronym-form="singular+short"}. [Bonnie]{acronym-label="Bonnie" acronym-form="singular+short"} is an "unreconstructed selfish creep"  [@Rosen2003 77], who nevertheless is internally coherent. So far, so bad. [Bonnie]{acronym-label="Bonnie" acronym-form="singular+short"} seems like an appalling person, even if it is rather sad that she has become an appalling person. But a few weeks later, the virus wears off, and she regrets having the views that she previously had, and of course acting on them. Is she now blameworthy for the terrible things she did while suffering the virus?

I think one could go either way on this. But it seems that question is separate from the question of whether she was then blameworthy for what she did. If you think [Bonnie]{acronym-label="Bonnie" acronym-form="singular+short"} should not now be blamed for what she did while suffering the virus, because you think that in some sense she isn't the same person as the one who committed those misdeeds, then your willingness to let [Bonnie]{acronym-label="Bonnie" acronym-form="singular+short"} off the hook now isn't even evidence that what she did wasn't then blameworthy.

Rosen actually notes that time might matter to [Bonnie]{acronym-label="Bonnie" acronym-form="singular+short"}'s case, but dismisses this consideration too quickly. He writes,

> You may think that blame is no longer appropriate, not because the act was not blameworthy when it was committed, but rather because time has passed and it is time for you to let it go. The judgment that forgiveness is now mandatory is not the judgment that it was unfair to blame [Bonnie]{acronym-label="Bonnie" acronym-form="singular+short"} in the first place. It is the judgment that further blame would be unfair given the severity of the transgression. Since we want to focus on whether the act was blameworthy when committed, we need to set this thought aside. So let's stipulate that the offence was recent enough and serious enough that if [Bonnie]{acronym-label="Bonnie" acronym-form="singular+short"} was indeed responsible, you are not yet required to forgive her.  [@Rosen2003 81]

But the last point is exactly what can't be stipulated. It isn't just passage of time or forgiveness of victims that makes blameworthiness go away. Sufficient change of character can too. That's why it doesn't take too long for juvenile wrongdoing to be morally expunged. Commit the misdeed at the right time, and it might be legally expunged in a few days. Morality doesn't use the same hard cutoffs the law uses, but the principle is the same. [Bonnie]{acronym-label="Bonnie" acronym-form="singular+short"}'s change of character is much quicker, but not completely unrealistic. (Compare the case discussed by @BurnsSwedlow2003.) And we should have the same verdict; her actions were blameworthy, but she is no longer to blame for them.

## Acting In Ignorance is No Excuse {#actinginignoranceisnoexcuse}

The next three sections are on clause 3 of MIE. The clause is ambiguous, and on the most natural interpretations, MIE is clearly false. So we'll look at whether there is any interpretation that makes MIE plausibly true. It will take a while to cover the possibilities, but at the end the only version of MIE left viable will be one that is very weak.

In the *Nichomachean Ethics*, Aristotle distinguishes between acting in ignorance of the wrongness of one's actions, and acting from that ignorance. Getting clear on just what this means is not easy. But doing so is crucial to finding a version of MIE that is plausible.

Consider first an extremely contented carnivore. We'll assume she's in a world where meat-eating is wrong. And we'll assume she is ignorant of that fact, as she chews away happily on a hamburger. But this ignorance plays no role in bringing about her eating. She certainly does not think to herself "It's a good thing this is permissible," as she eats away. She is not disposed to order different foods on learning that meat-eating is wrong. She would not eat differently were she to have different views about meat-eating. She regards the coincidence between her wants and what is, by her lights, morally permissible as a happy but irrelevant accident. She eats a hamburger because she wants a hamburger, and that settles things as far as she is concerned.

The ignorance that our carnivore shows does not excuse her. It is true that she is ignorant of the wrongness of her action. But she doesn't eat because she is so ignorant. So it does not affect the moral status of her action. The general point is that moral ignorance that merely accompanies a wrongful act doesn't excuse the act. The ignorance must in some way make a difference to the act.

There are two natural ways to think that moral mistakes could be relevant to actions in ways that are excusing. First, the action might be counterfactually dependent on the mistake. If the agent wasn't making the mistake, they wouldn't have performed the action. Second, the action might be motivated by the mistake. That is, the reasons the agent had for the action might have included the mistaken belief. In many cases, these two will go together. But this actually makes things tricky for the idea that action from ignorance can excuse. The next subsection will show that adding a condition that the action was counterfactually dependent on the mistake does not provide a sufficient condition for blamelessness. And the following subsection will show that if ignorance ever does excuse, it isn't necessary that the ignorance is motivating. Indeed, it is sometimes necessary that the ignorance is not motivating. The space of cases in which ignorance excuses is, if not empty, exceedingly small.

## Against Counterfactual Interpretations of Acting From Ignorance {#againstcounterfactualinterpretationsofactingfromignorance}

The mere presence of a blameless moral mistake does not excuse. It is a little more plausible to think that actions that are in some way traceable to a blameless moral mistake are excusable. Here's a version of MIE that makes that idea rigorous.

> For any agent S, proposition *p* and action *X*, if
>
> 1.  S blamelessly believes *p*; and
> 2.  *p* is false; and
> 3.  If S had not believed *p*, S would not have done *X*, then
>
> S is not blameworthy for doing *X*, since her ignorance of *X* is an excuse.

This proposal won't work for a reason Gideon Rosen notes  [@Rosen2003 63n4]. [Pasco]{acronym-label="Pasco" acronym-form="singular+short"} has read online that his football team has lost. The website he reads this on is, as he knows, extremely reliable. But the website is wrong on this occasion. Since [Pasco]{acronym-label="Pasco" acronym-form="singular+short"} knows the website is generally reliable, he is blameless for believing his team lost. [Pasco]{acronym-label="Pasco" acronym-form="singular+short"} reacts to the report of the loss by throwing a brick through his neighbour's window. He wouldn't have done this had his team won. So all three conditions are satisfied, and yet [Pasco]{acronym-label="Pasco" acronym-form="singular+short"}'s ignorance of the result of the football match does not provide an excuse for the brick-throwing.

We need to at least supplement the simple theory. Rosen suggests the following fourth condition.

> If *p* had been true, then S's action would not have been blameworthy.  [@Rosen2003 63n4]

I'm not sure why Rosen uses 'blameworthy' here, rather than 'wrong'. It seems unintuitive to say that a false belief that would have offered a mere excuse if true could actually furnish an excuse. But I won't press the point, since it doesn't matter for the larger debate. Nothing like this condition can work. Indeed, it seems very unlikely that we can hold onto the idea that actions done from moral ignorance excuse, while understanding the concept of acting from moral ignorance in terms of conjunctions of counterfactuals.

To see this, add another assumption to the example: [Pasco]{acronym-label="Pasco" acronym-form="singular+short"} is a moral nihilist. That is, he thinks that nothing is good or bad, right or wrong, blameworthy or praiseworthy. This doesn't affect what he does very much (unless you're unfortunate enough to be stuck in a philosophical discussion with him). It certainly doesn't affect whether he reacts to bad football news by quietly cursing that overpaid forward, or by tossing bricks around. And assume that this belief in moral nihilism is blameless; it is a natural enough reaction to the strange diet of philosophical reading he has had.

Now let *p* be the proposition *Pasco's football team lost, and moral nihilism is true*. [Pasco]{acronym-label="Pasco" acronym-form="singular+short"} believes that. It is false; doubly so since both conjuncts are false. If he did not believe *p*, he would have not thrown the brick through his neighbour's window. I'm making an extra assumption here, but it's a plausible addition to the case. The assumption is that possible worlds in which either the website reports the results correctly, or [Pasco]{acronym-label="Pasco" acronym-form="singular+short"} reads some other website to get the football score, are much more like reality than the world where he sees the error of his nihilist thinking. That is, if he were to see that *p* is false, it would be because he saw the first conjunct is false, not because he saw the second conjunct is false. Finally, if *p* were true, what [Pasco]{acronym-label="Pasco" acronym-form="singular+short"} did would not be bad, or wrong, or blameworthy.

The last point is a little delicate, in a way that I don't think helps Rosen's case. Moral nihilism is necessarily false. False global moral theories are, typically, necessarily false. So evaluating counterfactuals about what would happen were one of them true require thinking about counterfactuals with necessarily false antecedents. Such counterfactuals are, to put it mildly, not well behaved. I'm a little inclined to think, following @Lewis1973a that they are all trivially true.[^35] And I suspect this will make trouble for any attempt to spell out the idea of acting from ignorance in the way Rosen suggests. But set that aside, because the issues are very hard, and because we don't need to address them. Any theory of counterfactuals should say that it is true that if moral nihilism were true, then [Pasco]{acronym-label="Pasco" acronym-form="singular+short"}'s action would not be bad, or wrong, or blameworthy. And that's all we need to make trouble for Rosen's view.

[^35]: But wait! Haven't I been talking all book about examples in which some things are true that are, in fact, necessarily false? Yes, I have, but there's no contradiction here. I think, following @IchikawaJarvis2009 that we should understand philosophical examples as little fictions. And, contra @Lewis1978b, I think there are good reasons to not understand truth in fiction in terms of counterfactuals. It would take us too far afield to go into these reasons, but see @Gendler2000 for discussion of some of the relevant considerations. If I'm right about both of those claims, then there are non--trivial truths about about what is true in a necessarily false thought experiment, but not about what would happen if a necessary falsehood were true.

So on Rosen's view, [Pasco]{acronym-label="Pasco" acronym-form="singular+short"}'s false belief in the conjunction *My football team lost and moral nihilism is true* excuses the brick throwing. And that's implausible. To see how implausible, note that the belief on its own that moral nihilism is true is not exculpatory. Imagine first a person just like [Pasco]{acronym-label="Pasco" acronym-form="singular+short"}, except that this person planned to throw the brick either in anger or celebration, whether the team lost or won. He shares [Pasco]{acronym-label="Pasco" acronym-form="singular+short"}'s false belief, but he doesn't have an excuse. Next consider a person who is like [Pasco]{acronym-label="Pasco" acronym-form="singular+short"} except he has correct moral beliefs, and knows he is acting immorally when he throws the brick. He too has no excuse. It is only the strange combination of views and dispositions that [Pasco]{acronym-label="Pasco" acronym-form="singular+short"} has that are excusing. And that's very implausible, even if one thinks that false moral beliefs could in principle excuse.

One possible move that could be made here is to restrict the quantifier in our principle about excuse. Perhaps we should say that a false belief is excusing only if it is a false belief in a proposition about morality, and satisfies these conditions. But such a move would be undermotivated twice over. For one thing, a core motivation for MIE is the argument from symmetry, and making this move is to insist on a huge asymmetry. For another thing, we need some special story about why such a restricted theory should be true, and the literature is not exactly forthcoming with such stories. Indeed, if we had such a restriction in place, it isn't clear we would even need Rosen's fourth condition. But, as Rosen acknowledged, we do need such a condition to get a plausible thesis about mistake and excuse.

## Against Motivational Interpretations of Acting From Ignorance {#againstmotivationalinterpretationsofactingfromignorance}

Still, there is a natural enough fix to MIE. [Pasco]{acronym-label="Pasco" acronym-form="singular+short"}'s false moral belief, either on its own or in conjunction with false factual beliefs, doesn't excuse because it doesn't play the right kind of role in his deliberations. For a false belief to excuse, it isn't sufficient for an agent's actions to be counterfactually sensitive to the presence of the belief. Rather, the belief must play some kind of affirmative role in the agent's motivations, not just the kind of regulative role that is implied by counterfactuals like the one Rosen uses. The action must not just be sensitive to the presence of the belief, but in some way brought about by the belief.

That's intuitively why [Pasco]{acronym-label="Pasco" acronym-form="singular+short"}'s false belief in the conjunction *p* is not exculpatory. Although he would not have acted had he not believed *p*, his belief that *p* doesn't play any role in bringing about the wrong action. So adding a requirement that the ignorance be motivating avoids that counterexample. But it introduces new problems. I'm going to discuss two counterexamples to the new version of MIE.

First consider [Gusto]{acronym-label="Gusto" acronym-form="singular+short"}. [Gusto]{acronym-label="Gusto" acronym-form="singular+short"} normally has little interest in morality. But he is interested in girls, and right now he is interested in [Irene]{acronym-label="Irene" acronym-form="singular+short"}. She says that she will only date him if he does nothing immoral for a week. So for this reason, and this reason only, he develops a keen interest in morality. Sadly, he gets some things wrong. So even though he thinks it is morally acceptable to break a particular promise he made to [Oleg]{acronym-label="Oleg" acronym-form="singular+short"} in the service of a greater good, it is not, and he acts immorally when he breaks the promise. [Oleg]{acronym-label="Oleg" acronym-form="singular+short"} can blame him for breaking the promise, despite [Gusto]{acronym-label="Gusto" acronym-form="singular+short"}'s instrumental desire to act morally. It is very strange to think that his promise breaking ceases to be blameworthy merely because it is driven by his desire to date [Irene]{acronym-label="Irene" acronym-form="singular+short"}.

For another example, consider [Sebastian]{acronym-label="Sebastian" acronym-form="singular+short"} and [Belle]{acronym-label="Belle" acronym-form="singular+short"} who are, blamelessly, committed consequentialists. That is, they do the actions they think will have the best consequences, understood in a completely neutral manner. They are also siblings. But there is a difference between them. When faced with any choice of any importance whatsoever, [Sebastian]{acronym-label="Sebastian" acronym-form="singular+short"} will first think to himself, "What will produce the most utility?". Having convinced himself that a particular action is utility maximizing, he will perform that action just because it is utility maximizing. [Belle]{acronym-label="Belle" acronym-form="singular+short"} has simply adjusted her values and dispositions in such a way that she sees actions in terms of their utility, and is directly motivated to do the thing that is in fact utility maximising.

One day, their mother is sick in hospital. It isn't life threatening, but it is a bit scary, and she would be helped by a visit from her children. But neither of them visit. They are both volunteering at a soup kitchen, and don't want to leave their posts. [Sebastian]{acronym-label="Sebastian" acronym-form="singular+short"} deliberates about what to do. He thinks "If I leave, some people will go hungry. That will produce more disutility than my mother's sadness. And it is bad to produce more disutility, and I don't want to do what is bad. So I'll stay here." [Belle]{acronym-label="Belle" acronym-form="singular+short"} simply is moved by the plight of the hungry in front of her, and stays without deliberating.

Assume, for the sake of the argument, that the beliefs [Sebastian]{acronym-label="Sebastian" acronym-form="singular+short"} and [Belle]{acronym-label="Belle" acronym-form="singular+short"} have are blameless. And assume that the impersonal consequentialism they believe is wrong - they should go to visit their sick mother. Finally, note that they would not have ignored their mother's needs had they not had their false belief in consequentialism. As Rosen's proposal stands, both of them are blameless for their action, since their false belief in consequentialism excuses. But Rosen's proposal is false, as the example of [Pasco]{acronym-label="Pasco" acronym-form="singular+short"} shows. And the natural way to fix it puts a gap between [Sebastian]{acronym-label="Sebastian" acronym-form="singular+short"} and [Belle]{acronym-label="Belle" acronym-form="singular+short"}. Since [Sebastian]{acronym-label="Sebastian" acronym-form="singular+short"}'s false belief in consequentialism does motivate his decision to stay, but [Belle]{acronym-label="Belle" acronym-form="singular+short"}'s false belief does not motivate her decision to stay, [Sebastian]{acronym-label="Sebastian" acronym-form="singular+short"} has an excuse but [Belle]{acronym-label="Belle" acronym-form="singular+short"} does not.

This is the wrong way around. [Sebastian]{acronym-label="Sebastian" acronym-form="singular+short"} is worse than [Belle]{acronym-label="Belle" acronym-form="singular+short"}. The kind of hyper-moralised thinking that [Sebastian]{acronym-label="Sebastian" acronym-form="singular+short"} engages in is exactly the kind of 'one thought too many' thinking that Bernard @Williams1981 accuses consequentialists of. I think, following @Railton1984, that Williams's complaint against consequentialism misses the mark. [Belle]{acronym-label="Belle" acronym-form="singular+short"} is a perfectly good consequentialist, but can't be accused of having too many thoughts. But I do think Williams is right that having one thought too many is a bad thing,. And we should not reward [Sebastian]{acronym-label="Sebastian" acronym-form="singular+short"} for having one thought too many by excusing his lack of filial piety. Even if you think Williams's idea in general is too strong, it seems extremely appropriate here. By pausing to deliberate, and check for his own moral rectitude, [Sebastian]{acronym-label="Sebastian" acronym-form="singular+short"} helps nobody. Deliberation takes time, and it is time he could have spent helping others. Indeed, [Belle]{acronym-label="Belle" acronym-form="singular+short"} does spend that time helping others. It seems extremely odd to say that she is blameworthy because she kept on serving food rather than stopping for a bit of a think then, quite predictably, gone on serving the food.

Perhaps we can avoid both kinds of counterexamples just described if we modify the idea that false moral belief can excuse even further. For a false moral belief to excuse it must:

-   Be blamelessly held; and
-   Be relied on in action guidance; and
-   Be blamelessly relied on in action guidance.

Note that I say 'action guidance' not 'deliberation' here, because I take it we want to say that someone can be guided by their beliefs without using them in deliberation. When I descend from a balcony by the stairs rather than jumping over the railing, I'm guided by my belief that jumping over the railing will result in injury, even if I don't deliberate using that belief. Typically, I don't deliberate at all before descending via stairs rather than via jumping, so I don't use any beliefs in deliberation. Now given what we said about [Pasco]{acronym-label="Pasco" acronym-form="singular+short"}, we'll need some notion of action guidance that is stronger than counterfactual dependence, and that will be no small challenge. I'll return to that problem in the next section, because first I need to note some points about the restriction to reliance that is blameless.

First, this restriction gives us at least a chance of getting the cases of [Belle]{acronym-label="Belle" acronym-form="singular+short"} and [Gusto]{acronym-label="Gusto" acronym-form="singular+short"} right. A philosopher who thinks that false moral beliefs can excuse should, I suspect, say that [Belle]{acronym-label="Belle" acronym-form="singular+short"} blamelessly relies on her consequentialism. She isn't directly motivated by it; indeed it feels rather forced to say she is motivated by it at all. She's motivated by the needs of her clients at the soup kitchen. But she relies, in some sense, on consequentialism. On the other hand, it is plausible that [Gusto]{acronym-label="Gusto" acronym-form="singular+short"} doesn't get off the hook so easily. It is, perhaps, blameworthy to have a merely instrumental motivation to act morally. So while [Gusto]{acronym-label="Gusto" acronym-form="singular+short"}'s false moral beliefs may be blamelessly held, and may be relied on in action, they are not blamelessly relied on in action.

Second, it is a commonplace that blameworthy acts have to be traceable to something blameworthy. Indeed, something like this is a key premise in an important argument for MIE. (Though recall that I expressed some scepticism about that argument.) Now note that someone who did *X* being motivated by *p*, where *p* was both a false belief blamelessly held, and a completely terrible reason to *X*, would still be blameworthy. And a natural story about why that's true is that relying on an irrelevant consideration when deliberating about whether to do something wrong is blameworthy.

But once we remember Williams's point about too many thoughts, we should see that this is a very tight restriction. In a lot of cases, it is wrong to directly bring considerations of the morality of the action into one's deliberation. Rather, actions should be guided by the facts in virtue of which the action is right or wrong. A false belief about morality should generally be behaviourally inert, and so is not clear it can ever be blamelessly relied upon.

## Adopting a Decision Procedure and Acting on It {#adoptingadecisionprocedureandactingonit}

But, says the objector, it is not always wrong to think about right and wrong and use this to guide one's actions. Indeed, this is what one should do when faced with novel, hard cases. The objector I'm imagining here is making a point similar to something Sigrun @Svavarsdottir1999 says in response to Michael @Smith1994. Smith argued that good agents would never be motivated by right and wrong as such, but things that made actions right and wrong. Svavarsdóttir argued, in effect, that this should hold only in equilibrium. (See, for instance, her example of Mike on page 209. I also discussed this example in section 3.5, making a somewhat related point.) When an agent first reaches a momentous moral decision, it is fine that they are moved to act by it. In the long run, they should be able to be moved by the forces behind the moral truth. That is, in the long run they should reach an equilibrium between their moral beliefs and their motivations; things they believe to be good should become directly motivating. But it is too much to require one's motivations to turn on a dime, the instant belief changes, especially if the decision is one where there are weighty interests on either side of the scale.

This doesn't make any trouble for the [Sebastian]{acronym-label="Sebastian" acronym-form="singular+short"} and [Belle]{acronym-label="Belle" acronym-form="singular+short"} case from the previous section, for we can easily add to the case that they have been consequentialists for long enough that they should have by now reached this kind of equilibrium. But it does mean that there could be some cases where someone actually is moved by a moral belief, and is not thereby blameworthy. It is easiest to see that happening in novel cases where there is a lot at stake, morally speaking. In some of these cases, we might think, virtue requires both careful moral deliberation, and perhaps even acting on the result of that deliberation in advance of one's motives lining up with one's resulting view of the good.

But it turns out there is a distinct problem these cases pose for the view that moral ignorance is exculpatory. The problem is one raised by Alex @Guerrero2007, though I'm going to put his point in a slightly different way. The worry is that defenders of the view that moral ignorance excuses haven't been sensitive enough to time. If any kind of moral mistake matters, it is a mistake at the time of action. But it is all too easy, when thinking about cases, to focus on mistakes at the time of belief formation. If there can be cases where a belief is blamelessly formed, but the persistence of that belief is blameworthy, these will come apart. And that's just what happens, Guerrero argues, in some of the cases that we've just said looked most promising for the view that moral ignorance excuses.

Consider the example, used by both Rosen and Guerrero, of the ancient slaveowner. Rosen says that such people were often blamelessly wrong about the morality of slaveowning. They were blameless because they simply absorbed the prevailing morality of the day. No one around them questioned whether slaveowning was right or wrong, so they were under no obligation to do so either.

But, says Guerrero, look at things from the slaveowner's perspective. He sees families being torn apart. He sees people being cast into chains and thrown into dungeons. When faced with such appalling cruelty, it is callous in the extreme to not wonder for a moment whether this is all an acceptable way to treat people. Perhaps it is blameless to simply absorb moral standards in childhood the way one absorbs a language. But retaining those beliefs, not subjecting them to question when faced with the misery one sees every day in the institution of slavery, is a very different matter. (In general, slaveowning is a pretty terrible case for the proponents of the view that ignorance is exculpatory, as argued by by Michelle @MoodyAdams1994.)

Guerrero puts forward these considerations in service of what he calls 'moral contextualism'. I agree with his reasoning, and his conclusion, but not the name he gives to the view. What he defends isn't analogous to the epistemic contextualism of @Cohen1986, @DeRose1995 and @Lewis1996b, but to the interest-relative invariantism of @Stanley2005, and @FantlMcGrath2009. The closest epistemological equivalents to his view came after his paper, in the theories developed by @Ganson2008 and @Weatherson2012 that make belief relative to the agent's interests, stakes and deliberations.

When an agent is abstractly deliberating the morality of slavery, or even mindlessly absorbing the prevailing wisdom, the stakes are not so high. But when they head to the auction block, or commission a slave-catching party, the stakes are about as high as can be. Taking a belief formed in such a low-stakes setting, and acting on it without further consideration in a high-stakes setting, is blameworthy. Not reconsidering the belief in light of the change in stakes is itself blameworthy. So even if the formation of the belief that slavery is permissible is blameless, the retention of it through the course of deciding to acquire and retain slaves, need not be.

I've set up Guerrero's argument in terms of interest-relative theories of belief. But his conclusion need not rest on anything quite so controversial. @SchroederRoss2014 object to these interest-relative theories of belief. One key problem they raise is that such theories make change of belief without change of evidence too easy. Ross and Schroeder propose instead that belief should be constituted by defeasible dispositions to use propositions in inquiry. In high-stakes settings, we retain the belief, but the disposition to use the proposition in inquiry is defeated. It should be clear this is no help to the proponent of the view that moral ignorance excuses. On Ross and Schroeder's view, the retention of the belief that slaveowning is permissible is not blameworthy. Indeed, it may be wrong to change that belief on the basis of familiar evidence. But when one is actually deciding to enslave other people, one should lose the disposition to act on the belief. Just having the belief is no guarantee that one can, or should, use it. And in such a high stakes case, one should not.

So we have, after a long detour, an answer to some of the rhetorical questions Rosen posed earlier. [Bonnie]{acronym-label="Bonnie" acronym-form="singular+short"} believes that she has most reason to steal the cab; what do we expect her to do? On the Ganson-Weatherson view, we expect her to lose the belief in light of the stakes. On the Ross and Schroeder view, we expect her to lose the disposition to act on the belief in light of the stakes. Either way, there's no excuse for simply harming others on the basis of a prior belief that one would be blameless in so doing.

## Calhoun on Blame and Blameworthiness {#calhounonblameandblameworthiness}

The considerations raised so far suggest that there will be very few cases of wrongdoing that are excused for the reasons that Rosen and Zimmerman raise. The wrongdoing must be counterfactually sensitive to the mistaken belief, and be motivated, or at least guided, by the mistaken belief, and both of these things must be blameless, and the belief itself, both in formation and retention, must be blameless, along with the use of that belief in deliberation. And it turns out these exceptions to the excuse condition are complementary, so between them they cover a vast range of cases. Indeed, at this stage it would be reasonable to speculate that there are no cases at all that satisfy all of these constraints.

But while the constraints are tight, there are some interesting cases that might comply with all of them. These are the cases that are at the centre of the classic treatment of normative ignorance, Cheshire Calhoun's "Responsibility and Reproach". Calhoun's position is more complex than most of the contemporary views, and that complexity reflects a sensitivity to where the really tricky cases are.

Calhoun thinks that blameless ignorance can excuse. But she also thinks it is hard to be blamelessly ignorant of the wrongfulness of your actions when the society you're in knows they are wrong. Blameless ignorance will, in almost all cases, require social ignorance. (This theme is echoed in more recent work by Miranda @Fricker2010.) But in cases of social ignorance, if we want to bring about social change, we may have no alternative but to blame wrongdoers who we think, when engaged in philosophical reflection, are blameless for their wrongdoing. I'm not going to engage with that last point, as interesting as it is, save to note that it might go some way to assuaging the intuitions of those who find the idea that ignorance can excuse highly counter-intuitive.

Following Calhoun, I'll spend some time on cases that are relevant to the way that structures of sexist oppression are maintained by actions that are hardly oppressive in themselves. These acts are thoughtless, but on their own they are almost harmless. The problem, of course, is that these actions are not done on their own. There are a lot of sexist actions that are much worse than thoughtless, but we'll set those aside for now. So don't focus for now on the pimps and the pornographers, or even on the fathers who go out of their way to provide more for their sons than their daughters. Instead focus on casual, everyday sexism of ordinary men in sexist societies. ('Microaggressions' in current terminology.) Calhoun certainly wants to say that the things these ordinary men do are wrong. Indeed, they are collectively extremely wrong, as they collectively maintain a structure of oppression. But, she says, the ordinary men involved are not blameworthy for their misdeeds. There are three grounds for that claim in her paper.

First, blaming everyone would make us massively revise our views of the virtue of many people around us.

> If we assume, as we often do, that only morally flawed individuals could act oppressively, the we will have to conclude that the number of morally flawed individuals is more vast than we had dreamed and includes individuals whom we would otherwise rank high on scales of moral virtue and goodwill. The oddity of this conclusion forces serious questions about the possibility of morally unflawed individuals committing serious wrongdoing.  [@Calhoun1989 389]

This conclusion shouldn't strike us as odd. The world is full of people who have good features alongside serious character flaws. Indeed, it is common in psychological research and in classic literature and in history to see basically good people easily led down a path of moral corruption. (Robespierre was one of the most morally decent people in the French Revolution until he wasn't.) If a theory implied that basically half the population fell under the description *largely good but with a big moral flaw* I wouldn't see that as a fatal flaw in the theory.

In the case of casual sexism, the argument that we couldn't conclude that everyone is flawed seems particularly strange.Let's say we don't want to blame the ordinary man for the part he plays in oppression by everyday acts like using demeaning terms like 'girls' to refer to women. Still, most of these ordinary men provided considerably more resources for their sons than their daughters. And of those that did not, most were 'off the hook' solely because they didn't have both sons and daughters. And that unfair distribution, or at least disposition to distribute unfairly, isn't the kind of individually minor wrong that Calhoun wants to excuse. It isn't that surprising to think that most men in sexist societies are at least somewhat blameworthy.

Second, Calhoun notes that we should not simply assume that causing harm is "the same as being responsible for the harm"  [@Calhoun1989 392]. This is surely right - and I want to come back to it below. It is important that we respect the conceptual difference between wrong and blameworthy action, and return to that distinction.

But the biggest consideration, one that runs through Calhoun's paper, is that there are cases where the wrongdoer has no reason to reconsider their false moral belief. Calhoun shows that many false moral beliefs are not be like that. If society disagrees with one's false moral beliefs, then one has frequent occasion to reconsider the belief. So the false moral beliefs one has no reason to reconsider will only be one's shared by the community. For many other false moral beliefs, the thing that makes actions wrong will be a reason to reconsider the belief at the moment of action. (Guerrero's response to Rosen turns on a similar point.) But maybe that isn't true for all false moral beliefs. Maybe it is only true if the wrongness rises above a certain threshold. Not every potential harm is a ground for reconsidering one's views.

Let's consider a very different kind of example to Calhoun's in order to see the possibility I have in mind. Assume that [Inka]{acronym-label="Inka" acronym-form="singular+short"} lives in a city with a busy underground train system. It is possible to delay a train's departure from a station for a few seconds by standing in a doorway preventing a train leaving. [Inka]{acronym-label="Inka" acronym-form="singular+short"} believes, as do most people around her, that it is acceptable to so delay a train in order to let a friend running for the train catch it. Indeed, this is widely taken to be a requirement of friendship. It is also a false belief. Costing the other 600 people on the train 10 seconds each of extra travel time is a very bad thing to do in order to save one friend the five minutes they would have to wait for the next train. It is, in [Inka]{acronym-label="Inka" acronym-form="singular+short"}'s world, as morally bad as trapping one person in a train for 100 minutes.[^36]

[^36]: I think holding a train for a friend to catch it is also wrong in *our* world, for just this reason. But the argument doesn't turn on this assumption.

Now [Inka]{acronym-label="Inka" acronym-form="singular+short"} is in a position where she can help a friend catch a train by blocking the doorway, and letting her friend run the last few steps to catch it. She does just this. It's not true that what [Inka]{acronym-label="Inka" acronym-form="singular+short"} should have done instead was stop and think about her action. Any deliberation and the moment for action will have passed. Even if [Inka]{acronym-label="Inka" acronym-form="singular+short"} did have time to contemplate action, it isn't clear she has any reason to do so. There is no person who she is harming so severely that this harm makes it compulsory for her to reconsider her actions. After all, each of them is only being delayed in the train for a few seconds more, and people get delayed in subways for seconds all the time. And [Inka]{acronym-label="Inka" acronym-form="singular+short"} presumably thinks that small delays like this are of no moral significance.

Putting these points together, we can sketch a way in which moral ignorance might excuse. Assume that all of the following conditions are met.

1.  S is, as a matter of policy, disposed to do *X* in circumstances C.
2.  S has this policy for the same reasons that she has the false moral belief that doing *X* in circumstances C is permissible. This means that she would (eventually) lose the policy if she lost the belief, and that the adoption and maintenance of the policy is part of a general disposition to adopt policies she regards as permissible.
3.  It is commonly held in S's community that it is permissible to do *X* in circumstances C.
4.  S is in circumstances C.
5.  If S does *X* right now, no one will be greatly harmed.
6.  S has no time or reason to reconsider her policy of doing *X* in C before it becomes time to act.
7.  S does *X*.

None of the arguments I've offered so far refute the idea that S is less blameworthy in these cases than is a typical person who does *X*. Even without having necessary and sufficient conditions for 'acting from ignorance', it is plausible that S acts from ignorance and not just in ignorance. And it's not true that the situation S finds herself in calls for reflection and deliberation rather than action. So nothing I've said so far rules out S's actions being excused. I'm going to defend three claims about this case.

-   We need to know more about S to know how much her situation excuses her behaviour.
-   Even when S has a partial excuse, it isn't the fact that she is morally ignorant that excuses. But the moral ignorance is relevant; the reasons that she is morally ignorant will typically be the reasons that she is excused.
-   In any case, there are no such things as full excuses for wrong action, so S couldn't have a full excuse for wrong action.

I'm going to defend the first and second claims in this section, and the third claim at the end of the chapter. The defences will turn on considerations arising from cases of practical irrationality. [^37]

[^37]: As I mentioned above when introducing the cases of [Abbott]{acronym-label="Abbott" acronym-form="singular+short"} and [Costello]{acronym-label="Costello" acronym-form="singular+short"}, I only saw the importance of these cases in discussions with Claire Field. Her work in progress has a different, and interesting, take on the cases I'm about to describe.

Imagine that you have the following views. You think that the conclusions of "Famine, Affluence and Morality"  [@SingerFAM] are basically correct. And you're a Strawsonian about moral responsibility. And you know of someone, call him [Gloucester]{acronym-label="Gloucester" acronym-form="singular+short"}, who doesn't give a lot to charity. But you also know that [Gloucester]{acronym-label="Gloucester" acronym-form="singular+short"} is disposed to massively increase his charitable giving were he to simply be presented with Singer's drowning child argument. If he were presented with that argument, he would have an "A Ha!" moment, and see that he was required to give much more to charity. What should you say about [Gloucester]{acronym-label="Gloucester" acronym-form="singular+short"}'s responsibility for his current insufficient charitable givng?

I think you should say that [Gloucester]{acronym-label="Gloucester" acronym-form="singular+short"} is largely blameless. He would be completely blameless after he reads Singer and starts donating. But reading the paper does not change his fundamental desires. And the Strawsonian picture is that these fundamental desires are what makes him praiseworthy or blameworthy. So he isn't particularly blameworthy now.

Does this mean [Gloucester]{acronym-label="Gloucester" acronym-form="singular+short"} is a case where moral ignorance is excusing? I don't think it does. [Gloucester]{acronym-label="Gloucester" acronym-form="singular+short"} is practically irrational. Right now, before reading Singer, he values charitable donation over spending money on himself. But he doesn't act on those values. He also doesn't realise that those are his values. And both the failure to act and the failure to realise have a common cause - his practical irrationality.

Now [Inka]{acronym-label="Inka" acronym-form="singular+short"} might be just like [Gloucester]{acronym-label="Gloucester" acronym-form="singular+short"}. It might be that as soon as you present her the simple argument for why holding the train doors is wrong, she has an "A ha!" moment, and sees that what she is doing is wrong. That is, she sees that by her own lights, it was better to not hold the train door. And what matters is not that she sees this, but that it was true all along that she desires implied that train doors should not be held in these cases. She presumably also had other desires, inconsistent with those, that implied that the doors should be held open. And she is somewhat blameworthy for having those desires; but the existence of the correct desires mitigates her blameworthiness.

But [Inka]{acronym-label="Inka" acronym-form="singular+short"} might be different. It might be that she needs to change her desires to change her actions. She might be like someone who gives more to charity after visually seeing the suffering of the impoverished. Such people, I think, change their desires upon seeing the suffering. And they are blameworthy for not doing more in the first place. (At least if the conclusion of @SingerFAM is correct, and I'm not assuming it is for anything more than the duration of this argument.)

So that's my overall conclusion about the people who commit minor wrongs out of habit, while not believing they are wrong, and not having social pressure to change. Some of these people all along had desires that the wrongs not be committed. They were practically irrational in committing the wrongs. They have a partial excuse. They are also morally ignorant. But the moral ignorance does not explain the excuse. Rather something else, their practical irrationality, explains both the excuse and the ignorance. I don't want to take a stand on whether this is rejecting MIE, since it says ignorance never makes one have an excuse, or endorsing a weak version of MIE, since it says that ignorance goes along with having an excuse in some cases. That would require more careful parsing of the words of MIE-defenders than seems useful to do here.

Instead I'll turn to one other aspect of Calhoun's examples. [Inka]{acronym-label="Inka" acronym-form="singular+short"} is a case of habitual minor wrongdoing, in cases where habitual rather than reflective action is called for. Now we'll spend a bit of time on wrongdoing that is culturally approved.

## Moral Mistakes and Moral Strangers {#moralmistakesandmoralstrangers}

Nothing I've said so far explains why [JoJo]{acronym-label="JoJo" acronym-form="singular+short"} is less blameworthy than his father. And many philosophers hold it to be very intuitive that he is, and that something like MIE explains why. My preferred account of [JoJo]{acronym-label="JoJo" acronym-form="singular+short"} relies on work by Elinor @Mason2015.

Mason argues thinks that the debate about moral ignorance has been oversimplified in a number of ways. She argues that there are really two kinds of blame, what she calls 'ordinary blame' and 'objective blame'. And MIE is completely wrong about objective blame. But it is correct for ordinary blame, provided we are careful to restrict clause 2 to full beliefs of the agent. This restriction excludes where the agent knows, or even suspects, deep down that they are doing something wrong. And she is much more willing than Rosen or Zimmerman to say that even when someone does fully believe that what they are doing is right, this could be due to a blameworthy kind of motivated reasoning. But all that said, she does think that a suitable version of MIE could hold for ordinary blame. Here is an important part of what she means by 'ordinary blame', and why she thinks MIE is correct about it.

> Normally, we blame each other for what we deliberately do. And if we find out that some piece of behavior was not deliberate, we let the agent off the hook. This is ordinary everyday blameworthiness. Ordinary blameworthiness is based on subjective wrongdoing. When ordinary people behave badly, they are usually, at some level (and this need not be the fully conscious level that Rosen and Zimmerman require), aware that they are doing it. Tony Blair did many wrong things during his time as Prime Minister, and it seems plausible that he knew, at some level, that these actions were wrong. He is not outside of our moral community: he did not seem to have the wrong end of the stick about what morality required. Rather, he was too easily swayed by the wrong sorts of reason. He did not try hard enough. Much of his ignorance, both factual and moral, was motivated ignorance or affected ignorance. He was (and is) thus blameworthy in the ordinary way. When we blame people for their akratic acts, we take it that they have the capacities and moral knowledge that we have: they are part of our moral community in that they share the basic standards that we hold ourselves to.  [@Mason2015 12]

There are (at least) three interesting claims being made here.

1.  Only people who are in our moral community are subject to ordinary blame. We might have contempt, or disdain, or disrepect for people in alien moral communities. Indeed, we might hold them subject to objective blame. Indeed, having contempt, etc for them might be a way of objectively blaming them.
2.  When an ordinary person in our moral community does something wrong, they know that what they are doing is wrong, at least at some, possibly sub-conscious, level, or they are engaged in blameworthy motivated reasoning.
3.  Only people who know that what they are doing is wrong, at least at some, possibly sub-conscious, level, are subject to ordinary blame, unless they are engaged in blameworthy motivated reasoning.

I'm not sure whether Mason intended to argue from 1 and 2 to 3; the text doesn't make that appear to be the central strand on her reasoning. (Cases like JoJo's are much more important.) But as I've set this up, there is a valid argument from 1 and 2 to 3. And it's a pretty interesting argument for MIE.

Premise 2 in this argument is clearly an empirical claim. We saw a version of it in Calhoun's picture that blameless ignorance typically requires societal ignorance. People whose society generally disapproves of their moral theories have sufficient reason to temper those theories at least enough so they should not be acted on. And the general picture is continuous with what John Kenneth Galbraith was articulating when he described modern conservatism as "the search for a superior justification for selfishness"  [@Galbraith1964 16]. The picture is that deep down, people who do wrong know that they are being selfish, or discriminatory, or in some way immoral, but they attempt to, or perhaps successfully motivate themselves to, justify this behaviour in moral language.

But unless the claim about moral community is taken to, by stipulation, include only people who don't have any thorough-going, unmotivated, false moral beliefs, I don't see why we should accept this claim. Here are three very broad classes of exceptions.

[Hacker]{acronym-label="Hacker" acronym-form="singular+short"} is an anti-abortion activist. He knows that many people think abortion is permissible, and for this reason he refrains from using violence in support of his anti-abortion crusade. But he does campaign for regulations that are used to close abortion clinics. And he hacks into the computer systems of abortion clinics to render their systems inoperative, and make it harder for them to carry out abortions. He thinks this work is morally mandatory, so he certainly thinks it is permissible. I doesn't strike me as plausible that he believes, deep down, that he is doing something wrong. We can stipulate that he knows that what he is doing reduces the autonomy of women seeking abortions. But since he regards abortion as morally equivalent to murder, he doesn't think that reducing the autonomy of would be murderers is a bad thing.

[Guy]{acronym-label="Guy" acronym-form="singular+short"} is a regular American, with a regular American diet. This includes generous helpings of factory farmed meat. To the extent that he worries about this, it is just because of the health consequences. He doesn't think animals bred for food have any moral standing. (Though he does think people should be jailed for promoting dog fighting.) The interests of humans, he think, come first, and factory farming is justified because it lowers the cost of meat. It seems consistent to think that he is very badly wrong about this, and yet he doesn't have any internal sense, even deep down, that this is so.

Finally,[Rush]{acronym-label="Rush" acronym-form="singular+short"} is in a hurry to get home. It's an emergency. Well, it's not an emergency really, but his child is hungry and is screaming, so it feels like one. So [Rush]{acronym-label="Rush" acronym-form="singular+short"} drives somewhat aggressively, and somewhat impolitely, and in so doing wrongs other road users. He actually does know that what he is doing is usually wrong. But he also knows that what he's doing is acceptable, and perhaps mandatory, in an emergency. (Assume that his driving, though inconvenient for other road users, would be exactly the right thing to do if he needed to race his child to hospital. So Rush really knows that there is an exception here; he's just mistaken about its scope.) And he is, like most of us, rather too willing to classify his own challenges as falling into the scope of that exception for emergency. Note that he is making a moral mistake here, not a factual one. The mistake is not about how to describe what it's like in his car. He knows that he has a hungry but not actually endangered baby who is screaming. What he's wrong about is whether this is enough to trigger an exception to the normal moral rules about carefulness and politeness on the roads. Maybe some real people who are like [Rush]{acronym-label="Rush" acronym-form="singular+short"} know that there is some special pleading here. But I don't think they all do; some people make moral mistakes that are convenient without being at any level motivated.

[Hacker]{acronym-label="Hacker" acronym-form="singular+short"}, [Guy]{acronym-label="Guy" acronym-form="singular+short"} and [Rush]{acronym-label="Rush" acronym-form="singular+short"} all do something they think is permissible. And they are all wrong. And they are all in our moral community, at least as I'd understand the expression 'moral community'. And in none of those cases should their mistaken moral beliefs lessen their responsibility. That's a striking contrast with [JoJo]{acronym-label="JoJo" acronym-form="singular+short"}.

And this all suggests a simple explanation for the intuitions about [JoJo]{acronym-label="JoJo" acronym-form="singular+short"}. We intuit that there is a kind of blameworthiness, or perhaps a degree of blameworthiness, that only applies when the agent is part of our moral community. I'm not endorsing this intuition; I'm just trying to explain why we think what we do about [JoJo]{acronym-label="JoJo" acronym-form="singular+short"}. What I do think is that we intuit that [JoJo]{acronym-label="JoJo" acronym-form="singular+short"} is, in virtue of his depraved upbringing, outside our moral community in a way that his father might not be. This idea, that intuitions about blameworthiness track membership in a moral community rather than moral ignorance, seems like a better explanation of our intuitions about [JoJo]{acronym-label="JoJo" acronym-form="singular+short"}.

This view is similar to what Miranda @Fricker2010 [152] calls the 'relativism of blame'. She holds that

> Blame is inappropriate if the relevant action or omission is owing to a structurally caused inability to form the requisite moral thought.  [@Fricker2010 167]

I don't think this can be quite right, because moral thoughts are never requisite for an action. Fricker talks about a schoolmaster a few decades back who canes students, but could not be expected to realise that this common practice was immoral. Well, maybe he couldn't, but he doesn't have to in order to not beat students. He just has to not beat them. [Huck]{acronym-label="Huck" acronym-form="singular+short"} Finn didn't have to realise it was wrong to turn in fugitive slaves in order to not turn in Jim; he just had to not turn Jim in. But set this point aside, and assume the issue is not 'requisite' moral thoughts, but simply corresponding ones.

And I don't think we should necessarily insist that we are dealing with structurally caused thoughts. A young child with a weakly developed sense of morality may be excused for their wrong actions. And that's because they are not fully part of our moral community. But it's a stretch to call this a structurally caused inability to form moral thoughts. Better to just say that the mid-Century schoolmaster, the ancient slaveholder and the young child are not full members of our moral community, and that's why blame is inappropriate.

(Joseph Shin pointed out in a seminar at Michigan that it is an attractive feature of MIE that is offers an explanation of why children are typically exempt from moral blame. He's right about this, and this strikes me as a point that future proponents and opponents of MIE should engage with.)

But all that said, there is something plausible about Fricker's relativism of blame. To blame someone is to stand in a relationship to them that is most natural in the context of some pre-existing relationship, or at least some pre-existing commonality. People who are outside our moral community are not so much excused for their wrong actions as exempt from blame.

Moral communities are informal entities, quite unlike countries. Membership of a common moral community could be a matter of degree. So we could make a gradational version of Fricker's relativism of blame. A wrong-doer is only blameworthy to the extent they are a member of our moral community. As a corrollorary they are only fully blameworthy if they are fully a member of the community.

This approach agrees with intuitions about cases. [JoJo]{acronym-label="JoJo" acronym-form="singular+short"}'s upbringing is so strange that he's outside our community in many respects. So he's exempt from certain kinds of blame. [Hacker]{acronym-label="Hacker" acronym-form="singular+short"}, [Guy]{acronym-label="Guy" acronym-form="singular+short"} and [Rush]{acronym-label="Rush" acronym-form="singular+short"} are in our moral community, although they make moral mistakes. Those mistakes don't exempt them from blame. On this way of thinking, the argument from cases starts with plausible premises, but overgeneralises. What is relevant is not that [JoJo]{acronym-label="JoJo" acronym-form="singular+short"} thinks the token acts he performs as a vicious dictator are permissible, but the broader moral system he is a part of. MIE goes wrong by focussing on local beliefs of the wrong-doer; we should be looking at structural features of their belief system.

I've said this is a plausible explanation of why we have certain intuitions, but that's a long way from saying those intuitions are true. I don't have to take a stand on that question, and I don't know what the right thing to say is. My best guess is that figuring out what to say about [JoJo]{acronym-label="JoJo" acronym-form="singular+short"} requires settling some very big picture questions about the role of blame in a moral theory. One possible consequence of the ideas I've just been sketching is that we shouldn't *blame* [JoJo]{acronym-label="JoJo" acronym-form="singular+short"}, but we should have some other negative person-level evaluation of him. That's to say, we should still in some good sense hold him responsible for his actions - though maybe not in the way that we hold people responsible when we blame them. It is not uncommon to see philosophers identify moral responsibility with susceptibility to praise and blame, and if the picture I've been building to here is right, that identification must be wrong. We could treat [JoJo]{acronym-label="JoJo" acronym-form="singular+short"} as responsible by, for example, being angry at him, or having contempt for him, even if we don't blame him, or think blame would be the right kind of attitude to hold. While I'm not going to settle any questions that big, I will end with some other points about blame that help make sense of the views I've defended in this chapter.

## Two Approaches to Blame {#twoapproachestoblame}

Neil @Levy2005 helpfully distinguishes two approaches to responsibility.

> There are accounts that hold that an agent is responsible for something (an act, omission, attitude, and so on) just in case that agent has -- directly or indirectly -- chosen that thing, and there are accounts that hold that an agent is responsible for something just in case that thing is appropriately attributable to her. ... Call these accounts volitionist and attributionist accounts of moral responsibility.  [@Levy2005 2]

The view of responsibility I'm taking here is very much in the spirit of the views that Levy calls attributionist. In particular, I've relied heavily on the idea that someone can be responsible for not reconsidering their moral views. Yet we rarely choose to deliberate. Indeed, the notion of choosing to deliberate is of dubious coherence. Once we are thinking about whether to look more closely at, say, our belief that *p*, we already are to some extent deliberating about *p*. So some things that we are responsible for, namely failures to deliberate, are not choices. And that's contrary to the view that Levy calls volitionist.

The argument of the last paragraph is not novel; it draws heavily on the arguments for attributionism by Angela @AngelaSmith2005. It is sometimes thought that agents are never really responsible for certain failures, such as failures to deliberate. What they are responsible for are the actions that produce a disposition to deliberate or not in the appropriate circumstances. This seems rather implausible to me, for reasons set out by Manuel @Vargas2005. But perhaps this kind of consideration can be used to produce a form of normative externalism that is compatible with volitionism. After all, normative externalism doesn't require rejecting volitionism, at least as Levy has defined it here. Consider again the ancient slaveowner in the example that Rosen and Guerrero discuss. The slaveowner does choose to own slaves, and it is the slaveowning for which he is blameworthy. He doesn't choose to do the wrong thing as such. But it is a very stringent condition on responsibility that one choose to do the wrong thing as such. Someone could be a volitionist and a normative externalist provided they reject that stringent condition.

Levy argues that one problem for the attributionist view is that it can't distinguish between the wrong and the blameworthy. As we saw, this idea is also behind one of Calhoun's arguments. She thinks that some arguments that men are blameworthy for their part in maintaining an oppressive society turn on conflating wrong and blameworthy acts. And intuitively this is a conflation between two distinct concepts. As Levy notes, attributionists can find some difficulty in making sense of the distinction. Indeed, he quotes two prominent attributionists, Robert @Adams1985 and Gary @Watson1996 explicitly saying that thinking something is wrong is, to some extent, blaming the wrongdoer. To conclude this discussion of responsibility, I want to note that there is a possible view that holds that blameworthiness and responsibility are conceptually distinct, even though any wrong act is blameworthy. This view is particularly congenial to the normative externalist.

On the view I have in mind, wrongfulness and blameworthiness differ in three respects.

1.  They have different targets. It is, in the first instance, actions that are wrong, but agents who are blameworthy.
2.  They differ with respect to time. As noted above, an action can become less blameworthy over time, but does not become less wrong.
3.  They frequently differ with respect to degree.

The last point is true because there are such things as partial excuses. Indeed, it is arguable that all excuses are partial excuses. By a partial excuse, I mean something that reduces an agent's blameworthiness, without fully absolving the agent. It is helpful to think of a familiar analogy from the criminal law. Sometimes, special circumstances can provide an agent with a defence; the circumstances mean that the agent was not guilty of any crime even though they fulfilled all the elements of the crime. (Defence of another is often thought of this way.) In other cases, circumstances mitigate an agent's guilt. They don't provide a reason for finding the agent not guilty, but they provide a reason for imposing a lesser punishment. In this context, a full excuse would be something that meant there was no punishment at all that was appropriate, but which did not provide a reason for finding the person not guilty. This is a strange combination. Indeed, it may be incoherent. The finding of guilt is itself a punishment. The same thing is true in the moral case. Excuses typically mitigate responsibility. But things that absolve an agent from responsibility are usually defences, which imply the agent didn't do anything wrong. Holding that the agent has no defence for what they did, but they are fully excused, is an unstable position.

The reasoning of the last paragraph suggests that the following principle is plausible:

-   If S's action *X* at *t* is wrong, then S is to some extent blameworthy at *t* for *X*.

This principle does not imply that S's action is blameworthy, only that S herself is. And the principle does not imply anything about how blameworthy S is at later times. And it does not imply that S is blameworthy in strict proportion to the wrongness of her action. Indeed, none of these three claims is plausibly true. So here we have three important conceptual distinctions between wrongfulness and blameworthiness. But the principle does amount to a kind of attributionism, one that is very friendly to normative externalism. So the normative externalist, and the attributionist, need not be guilty of any conceptual confusion.

Here is another way to defend the principle. It is sufficient to count as blaming someone for an action that you in some way harm them, or sanction them, for performing the action, on non-consequentialist grounds. To believe that someone has done something wrong is to harm them. To improperly believe someone has done something wrong is indeed to wrong them  [@BasuSchroeder2018]. It's not a wrong if the belief is well-grounded, but it is still a harm. And, like most beliefs, it isn't held on consequentialist grounds. So to believe that someone has done something is wrong is already to blame them - at least a little. When philosophers say that some wrong actions are not blameworthy, I think it would be better to say that no further blame, beyond believing the person performed the wrong actions, is fitting. In cases like [Inka]{acronym-label="Inka" acronym-form="singular+short"}'s, or [Gloucester]{acronym-label="Gloucester" acronym-form="singular+short"}'s, that might be the right thing to say.
